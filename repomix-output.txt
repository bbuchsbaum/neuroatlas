This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: R/*.R, R/*.r, *.Rmd, *.rmd, DESCRIPTION, tests/*.R, tests/*.r, tests/**/*.R, tests/**/*.r, src/*.cpp, src/*.h, src/*.hpp, src/**/*.cpp, src/**/*.h, src/**/*.hpp
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
R/
  all_generic.R
  aseg_subcort.R
  atlas_methods.R
  atlas_utils.R
  atlas.R
  chart.R
  data-schaefer.R
  dilate_parcels.R
  fsaverage.R
  ggschaefer.R
  glasser.R
  neuroatlas-package.R
  olsen_mtl.R
  print-plot-methods.R
  schaefer.R
  template_flow.R
  zzz.R
tests/
  testthat/
    test-atlas-integrity.R
    test-data-integrity.R
    test-dilation.R
    test-merge-atlases.R
    test-reduce-atlas.R
    test-roi-operations.R
    test-space-transforms.R
    test-surface-atlases.R
    test-templateflow-advanced.R
  testthat.R
DESCRIPTION
README.Rmd
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="R/atlas_utils.R">
#' Internal Helper: Get Atlas Volume
#'
#' Retrieves the volume component from an atlas object.
#'
#' @param atlas An object of class 'atlas' or similar containing a volume
#'   definition in either `atlas$atlas` or `atlas$data`.
#'
#' @return A `NeuroVol` object used to define ROIs.
#' @keywords internal
#' @noRd
.get_atlas_volume <- function(atlas) {
  vol <- NULL

  if (!is.null(atlas$atlas) && methods::is(atlas$atlas, "NeuroVol")) {
    vol <- atlas$atlas
  } else if (!is.null(atlas$atlas) && methods::is(atlas$atlas, "ClusteredNeuroVol")) {
    vol <- atlas$atlas
  } else if (!is.null(atlas$data) && methods::is(atlas$data, "NeuroVol")) {
    vol <- atlas$data
  } else if (!is.null(atlas$data) && methods::is(atlas$data, "ClusteredNeuroVol")) {
    vol <- atlas$data
  }

  if (is.null(vol)) {
    stop("Could not determine atlas volume from object")
  }
  vol
}
</file>

<file path="R/data-schaefer.R">
#' Schaefer Atlas with 17 Networks and 200 Parcels
#'
#' @description
#' Pre-loaded Schaefer cortical parcellation with 200 regions organized into 17 
#' functional networks. This atlas divides the cerebral cortex based on resting-state 
#' functional connectivity patterns.
#'
#' @format A list with class 'schaefer' and 'atlas' containing:
#' \describe{
#'   \item{name}{Character string "schaefer17_200"}
#'   \item{atlas}{A \code{ClusteredNeuroVol} object with the parcellation}
#'   \item{cmap}{Data frame with RGB color values for visualization}
#'   \item{ids}{Integer vector of region IDs (1:200)}
#'   \item{labels}{Character vector of region labels}
#'   \item{orig_labels}{Original Schaefer labels}
#'   \item{network}{Network assignment for each region}
#'   \item{hemi}{Hemisphere designation ('left' or 'right')}
#' }
#'
#' @source
#' \url{https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal}
#'
#' @references
#' Schaefer, A., et al. (2018). Local-Global Parcellation of the Human Cerebral
#' Cortex from Intrinsic Functional Connectivity MRI. Cerebral Cortex, 28(9),
#' 3095-3114.
#'
#' @examples
#' \donttest{
#' data(Schaefer17_200)
#' print(Schaefer17_200)
#' table(Schaefer17_200$network)
#' }
#'
#' @keywords datasets
"Schaefer17_200"

#' Schaefer Atlas with 17 Networks and 400 Parcels
#'
#' @description
#' Pre-loaded Schaefer cortical parcellation with 400 regions organized into 17 
#' functional networks. This atlas divides the cerebral cortex based on resting-state 
#' functional connectivity patterns.
#'
#' @format A list with class 'schaefer' and 'atlas' containing:
#' \describe{
#'   \item{name}{Character string "schaefer17_400"}
#'   \item{atlas}{A \code{ClusteredNeuroVol} object with the parcellation}
#'   \item{cmap}{Data frame with RGB color values for visualization}
#'   \item{ids}{Integer vector of region IDs (1:400)}
#'   \item{labels}{Character vector of region labels}
#'   \item{orig_labels}{Original Schaefer labels}
#'   \item{network}{Network assignment for each region}
#'   \item{hemi}{Hemisphere designation ('left' or 'right')}
#' }
#'
#' @source
#' \url{https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal}
#'
#' @references
#' Schaefer, A., et al. (2018). Local-Global Parcellation of the Human Cerebral
#' Cortex from Intrinsic Functional Connectivity MRI. Cerebral Cortex, 28(9),
#' 3095-3114.
#'
#' @examples
#' \donttest{
#' data(Schaefer17_400)
#' print(Schaefer17_400)
#' table(Schaefer17_400$network)
#' }
#'
#' @keywords datasets
"Schaefer17_400"

#' Schaefer Atlas with 17 Networks and 600 Parcels
#'
#' @description
#' Pre-loaded Schaefer cortical parcellation with 600 regions organized into 17 
#' functional networks. This atlas divides the cerebral cortex based on resting-state 
#' functional connectivity patterns.
#'
#' @format A list with class 'schaefer' and 'atlas' containing:
#' \describe{
#'   \item{name}{Character string "schaefer17_600"}
#'   \item{atlas}{A \code{ClusteredNeuroVol} object with the parcellation}
#'   \item{cmap}{Data frame with RGB color values for visualization}
#'   \item{ids}{Integer vector of region IDs (1:600)}
#'   \item{labels}{Character vector of region labels}
#'   \item{orig_labels}{Original Schaefer labels}
#'   \item{network}{Network assignment for each region}
#'   \item{hemi}{Hemisphere designation ('left' or 'right')}
#' }
#'
#' @source
#' \url{https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal}
#'
#' @references
#' Schaefer, A., et al. (2018). Local-Global Parcellation of the Human Cerebral
#' Cortex from Intrinsic Functional Connectivity MRI. Cerebral Cortex, 28(9),
#' 3095-3114.
#'
#' @examples
#' \donttest{
#' data(Schaefer17_600)
#' print(Schaefer17_600)
#' table(Schaefer17_600$network)
#' }
#'
#' @keywords datasets
"Schaefer17_600"
</file>

<file path="R/fsaverage.R">
#' Surface geometry for the fsaverage6 atlas
#'
#' a list including left and right hemispheres for the orig, white, inflated, and pial surfaces.
#'
#' @docType data
#' @keywords datasets
#' @name fsaverage
#' @usage data(fsaverage)
"fsaverage"
</file>

<file path="R/neuroatlas-package.R">
#' @keywords internal
"_PACKAGE"

#' neuroatlas: Neuroimaging Atlases and Parcellations
#'
#' The neuroatlas package provides a unified interface to access and work with 
#' various neuroimaging atlases and parcellations. It includes support for 
#' cortical atlases (Schaefer, Glasser), subcortical segmentations (FreeSurfer ASEG), 
#' and specialized atlases (Olsen MTL). The package integrates with TemplateFlow 
#' for standardized template access and supports visualization through the ggseg ecosystem.
#'
#' @section Main Functions:
#' \describe{
#'   \item{\code{\link{get_schaefer_atlas}}}{Access Schaefer cortical parcellations}
#'   \item{\code{\link{get_glasser_atlas}}}{Access Glasser multi-modal parcellation}
#'   \item{\code{\link{get_aseg_atlas}}}{Access FreeSurfer subcortical segmentation}
#'   \item{\code{\link{get_olsen_mtl}}}{Access Olsen medial temporal lobe atlas}
#'   \item{\code{\link{get_template}}}{Fetch templates from TemplateFlow}
#' }
#'
#' @section Atlas Operations:
#' \describe{
#'   \item{\code{\link{get_roi}}}{Extract specific regions from an atlas}
#'   \item{\code{\link{map_atlas}}}{Map values to atlas regions}
#'   \item{\code{\link{reduce_atlas}}}{Combine regions within an atlas}
#'   \item{\code{\link{merge_atlases}}}{Combine multiple atlases}
#'   \item{\code{\link{dilate_atlas}}}{Expand atlas regions into unassigned voxels}
#' }
#'
#' @section Visualization:
#' The package integrates with ggseg for brain visualization:
#' \describe{
#'   \item{\code{\link{plot.atlas}}}{Plot atlas objects}
#'   \item{\code{\link{ggseg_schaefer}}}{Visualize Schaefer parcellations with ggseg}
#' }
#'
#' @section TemplateFlow Integration:
#' Access standardized neuroimaging templates:
#' \describe{
#'   \item{\code{\link{create_templateflow}}}{Initialize TemplateFlow connection}
#'   \item{\code{\link{tflow_spaces}}}{List available template spaces}
#'   \item{\code{\link{install_templateflow}}}{Install Python TemplateFlow module}
#' }
#'
#' @name neuroatlas-package
#' @aliases neuroatlas
NULL
</file>

<file path="R/print-plot-methods.R">
#' Print Methods for neuroatlas Objects
#'
#' @description
#' Print methods for various atlas objects in the neuroatlas package
#'
#' @param x An atlas object (atlas, glasser, schaefer, etc.)
#' @param ... Additional arguments passed to print
#'
#' @return The object is returned invisibly
#' @name print-methods
NULL

#' Plot Methods for neuroatlas Objects  
#'
#' @description
#' Plot methods for various atlas objects in the neuroatlas package
#'
#' @param x An atlas object (atlas, glasser, schaefer, etc.)
#' @param y Ignored (required for S3 consistency)
#' @param ... Additional arguments passed to specific plot implementations
#'
#' @return A plot object (specific type depends on the atlas)
#' @name plot-methods
NULL

#' @rdname print-methods
#' @importFrom cli rule symbol
#' @importFrom crayon bold blue green yellow red white
#' @export
print.schaefer <- function(x, ...) {
  cat(cli::rule(crayon::bold("Schaefer Atlas"), line = 2), "\n")
  cat(crayon::blue("Name:"), x$name, "\n")
  
  if (!is.null(x$atlas)) {
    dims <- dim(x$atlas)
    cat(crayon::blue("Dimensions:"), paste(dims, collapse = " x "), "\n")
  }
  
  n_regions <- length(x$ids)
  cat(crayon::blue("Regions:"), n_regions, "\n")
  
  # Extract network count from name
  if (grepl("\\d+networks", x$name)) {
    networks <- sub(".*-(\\d+)networks.*", "\\1", x$name)
    cat(crayon::blue("Networks:"), networks, "\n")
  }
  
  # Hemisphere distribution
  if (!is.null(x$hemi)) {
    hemi_table <- table(x$hemi)
    hemi_str <- paste(names(hemi_table), hemi_table, sep = ": ", collapse = ", ")
    cat(crayon::blue("Hemispheres:"), hemi_str, "\n")
  }
  
  # Network distribution if available
  if (!is.null(x$network)) {
    unique_networks <- length(unique(x$network))
    cat(crayon::blue("Unique networks:"), unique_networks, "\n")
  }
  
  invisible(x)
}
</file>

<file path="tests/testthat/test-atlas-integrity.R">
test_that("atlas loading maintains data integrity and handles errors gracefully", {
  skip_on_cran()
  
  # Test 1: Schaefer atlas label consistency and ID mapping
  # This tests critical ID remapping for right hemisphere and label parsing
  atlas <- tryCatch({
    get_schaefer_atlas(parcels = "100", networks = "7")
  }, error = function(e) {
    skip("Failed to download Schaefer atlas")
  })
  
  # Check basic structure
  expect_true(inherits(atlas, "atlas"))
  expect_true(inherits(atlas, "schaefer"))
  expect_equal(length(atlas$ids), 100)
  expect_equal(length(atlas$labels), 100)
  expect_equal(length(atlas$orig_labels), 100)
  expect_equal(length(atlas$hemi), 100)
  expect_equal(length(atlas$network), 100)
  
  # Critical: Check hemisphere distribution (should be exactly 50/50)
  hemi_table <- table(atlas$hemi)
  expect_equal(as.numeric(hemi_table["left"]), 50)
  expect_equal(as.numeric(hemi_table["right"]), 50)
  
  # Critical: Check ID mapping - left should be 1:50, right should be 51:100
  left_ids <- atlas$ids[atlas$hemi == "left"]
  right_ids <- atlas$ids[atlas$hemi == "right"]
  expect_equal(sort(left_ids), 1:50)
  expect_equal(sort(right_ids), 51:100)
  
  # Critical: Verify label_map integrity in ClusteredNeuroVol
  label_map <- atlas$atlas@label_map
  expect_equal(length(label_map), 100)
  
  # Label map values should match the IDs
  label_map_ids <- sort(unique(unlist(label_map)))
  expect_equal(label_map_ids, 1:100)
  
  # Check that all voxel values in the atlas correspond to valid IDs
  # Use proper S4 extraction
  atlas_values <- unique(atlas$atlas@.Data[atlas$atlas@.Data != 0])
  expect_true(all(atlas_values %in% 1:100))
  
  # Test error handling for invalid parameters
  expect_error(get_schaefer_atlas(parcels = "999", networks = "7"), 
               "'arg' should be one of")
  expect_error(get_schaefer_atlas(parcels = "100", networks = "5"), 
               "'arg' should be one of")
})

test_that("resampling preserves labels and handles edge cases correctly", {
  skip("Skipping resampling test - neuroim2::resample doesn't support ClusteredNeuroVol properly")
})

test_that("merge_atlases handles ID conflicts and maintains referential integrity", {
  skip_on_cran()
  
  # Test 3: Critical atlas merging scenarios
  # Create two small atlases to merge
  atlas1 <- get_aseg_atlas()
  
  # We need a second atlas in the same space
  # For testing, we'll use a modified version of the same atlas
  atlas2 <- atlas1
  atlas2$name <- "aseg_modified"
  
  # Modify IDs to create a potential conflict scenario
  # This simulates merging atlases that might have overlapping ID schemes
  max_id <- max(atlas1$ids)
  
  # Test basic merge
  merged <- merge_atlases(atlas1, atlas2)
  
  # Critical checks for merged atlas
  expect_equal(merged$name, paste0(atlas1$name, "::", atlas2$name))
  expect_equal(length(merged$ids), length(atlas1$ids) + length(atlas2$ids))
  expect_equal(length(merged$labels), length(atlas1$labels) + length(atlas2$labels))
  
  # Check ID adjustment - atlas2 IDs should be shifted
  original_max <- max(atlas1$ids)
  atlas2_ids_in_merged <- merged$ids[(length(atlas1$ids) + 1):length(merged$ids)]
  expect_true(all(atlas2_ids_in_merged > original_max))
  
  # Check no ID collisions
  expect_equal(length(unique(merged$ids)), length(merged$ids))
  
  # Verify spatial integrity - merged volume should contain all regions
  # Convert ClusteredNeuroVol to dense first
  merged_dense <- neuroim2::as.dense(merged$atlas)
  merged_values <- sort(unique(as.vector(merged_dense[merged_dense != 0])))
  
  # When merging identical atlases, the second overwrites the first
  # So we expect only the shifted IDs from atlas2
  shifted_start <- max(atlas1$ids) + 1
  expected_values <- seq(shifted_start, shifted_start + length(atlas2$ids) - 1)
  expect_equal(merged_values, expected_values)
  
  # Test dimension mismatch error
  # Create atlas with different dimensions
  different_space <- neuroim2::NeuroSpace(
    dim = c(50, 50, 50),
    spacing = c(2, 2, 2),
    origin = c(0, 0, 0)
  )
  
  # Create a dummy atlas with different dimensions
  dummy_vol <- neuroim2::NeuroVol(array(1, dim = c(50, 50, 50)), 
                                  space = different_space)
  dummy_atlas <- list(
    name = "dummy",
    atlas = neuroim2::ClusteredNeuroVol(
      as.logical(dummy_vol),
      clusters = dummy_vol[dummy_vol != 0],
      label_map = list("region1" = 1)
    ),
    ids = 1,
    labels = "region1",
    orig_labels = "region1",
    hemi = NA,
    cmap = data.frame(id = 1, r = 255, g = 0, b = 0)
  )
  class(dummy_atlas) <- c("dummy", "atlas")
  
  # This should fail due to dimension mismatch
  expect_error(merge_atlases(atlas1, dummy_atlas),
               "dim\\(atlas1\\$atlas\\) == dim\\(atlas2\\$atlas\\)")
  
  # Test that merged atlas maintains all labels
  expect_equal(length(merged$labels), 
               length(atlas1$labels) + length(atlas2$labels))
})
</file>

<file path="tests/testthat/test-data-integrity.R">
test_that("Pre-loaded datasets have correct structure and integrity", {
  skip_on_cran()
  
  # Test 1: Check Schaefer pre-loaded datasets
  # These are ggseg atlas objects, not neuroatlas atlas objects
  schaefer_datasets <- c("Schaefer17_200", "Schaefer17_400", "Schaefer17_600")
  
  for (dataset_name in schaefer_datasets) {
    # Load the dataset
    data(list = dataset_name, envir = environment())
    dataset <- get(dataset_name)
    
    # Extract expected parcels from name
    parcels <- as.numeric(sub("Schaefer17_", "", dataset_name))
    
    # Verify it's a ggseg atlas
    expect_true(inherits(dataset, "ggseg_atlas"))
    expect_true(inherits(dataset, "data.frame"))
    
    # Should have regions - note the actual count may vary from simple 2x formula
    # due to exclusion of medial wall regions in ggseg format
    # Schaefer17_600 has 580 rows (missing some medial regions)
    expect_true(nrow(dataset) >= parcels * 0.95)  # Allow 5% fewer regions
    
    # Check for required ggseg columns
    expect_true("area" %in% names(dataset))
    expect_true("hemi" %in% names(dataset))
    expect_true("label" %in% names(dataset))
    
    # Check hemisphere distribution
    hemi_counts <- table(dataset$hemi)
    expect_true("left" %in% names(hemi_counts))
    expect_true("right" %in% names(hemi_counts))
    
    # Should have geometry data
    expect_true("side" %in% names(dataset))
    expect_true("ggseg" %in% names(dataset))
  }
  
  # Test 2: Check fsaverage dataset
  data("fsaverage", envir = environment())
  
  expect_true(inherits(fsaverage, "list"))
  
  # Should contain surface geometry data
  expected_surfaces <- c("lh_inflated", "rh_inflated", "lh_pial", "rh_pial",
                        "lh_white", "rh_white")
  available_surfaces <- intersect(names(fsaverage), expected_surfaces)
  expect_true(length(available_surfaces) > 0)
  
  # Check surface data structure
  for (surf in available_surfaces) {
    expect_true(inherits(fsaverage[[surf]], "SurfaceGeometry"))
    # Check if it has mesh data (SurfaceGeometry uses mesh slot, not vertices)
    expect_true(!is.null(fsaverage[[surf]]@mesh))
    # mesh3d objects have vertex buffer (vb) with 4 rows (x,y,z,w)
    expect_true(!is.null(fsaverage[[surf]]@mesh$vb))
    expect_true(is.matrix(fsaverage[[surf]]@mesh$vb))
    expect_true(nrow(fsaverage[[surf]]@mesh$vb) == 4)  # x, y, z, w coordinates
  }
  
  # Test 3: Check olsen_mtl dataset
  data("olsen_mtl", envir = environment())
  
  expect_true(is.list(olsen_mtl))  # Check it's a list type
  expect_true(inherits(olsen_mtl, "olsen_mtl"))
  expect_true(inherits(olsen_mtl, "atlas"))
  
  # Check MTL-specific structure
  expect_true(all(c("name", "atlas", "cmap", "ids", "labels", 
                    "orig_labels", "hemi") %in% names(olsen_mtl)))
  
  # MTL regions should include hippocampus, entorhinal, etc.
  # Note: Olsen uses abbreviations: ERC=Entorhinal, PHC=Parahippocampal, PRC=Perirhinal
  mtl_regions <- c("Hipp", "ERC", "PHC", "PRC", "CA1", "CA3", "Sub")
  found_regions <- sapply(mtl_regions, function(r) {
    any(grepl(r, olsen_mtl$labels, ignore.case = TRUE))
  })
  expect_true(sum(found_regions) >= 5)  # At least 5 MTL regions
  
  # Should have bilateral regions
  expect_true("left" %in% olsen_mtl$hemi)
  expect_true("right" %in% olsen_mtl$hemi)
})

test_that("Critical helper functions work correctly", {
  skip_on_cran()
  
  # Test 1: getmode function
  # This is used in resampling for smoothing
  test_vectors <- list(
    single_mode = c(1, 2, 2, 2, 3, 3, 4),  # Mode is 2
    tie = c(1, 1, 2, 2, 3, 3),              # Tie, should return first
    all_unique = c(1, 2, 3, 4, 5),         # All unique
    with_zeros = c(0, 0, 0, 1, 1, 2)       # Mode is 0
  )
  
  # Access internal function
  getmode <- neuroatlas:::getmode
  
  expect_equal(getmode(test_vectors$single_mode), 2)
  expect_true(getmode(test_vectors$tie) %in% c(1, 2, 3))  # Any tied value
  expect_true(getmode(test_vectors$all_unique) %in% 1:5)  # Any value
  expect_equal(getmode(test_vectors$with_zeros), 0)
  
  # Test 2: Label parsing in schaefer_metainfo
  test_labels <- c(
    "7Networks_LH_Vis_1",
    "7Networks_RH_Default_10",
    "17Networks_LH_VisCent_ExStr_1",
    "17Networks_RH_SomMotA_2"
  )
  
  for (label in test_labels) {
    # Check label format - should start with network specification
    expect_true(grepl("^(7|17)Networks", label))
    
    # Check hemisphere specification
    expect_true(grepl("_(LH|RH)_", label))
    
    # Check it has a region name and number
    parts <- strsplit(label, "_")[[1]]
    expect_true(length(parts) >= 4)  # e.g., "17Networks", "LH", "VisCent", "1"
  }
  
  # Test 3: Cache directory function
  cache_dir <- neuroatlas:::get_cache_dir()
  
  expect_true(is.character(cache_dir))
  expect_true(nchar(cache_dir) > 0)
  
  # Should be a valid path
  expect_true(dir.exists(dirname(cache_dir)) || 
              dir.create(cache_dir, recursive = TRUE, showWarnings = FALSE))
  
  # Test 4: Basic dimension checks for loaded atlases
  # Load a small atlas to test
  atlas_test <- tryCatch(get_aseg_atlas(), error = function(e) NULL)
  if (!is.null(atlas_test)) {
    dims <- dim(atlas_test$atlas)
    expect_equal(length(dims), 3)
    expect_true(all(dims > 0))
  }
})

test_that("Edge cases in atlas operations are handled correctly", {
  skip("reduce_atlas method not yet implemented")
  skip_on_cran()
  
  # Test using existing loaded atlas instead of creating new spaces
  atlas <- tryCatch(get_aseg_atlas(), error = function(e) NULL)
  if (is.null(atlas)) {
    skip("Could not load test atlas")
  }
  
  # Test 1: Empty data operations
  test_vol <- atlas$atlas
  empty_data <- neuroim2::NeuroVol(
    numeric(prod(dim(test_vol))),  # All zeros
    space = neuroim2::space(test_vol)
  )
  
  # This should work but return zeros
  result <- tryCatch({
    reduce_atlas(atlas, empty_data, sum)
  }, error = function(e) e)
  
  if (!inherits(result, "error")) {
    expect_true(all(result$value == 0))
  }
  
  # Test 2: Atlas with all same values
  uniform_data <- neuroim2::NeuroVol(
    rep(42, prod(dim(test_vol))),
    space = neuroim2::space(test_vol)
  )
  
  reduced_uniform <- tryCatch({
    reduce_atlas(atlas, uniform_data, mean)
  }, error = function(e) e)
  
  if (!inherits(reduced_uniform, "error")) {
    expect_true(all(reduced_uniform$value == 42))
  }
  
  # Test 3: Extreme values - skip as reduce_atlas is not implemented
  skip("reduce_atlas method not yet implemented")
})
</file>

<file path="tests/testthat/test-merge-atlases.R">
context("merge_atlases")

test_that("merge_atlases combines ids and preserves dimensions", {
  skip_on_cran()
  a1 <- get_aseg_atlas()
  a2 <- get_aseg_atlas()
  merged <- merge_atlases(a1, a2)

  expect_true(inherits(merged, "atlas"))
  expect_equal(length(merged$ids), length(a1$ids) + length(a2$ids))
  expect_equal(dim(merged$atlas), dim(a1$atlas))
})
</file>

<file path="tests/testthat.R">
# This file is part of the standard devtools suite.
# All unit tests are placed within the tests/testthat/ directory.

library(testthat)
library(neuroatlas)

test_check("neuroatlas")
</file>

<file path="README.Rmd">
---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = file.path("man", "figures", "README-"),
  out.width = "100%"
)
```

<!-- badges: start -->
[![Project Status: Concept â€“ Minimal or no implementation has been done yet, or the repository is only intended to be a limited example, demo, or proof-of-concept.](https://www.repostatus.org/badges/latest/concept.svg)](https://www.repostatus.org/#concept)
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![License](https://img.shields.io/badge/license-GPL--3-blue.svg?style=flat)](https://www.gnu.org/licenses/gpl-3.0.html)
[![Release](https://img.shields.io/github/release/inbo/neuroatlas.svg)](https://github.com/inbo/neuroatlas/releases)
![GitHub](https://img.shields.io/github/license/inbo/neuroatlas)
[![R build status](https://github.com/inbo/neuroatlas/workflows/check%20package%20on%20main/badge.svg)](https://github.com/inbo/neuroatlas/actions)
![r-universe name](https://inbo.r-universe.dev/badges/:name?color=c04384)
![r-universe package](https://inbo.r-universe.dev/badges/neuroatlas)
[![Codecov test coverage](https://codecov.io/gh/inbo/neuroatlas/branch/main/graph/badge.svg)](https://app.codecov.io/gh/inbo/neuroatlas?branch=main)
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/inbo/neuroatlas.svg)
![GitHub repo size](https://img.shields.io/github/repo-size/inbo/neuroatlas.svg)
<!-- badges: end -->

# neuroatlas

The goal of neuroatlas is to ...

## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("remotes")
remotes::install_github("inbo/neuroatlas")
```

## Example

This is a basic example which shows you how to solve a common problem:

```{r example}
library(neuroatlas)
## basic example code
```

What is special about using `README.Rmd` instead of just `README.md`? 
You can include R chunks like so:

```{r cars}
summary(cars)
```

You'll still need to render `README.Rmd` regularly, to keep `README.md` up-to-date.
`devtools::build_readme()` is handy for this.

You can also embed plots, for example:

```{r pressure, echo = FALSE, eval = FALSE}
plot(pressure)
```

In that case, don't forget to commit and push the resulting figure files, so they display on GitHub and CRAN.
</file>

<file path="tests/testthat/test-surface-atlases.R">
test_that("surface atlas functions maintain hemisphere integrity and handle all surface types", {
  skip_on_cran()
  
  # Test 1: Load surface atlas and verify structure
  surf_atlas <- tryCatch({
    get_schaefer_surfatlas(parcels = "200", networks = "7", surf = "inflated")
  }, error = function(e) {
    skip("Failed to download surface atlas")
  })
  
  # Skip if download failed
  if (is.null(surf_atlas)) {
    skip("Surface atlas download failed")
  }
  
  # Check basic structure
  expect_true(inherits(surf_atlas, "surfatlas"))
  expect_true(all(c("lh_atlas", "rh_atlas", "name", "cmap", "ids", 
                    "labels", "orig_labels", "network", "hemi") %in% names(surf_atlas)))
  
  # Critical: Verify hemisphere data structures
  # LabeledNeuroSurface objects may have surf_atlas added to their class
  expect_true(inherits(surf_atlas$lh_atlas, "LabeledNeuroSurface") || 
              inherits(surf_atlas$lh_atlas, "surf_atlas"))
  expect_true(inherits(surf_atlas$rh_atlas, "LabeledNeuroSurface") || 
              inherits(surf_atlas$rh_atlas, "surf_atlas"))
  
  # Test 2: Verify ID mapping between hemispheres
  # Left hemisphere should have IDs 1:100, right hemisphere 101:200
  # LabeledNeuroSurface objects use data slot
  lh_data <- slot(surf_atlas$lh_atlas, "data")
  rh_data <- slot(surf_atlas$rh_atlas, "data")
  
  lh_ids <- unique(lh_data[lh_data > 0])
  rh_ids <- unique(rh_data[rh_data > 0])
  
  expect_true(all(lh_ids <= 100))
  expect_true(all(rh_ids > 100 & rh_ids <= 200))
  expect_equal(length(lh_ids) + length(rh_ids), 200)
  
  # Test 3: Test different surface types
  surfaces <- c("inflated", "white", "pial")
  surf_list <- list()
  
  for (surf_type in surfaces) {
    surf_list[[surf_type]] <- tryCatch({
      get_schaefer_surfatlas(parcels = "100", networks = "7", surf = surf_type)
    }, error = function(e) NULL)
  }
  
  # Remove any failed downloads
  surf_list <- surf_list[!sapply(surf_list, is.null)]
  
  if (length(surf_list) > 1) {
    # Verify that different surfaces have same parcellation but different geometry
    surf_names <- names(surf_list)
    for (i in 1:(length(surf_names)-1)) {
      surf1 <- surf_list[[surf_names[i]]]
      surf2 <- surf_list[[surf_names[i+1]]]
      
      # Same parcellation
      expect_equal(surf1$ids, surf2$ids)
      expect_equal(surf1$labels, surf2$labels)
      
      # Different geometry (vertices should differ for different surfaces)
      if ("geometry" %in% slotNames(surf1$lh_atlas) && "geometry" %in% slotNames(surf2$lh_atlas)) {
        geom1 <- slot(surf1$lh_atlas, "geometry")
        geom2 <- slot(surf2$lh_atlas, "geometry")
        # Check if mesh vertices differ between surfaces
        if (!is.null(geom1@mesh$vb) && !is.null(geom2@mesh$vb)) {
          expect_false(all(geom1@mesh$vb == geom2@mesh$vb))
        }
      }
    }
  }
  
  # Test 4: Verify label consistency
  # Extract parcels number from name (e.g., "Schaefer-200-7networks")
  parcels_num <- as.numeric(gsub(".*-(\\d+)-.*", "\\1", surf_atlas$name))
  expect_equal(length(surf_atlas$labels), parcels_num)
  expect_equal(sum(surf_atlas$hemi == "left"), length(surf_atlas$labels) / 2)
  expect_equal(sum(surf_atlas$hemi == "right"), length(surf_atlas$labels) / 2)
  
  # Test 5: Test error handling
  expect_error(get_schaefer_surfatlas(parcels = "999", networks = "7"),
               "'arg' should be one of")
  expect_error(get_schaefer_surfatlas(parcels = "100", networks = "7", surf = "invalid"),
               "'arg' should be one of")
})

test_that("network-specific functionality works correctly in Schaefer atlases", {
  skip_on_cran()
  
  # Load atlases with different network configurations
  atlas_7net <- tryCatch({
    get_schaefer_atlas(parcels = "200", networks = "7")
  }, error = function(e) {
    skip("Failed to load Schaefer atlas")
  })
  
  atlas_17net <- tryCatch({
    get_schaefer_atlas(parcels = "200", networks = "17")
  }, error = function(e) {
    skip("Failed to load Schaefer atlas")
  })
  
  # Test 1: Network assignments are valid
  expect_true("network" %in% names(atlas_7net))
  expect_true("network" %in% names(atlas_17net))
  
  # All regions should have network assignments
  expect_equal(length(atlas_7net$network), 200)
  expect_equal(length(atlas_17net$network), 200)
  expect_false(any(is.na(atlas_7net$network)))
  expect_false(any(is.na(atlas_17net$network)))
  
  # Test 2: Network count validation
  unique_7net <- unique(atlas_7net$network)
  unique_17net <- unique(atlas_17net$network)
  
  # Should have expected number of unique networks
  expect_lte(length(unique_7net), 7)
  expect_lte(length(unique_17net), 17)
  
  # Test 3: Network distribution across hemispheres
  # Networks should be roughly balanced between hemispheres
  for (net in unique_7net) {
    net_regions <- which(atlas_7net$network == net)
    left_count <- sum(atlas_7net$hemi[net_regions] == "left")
    right_count <- sum(atlas_7net$hemi[net_regions] == "right")
    
    # Each network should have regions in both hemispheres
    expect_true(left_count > 0)
    expect_true(right_count > 0)
    
    # Should be roughly balanced (within 20% difference)
    balance_ratio <- min(left_count, right_count) / max(left_count, right_count)
    expect_gt(balance_ratio, 0.3)  # At least 30% balance
  }
  
  # Test 4: Network preservation during operations
  # Reduce data by network
  test_data <- neuroim2::NeuroVol(
    rnorm(prod(dim(atlas_7net$atlas))),
    space = neuroim2::space(atlas_7net$atlas)
  )
  
  # Use wide format to maintain backward compatibility with this test
  reduced <- reduce_atlas(atlas_7net, test_data, mean, format = "wide")
  
  # Convert wide format to long format for network summary
  # Get the values from the reduced tibble (one row, many columns)
  region_values <- as.numeric(reduced[1, ])
  
  # The column names in reduced correspond to atlas orig_labels
  # We need to match them to get the corresponding network assignments
  col_indices <- match(colnames(reduced), atlas_7net$orig_labels)
  region_networks <- atlas_7net$network[col_indices]
  
  # Create network summary
  network_means <- tapply(
    region_values,
    region_networks,
    mean,
    na.rm = TRUE
  )
  
  expect_equal(length(network_means), length(unique_7net))
  expect_false(any(is.na(network_means)))
  
  # Test 5: Network info is properly stored
  # Network info should be in the network field, not orig_labels
  expect_true(!is.null(atlas_7net$network))
  expect_true(!is.null(atlas_17net$network))
  # All regions should have network assignments
  expect_equal(length(atlas_7net$network), length(atlas_7net$labels))
  expect_equal(length(atlas_17net$network), length(atlas_17net$labels))
})

test_that("color map handling works correctly across atlas operations", {
  skip_on_cran()
  
  # Test 1: Atlas color maps are properly structured
  atlases <- list(
    schaefer = tryCatch(get_schaefer_atlas(parcels = "100", networks = "7"), 
                       error = function(e) NULL),
    glasser = tryCatch(get_glasser_atlas(), error = function(e) NULL),
    aseg = tryCatch(get_aseg_atlas(), error = function(e) NULL)
  )
  
  # Remove failed loads
  atlases <- atlases[!sapply(atlases, is.null)]
  
  for (atlas_name in names(atlases)) {
    atlas <- atlases[[atlas_name]]
    
    # Check cmap structure
    expect_true("cmap" %in% names(atlas))
    expect_true(inherits(atlas$cmap, "data.frame"))
    
    # Should have RGB columns
    expect_true(all(c("red", "green", "blue") %in% names(atlas$cmap)) ||
                all(c("r", "g", "b") %in% names(atlas$cmap)) ||
                all(c("R", "G", "B") %in% names(atlas$cmap)))
    
    # RGB values should be valid (0-255)
    rgb_cols <- intersect(names(atlas$cmap), c("red", "green", "blue", "r", "g", "b", "R", "G", "B"))
    for (col in rgb_cols) {
      expect_true(all(atlas$cmap[[col]] >= 0 & atlas$cmap[[col]] <= 255))
    }
    
    # Should have entry for each region
    expect_equal(nrow(atlas$cmap), length(atlas$ids))
  }
  
  # Test 2: Color map preservation during merge
  if (length(atlases) >= 2) {
    atlas_names <- names(atlases)[1:2]
    atlas1 <- atlases[[atlas_names[1]]]
    atlas2 <- atlases[[atlas_names[2]]]
    
    # Ensure same space
    if (!all(dim(atlas1$atlas) == dim(atlas2$atlas))) {
      # Skip if resampling would fail (e.g., ClusteredNeuroVol)
      if (inherits(atlas2$atlas, "ClusteredNeuroVol")) {
        skip("Cannot resample ClusteredNeuroVol")
      }
      atlas2 <- list(
        name = atlas2$name,
        atlas = resample(atlas2$atlas, neuroim2::space(atlas1$atlas)),
        cmap = atlas2$cmap,
        ids = atlas2$ids,
        labels = atlas2$labels,
        orig_labels = atlas2$orig_labels,
        hemi = atlas2$hemi
      )
      class(atlas2) <- class(atlases[[atlas_names[2]]])
    }
    
    merged <- merge_atlases(atlas1, atlas2)
    
    # Merged cmap should have all regions
    expect_equal(nrow(merged$cmap), length(merged$ids))
    
    # Original colors should be preserved
    # First atlas colors
    n1 <- length(atlas1$ids)
    expect_equal(merged$cmap[1:n1,], atlas1$cmap)
  }
  
  # Test 3: Unique colors per region
  for (atlas_name in names(atlases)) {
    atlas <- atlases[[atlas_name]]
    
    # Create color strings
    rgb_cols <- intersect(names(atlas$cmap), c("r", "g", "b", "R", "G", "B"))
    if (length(rgb_cols) == 3) {
      color_strings <- paste(atlas$cmap[[rgb_cols[1]]], 
                           atlas$cmap[[rgb_cols[2]]], 
                           atlas$cmap[[rgb_cols[3]]], sep = "-")
      
      # Most regions should have unique colors (allow some duplicates)
      duplicate_ratio <- sum(duplicated(color_strings)) / length(color_strings)
      expect_lt(duplicate_ratio, 0.2)  # Less than 20% duplicates
    }
  }
})
</file>

<file path="tests/testthat/test-roi-operations.R">
test_that("reduce_atlas handles various data types and edge cases correctly", {
  skip_on_cran()
  
  # Load test atlas
  atlas <- tryCatch({
    get_schaefer_atlas(parcels = "100", networks = "7", resolution = "2")
  }, error = function(e) {
    skip("Failed to download Schaefer atlas")
  })
  
  # Create test data matching atlas dimensions
  atlas_dims <- dim(atlas$atlas)
  atlas_space <- neuroim2::space(atlas$atlas)
  
  # Test 1: Basic 3D data reduction
  # Create random data with known properties
  set.seed(123)
  test_data_3d <- neuroim2::NeuroVol(
    rnorm(prod(atlas_dims), mean = 10, sd = 2),
    space = atlas_space
  )
  
  # Test mean reduction
  result_mean <- reduce_atlas(atlas, test_data_3d, mean)
  
  # Critical checks - default is long format for NeuroVol
  expect_true(inherits(result_mean, "tbl_df"))
  expect_equal(nrow(result_mean), 100)  # Should have one row per region
  expect_true(all(c("region", "value") %in% names(result_mean)))
  
  # Values should be reasonable (around mean=10)
  expect_true(all(result_mean$value > 5 & result_mean$value < 15))
  expect_equal(length(unique(result_mean$region)), 100)
  
  # Test with custom function that tracks calls
  call_count <- 0
  custom_func <- function(x, ...) {
    call_count <<- call_count + 1
    median(x, na.rm = TRUE)
  }
  
  result_custom <- reduce_atlas(atlas, test_data_3d, custom_func)
  expect_equal(call_count, 100)  # Should be called once per region
  
  # Test 2: 4D time series data
  # Skip NeuroVec tests due to creation issues
  skip("NeuroVec creation issue - skipping 4D tests")
  
  # Test 3: Edge cases and error conditions
  # Empty region handling - create data where one region might be empty
  sparse_data <- neuroim2::NeuroVol(
    numeric(prod(atlas_dims)),  # All zeros
    space = atlas_space
  )
  
  # Set values in the middle of the brain where regions actually exist
  # Use coordinates around the median brain location
  sparse_data[40:50, 50:60, 40:50] <- 1
  
  # Default is long format for NeuroVol
  result_sparse <- reduce_atlas(atlas, sparse_data, sum)
  
  # Most regions should have sum = 0
  expect_true(sum(result_sparse$value == 0) > 80)  # Allow for more non-zero regions
  # At least some regions should have non-zero values
  expect_true(any(result_sparse$value > 0))
  
  # Test error handling
  # Wrong space
  wrong_space <- neuroim2::NeuroSpace(
    dim = c(50, 50, 50),
    spacing = c(3, 3, 3),
    origin = c(0, 0, 0)
  )
  wrong_data <- neuroim2::NeuroVol(
    rnorm(50^3),
    space = wrong_space
  )
  
  expect_error(reduce_atlas(atlas, wrong_data, mean),
               "dimension|space|compatible")
  
  # Non-function stat_func
  expect_error(reduce_atlas(atlas, test_data_3d, "not_a_function"),
               "'stat_func' must be a function")
  
  # Test with NA handling
  na_data <- test_data_3d
  # For ClusteredNeuroVol, we need to find where region 1 is
  if (inherits(atlas$atlas, "ClusteredNeuroVol")) {
    # Get dense representation to find region 1
    atlas_dense <- neuroim2::as.dense(atlas$atlas)
    # Create a copy of the data and set NA where region 1 is
    na_data_vals <- na_data[,,]
    na_data_vals[atlas_dense == 1] <- NA
    na_data <- neuroim2::NeuroVol(na_data_vals, space = neuroim2::space(na_data))
  } else {
    na_data[atlas$atlas == 1] <- NA
  }
  
  result_na <- reduce_atlas(atlas, na_data, mean, na.rm = TRUE)
  # Find the row for region 1 in long format
  region_1_row <- which(result_na$region == "1")
  expect_true(is.na(result_na$value[region_1_row]))
  
  # Other regions should have valid values
  expect_false(all(is.na(result_na$value)))
})

test_that("get_roi extracts regions correctly and handles edge cases", {
  skip_on_cran()
  
  # Load atlas with known regions
  atlas <- get_aseg_atlas()
  
  # Test 1: Single region extraction by label
  hippo <- get_roi(atlas, label = "Hippocampus")
  
  expect_true(is.list(hippo))
  # ASEG atlas has bilateral structures, so Hippocampus returns 2 ROIs (left and right)
  expect_true(length(hippo) >= 1)
  expect_true(all(names(hippo) == "Hippocampus"))
  expect_true(all(sapply(hippo, function(x) inherits(x, "ROIVol"))))
  
  # Verify the ROI contains data
  total_roi_voxels <- sum(sapply(hippo, function(x) nrow(x@coords)))
  expect_true(total_roi_voxels > 0)
  
  # If we have multiple hippocampi, verify they match the atlas IDs
  hippo_ids <- atlas$ids[which(atlas$labels == "Hippocampus")]
  if (length(hippo_ids) > 0) {
    if (inherits(atlas$atlas, "ClusteredNeuroVol")) {
      atlas_hippo_voxels <- sum(atlas$atlas@clusters %in% hippo_ids)
    } else {
      atlas_data <- if (inherits(atlas$atlas, "NeuroVol")) atlas$atlas[,,] else atlas$atlas
      atlas_hippo_voxels <- suppressWarnings(sum(atlas_data %in% hippo_ids))
    }
    # Allow some tolerance for resampling differences
    expect_true(abs(total_roi_voxels - atlas_hippo_voxels) / atlas_hippo_voxels < 0.05 || 
                total_roi_voxels == atlas_hippo_voxels)
  }
  
  # Test 2: Multiple region extraction
  regions <- get_roi(atlas, label = c("Hippocampus", "Amygdala", "Thalamus"))
  
  expect_equal(length(regions), 3)
  expect_equal(sort(names(regions)), sort(c("Hippocampus", "Amygdala", "Thalamus")))
  
  # Each should be a valid ROIVol
  for (roi in regions) {
    expect_true(inherits(roi, "ROIVol"))
    expect_true(length(roi@coords) > 0)
  }
  
  # Test 3: Extraction by ID
  thalamus_ids <- atlas$ids[which(atlas$labels == "Thalamus")]
  thalamus_by_id <- get_roi(atlas, id = thalamus_ids)
  
  # Should get both left and right thalamus
  expect_equal(length(thalamus_by_id), length(thalamus_ids))
  expect_equal(names(thalamus_by_id), as.character(thalamus_ids))
  
  # Should extract the same total voxels as by label
  thalamus_by_label <- get_roi(atlas, label = "Thalamus")
  total_voxels_by_id <- sum(sapply(thalamus_by_id, function(x) nrow(x@coords)))
  total_voxels_by_label <- sum(sapply(thalamus_by_label, function(x) nrow(x@coords)))
  expect_equal(total_voxels_by_id, total_voxels_by_label)
  
  # Test error conditions
  # Non-existent label
  expect_error(get_roi(atlas, label = "NonExistentRegion"),
               "label.*not found|does not exist")
  
  # Both label and id specified
  expect_error(get_roi(atlas, label = "Hippocampus", id = 1),
               "must supply one of.*but not both")
  
  # Invalid ID - should return empty ROIVol
  result <- get_roi(atlas, id = 9999)
  expect_equal(length(result), 1)
  expect_equal(nrow(result[[1]]@coords), 0)
  
  # Test hemisphere filtering (if implemented)
  # Some atlases might support hemisphere-specific extraction
  if ("hemi" %in% names(formals(get_roi.atlas))) {
    left_labels <- atlas$labels[which(atlas$hemi == "left")]
    if (length(left_labels) > 0) {
      left_regions <- get_roi(atlas, label = left_labels)
      expect_true(length(left_regions) > 0)
    }
  }
})

test_that("map_atlas correctly maps values and applies thresholds", {
  skip_on_cran()
  
  # Test with ASEG atlas which doesn't require optional dependencies
  atlas <- tryCatch({
    get_aseg_atlas()
  }, error = function(e) {
    skip("Failed to download ASEG atlas")
  })
  
  # Test 1: Basic value mapping
  set.seed(456)
  n_regions <- length(atlas$orig_labels)
  test_values <- rnorm(n_regions, mean = 0, sd = 1)
  
  mapped <- map_atlas(atlas, vals = test_values, thresh = c(0, Inf))
  
  expect_true(inherits(mapped, "tbl_df"))
  # For non-ggseg atlases, we get exactly as many rows as input values
  expect_equal(nrow(mapped), n_regions)
  expect_true(all(c("statistic", "label") %in% names(mapped)))
  
  # Values should match input exactly for non-ggseg atlases
  expect_equal(mapped$statistic, test_values)
  expect_equal(mapped$label, atlas$orig_labels)
  
  # Test 2: Threshold application
  # Only keep values with absolute value > 1.5
  mapped_thresh <- map_atlas(atlas, vals = test_values, 
                            thresh = c(1.5, Inf), pos = FALSE)
  
  # Check thresholding works - values with |val| <= 1.5 should become NA
  # Get the non-NA statistics
  non_na_thresh <- mapped_thresh$statistic[!is.na(mapped_thresh$statistic)]
  # All remaining values should have |val| > 1.5
  expect_true(all(abs(non_na_thresh) > 1.5))
  
  # Test 3: Positive-only thresholding
  mapped_pos <- map_atlas(atlas, vals = test_values, 
                         thresh = c(1, 2), pos = TRUE)
  
  # Check that only values in range (1, 2] are kept
  non_na_pos <- mapped_pos$statistic[!is.na(mapped_pos$statistic)]
  expect_true(all(non_na_pos > 1 & non_na_pos <= 2))
  
  # Test edge cases
  # Wrong number of values
  expect_error(map_atlas(atlas, vals = rnorm(50), thresh = c(0, 0)))
  
  # Special values
  special_vals <- test_values
  special_vals[1] <- Inf
  special_vals[2] <- -Inf
  special_vals[3] <- NA
  special_vals[4] <- NaN
  
  mapped_special <- map_atlas(atlas, vals = special_vals, thresh = c(0, 0))
  
  # Should handle special values gracefully
  expect_true(is.na(mapped_special$statistic[1]) || 
              mapped_special$statistic[1] == Inf)
  expect_true(is.na(mapped_special$statistic[2]) || 
              mapped_special$statistic[2] == -Inf)
  expect_true(is.na(mapped_special$statistic[3]))
  expect_true(is.na(mapped_special$statistic[4]))
  
  # Skip Glasser test as it requires ggsegGlasser
  # Test with Glasser atlas would go here but requires optional dependency
})
</file>

<file path="tests/testthat/test-space-transforms.R">
test_that("atlas resampling to TemplateFlow spaces maintains integrity", {
  skip_on_cran()
  reticulate::py_config()
  skip_if_not(reticulate::py_available(initialize = FALSE),
              "Python not available")
  skip_if_not(reticulate::py_module_available("templateflow"),
              "templateflow not available")

  # Test 1: Resample atlas to TemplateFlow space string
  atlas <- get_schaefer_atlas(parcels = "100", networks = "7", resolution = "2")

  # Test resampling to MNI space (string identifier)
  atlas_mni <- tryCatch({
    get_schaefer_atlas(parcels = "100", networks = "7",
                      outspace = "MNI152NLin2009cAsym")
  }, error = function(e) {
    skip(paste("TemplateFlow resolution failed:", e$message))
  })

  # Basic structure should be preserved
  expect_true(inherits(atlas_mni, "schaefer"))
  expect_equal(length(atlas_mni$ids), 100)
  expect_equal(length(atlas_mni$labels), 100)

  # Dimensions should match MNI template (typically 193x229x193 for 1mm)
  # But actual dimensions depend on the template resolution
  expect_equal(length(dim(atlas_mni$atlas)), 3)

  # Test 2: Resample with explicit resolution
  atlas_mni_2mm <- tryCatch({
    get_schaefer_atlas(parcels = "100", networks = "7",
                      outspace = list(space = "MNI152NLin2009cAsym",
                                    resolution = "2"))
  }, error = function(e) {
    skip(paste("TemplateFlow resolution failed:", e$message))
  })

  if (!is.null(atlas_mni_2mm)) {
    # Should have smaller dimensions than 1mm
    expect_true(all(dim(atlas_mni_2mm$atlas) < dim(atlas_mni$atlas)))
  }

  # Test 3: Error handling for invalid TemplateFlow spaces
  expect_error(
    get_schaefer_atlas(parcels = "100", networks = "7",
                      outspace = "InvalidSpaceName123"),
    "Failed to resolve.*TemplateFlow|not.*valid.*space"
  )

  # Test with incompatible space object
  tiny_space <- neuroim2::NeuroSpace(
    dim = c(10, 10, 10),  # Too small for meaningful atlas
    spacing = c(10, 10, 10),
    origin = c(0, 0, 0)
    # axes parameter removed - will use default
  )

  atlas_tiny <- get_schaefer_atlas(parcels = "100", networks = "7",
                                  outspace = tiny_space)

  # Should complete but likely lose many regions
  unique_regions <- length(unique(as.vector(atlas_tiny$atlas[atlas_tiny$atlas != 0])))
  expect_true(unique_regions < 100)  # Some regions will be lost
})

test_that("dilate_atlas handles masks correctly and preserves label integrity", {
  skip_on_cran()

  # Load atlas
  atlas <- get_aseg_atlas()

  # Test 1: Dilation with explicit mask
  # Create a restrictive mask (smaller than full brain)
  atlas_vol <- atlas$atlas
  full_mask <- as.logical(atlas_vol != 0)

  # Create mask that excludes some boundary voxels
  restrictive_mask <- full_mask
  dims <- dim(atlas_vol)
  # Zero out edges
  restrictive_mask[c(1:5, (dims[1]-4):dims[1]), , ] <- FALSE
  restrictive_mask[, c(1:5, (dims[2]-4):dims[2]), ] <- FALSE
  restrictive_mask[, , c(1:5, (dims[3]-4):dims[3])] <- FALSE

  restrictive_mask_vol <- neuroim2::NeuroVol(
    as.numeric(restrictive_mask),
    space = neuroim2::space(atlas_vol)
  )

  dilated <- dilate_atlas(atlas, mask = restrictive_mask_vol,
                         radius = 2, maxn = 10)

  # Check that dilation occurred
  original_voxels <- sum(atlas_vol != 0)
  dilated_voxels <- sum(dilated$atlas != 0)
  expect_true(dilated_voxels >= original_voxels)

  # Check that dilation respected the mask
  dilated_outside_mask <- sum(dilated$atlas != 0 & !restrictive_mask)
  expect_equal(dilated_outside_mask, 0)

  # Test 2: Label preservation during dilation
  # No new labels should be introduced
  original_labels <- sort(unique(as.vector(atlas_vol[atlas_vol != 0])))
  dilated_labels <- sort(unique(as.vector(dilated$atlas[dilated$atlas != 0])))
  expect_true(all(dilated_labels %in% original_labels))

  # If original atlas had a label_map, it should be preserved
  if (inherits(atlas$atlas, "ClusteredNeuroVol") && !is.null(atlas$atlas@label_map)) {
    expect_equal(dilated$atlas@label_map, atlas$atlas@label_map)
  }

  # Test 3: Edge cases
  # Very large radius (should be limited by mask)
  dilated_large <- dilate_atlas(atlas, mask = restrictive_mask_vol,
                               radius = 50, maxn = 100)

  # Still shouldn't exceed mask
  dilated_outside <- sum(dilated_large$atlas != 0 & !restrictive_mask)
  expect_equal(dilated_outside, 0)

  # Empty dilation (mask excludes all potential dilation targets)
  # Create mask that perfectly matches current atlas
  exact_mask <- neuroim2::NeuroVol(
    as.numeric(atlas_vol != 0),
    space = neuroim2::space(atlas_vol)
  )

  dilated_none <- dilate_atlas(atlas, mask = exact_mask,
                              radius = 5, maxn = 50)

  # Should return unchanged atlas
  expect_equal(sum(dilated_none$atlas != 0), sum(atlas_vol != 0))
  expect_equal(class(dilated_none), class(atlas))

  # Test with TemplateFlow mask string (if available)
  if (reticulate::py_available(initialize = FALSE) &&
      reticulate::py_module_available("templateflow")) {
    dilated_tf <- tryCatch({
      dilate_atlas(atlas, mask = "MNI152NLin2009cAsym",
                  radius = 1, maxn = 10)
    }, error = function(e) {
      # Skip if TemplateFlow fails
      NULL
    })

    if (!is.null(dilated_tf)) {
      expect_true(inherits(dilated_tf, "atlas"))
      expect_true(sum(dilated_tf$atlas != 0) >= sum(atlas_vol != 0))
    }
  }
})

test_that("cross-atlas operations maintain consistency", {
  skip_on_cran()

  # Test operations between different atlas types
  # Load different atlases
  aseg <- get_aseg_atlas()

  # Get a Schaefer atlas and resample to match ASEG space
  schaefer_orig <- get_schaefer_atlas(parcels = "100", networks = "7")
  
  # Check if dimensions match
  if (!all(dim(aseg$atlas) == dim(schaefer_orig$atlas))) {
    # Need to resample Schaefer to ASEG space
    # For ClusteredNeuroVol, we can't resample directly
    if (inherits(schaefer_orig$atlas, "ClusteredNeuroVol")) {
      skip("Cannot resample ClusteredNeuroVol - skipping cross-atlas test")
    }
    schaefer_resampled <- resample(schaefer_orig$atlas, 
                                   neuroim2::space(aseg$atlas))
    
    # Create new atlas object with resampled data
    schaefer <- list(
      name = schaefer_orig$name,
      atlas = schaefer_resampled,
      cmap = schaefer_orig$cmap,
      ids = schaefer_orig$ids,
      labels = schaefer_orig$labels,
      orig_labels = schaefer_orig$orig_labels,
      hemi = schaefer_orig$hemi,
      network = schaefer_orig$network
    )
    class(schaefer) <- class(schaefer_orig)
  } else {
    schaefer <- schaefer_orig
  }

  # Test 1: Merge cortical and subcortical
  merged <- merge_atlases(aseg, schaefer)

  # Total regions should be sum of both
  expect_equal(length(merged$ids),
               length(aseg$ids) + length(schaefer$ids))

  # Check spatial overlap (subcortical and cortical should not overlap)
  aseg_mask <- as.logical(as.vector(aseg$atlas != 0))
  schaefer_mask <- as.logical(as.vector(schaefer$atlas != 0))
  overlap <- sum(aseg_mask & schaefer_mask)

  # Some overlap is expected at boundaries, but should be minimal
  overlap_percent <- overlap / sum(aseg_mask) * 100
  expect_true(overlap_percent < 10)  # Less than 10% overlap

  # Test 2: Create test data and reduce with merged atlas
  test_data <- neuroim2::NeuroVol(
    rnorm(prod(dim(merged$atlas))),
    space = neuroim2::space(merged$atlas)
  )

  reduced <- reduce_atlas(merged, test_data, mean)

  # Should have values for regions that actually exist in the merged volume
  # Note: After resampling, some regions might have no voxels
  # Get actual regions in the merged atlas
  if (inherits(merged$atlas, "ClusteredNeuroVol")) {
    actual_regions <- unique(merged$atlas@clusters)
  } else {
    actual_regions <- unique(as.vector(merged$atlas[merged$atlas != 0]))
  }
  
  expect_equal(nrow(reduced), length(actual_regions))

  # Test 3: Map values back to merged atlas
  # Note: map_atlas expects values for ALL regions in the atlas metadata,
  # even if some don't exist in the actual volume after resampling
  test_vals <- rnorm(length(merged$orig_labels))
  mapped <- map_atlas(merged, vals = test_vals, thresh = c(0, 0))

  expect_equal(nrow(mapped), length(merged$orig_labels))

  # Hemisphere information should be preserved from both atlases
  hemi_table <- table(merged$hemi, useNA = "always")
  expect_true("left" %in% names(hemi_table) || any(merged$hemi == "left", na.rm = TRUE))
  expect_true("right" %in% names(hemi_table) || any(merged$hemi == "right", na.rm = TRUE))

  # ASEG might have some bilateral/midline structures
  na_count <- sum(is.na(merged$hemi))
  expect_equal(na_count, sum(is.na(aseg$hemi)))
})
</file>

<file path="tests/testthat/test-templateflow-advanced.R">
test_that("TemplateFlow integration handles edge cases and vectorized operations correctly", {
  skip_on_cran()
  skip_if_not(reticulate::py_available(initialize = FALSE), 
              "Python not available")
  skip_if_not(reticulate::py_module_available("templateflow"),
              "templateflow not available")
  
  # Test 1: Cache management functions
  cache_path <- show_templateflow_cache_path()
  expect_true(is.character(cache_path))
  expect_true(nchar(cache_path) > 0)
  
  # Should contain "templateflow" in path
  expect_true(grepl("templateflow", cache_path, ignore.case = TRUE))
  
  # Test 2: Vectorized template fetching
  # Get multiple resolutions at once
  multi_res <- tryCatch({
    get_template(
      space = "MNI152NLin2009cAsym",
      suffix = "T1w",
      resolution = c("1", "2"),
      path_only = TRUE
    )
  }, error = function(e) NULL)
  
  if (!is.null(multi_res)) {
    expect_true(is.list(multi_res))
    expect_equal(names(multi_res), c("1", "2"))
    expect_true(all(sapply(multi_res, is.character)))
    
    # Paths should differ by resolution
    expect_false(multi_res[["1"]] == multi_res[["2"]])
    expect_true(grepl("res-01", multi_res[["1"]]) || grepl("res-1", multi_res[["1"]]))
    expect_true(grepl("res-02", multi_res[["2"]]) || grepl("res-2", multi_res[["2"]]))
  }
  
  # Test 3: Variant parameter handling
  variants <- tryCatch({
    get_template(
      space = "MNI152NLin2009cAsym",
      variant = c("brain", "mask"),
      resolution = "2",
      path_only = TRUE
    )
  }, error = function(e) NULL)
  
  if (!is.null(variants)) {
    expect_equal(names(variants), c("brain", "mask"))
    expect_true(grepl("T1w", variants[["brain"]]))
    expect_true(grepl("mask", variants[["mask"]]))
  }
  
  # Test 4: Error handling for invalid spaces
  expect_error(
    get_template(space = "NonExistentSpace123XYZ"),
    "not.*found|invalid.*space|does not exist"
  )
  
  # Test 5: Surface template retrieval
  surf_template <- tryCatch({
    get_surface_template(
      template_id = "fsLR",
      surface_type = "pial",
      hemi = "L",
      density = "32k",
      path_only = TRUE
    )
  }, error = function(e) NULL)
  
  if (!is.null(surf_template)) {
    expect_true(is.character(surf_template))
    expect_true(grepl("fsLR", surf_template))
    expect_true(grepl("hemi-L", surf_template))
    expect_true(grepl("32k", surf_template))
  }
  
  # Test 6: Volume template with different modalities
  # Test just T1w to reduce network operations
  vol <- tryCatch({
    get_volume_template(
      template = "MNI152NLin2009cAsym",
      type = "T1w",
      resolution = "2",
      path_only = TRUE
    )
  }, error = function(e) NULL)
  
  if (!is.null(vol)) {
    expect_true(grepl("T1w", vol))
  }
  
  # Test 7: .check_templateflow_connectivity
  connectivity <- .check_templateflow_connectivity()
  expect_true(is.logical(connectivity))
  
  # Test 8: Memoization behavior
  # First call
  time1 <- system.time({
    path1 <- tryCatch({
      get_template(space = "MNI152NLin2009cAsym", suffix = "T1w", 
                  resolution = "2", path_only = TRUE)
    }, error = function(e) NULL)
  })
  
  # Second call (should be memoized and faster)
  time2 <- system.time({
    path2 <- tryCatch({
      get_template(space = "MNI152NLin2009cAsym", suffix = "T1w", 
                  resolution = "2", path_only = TRUE)
    }, error = function(e) NULL)
  })
  
  if (!is.null(path1) && !is.null(path2)) {
    expect_equal(path1, path2)
    # Second call should be faster (memoized)
    # Using 0.9 instead of 0.5 to allow for system variability
    expect_lt(time2["elapsed"], time1["elapsed"] * 0.9)
  }
})

test_that("Convenience functions (sy_*) work correctly with all parameters", {
  skip_on_cran()
  
  # Test 1: Basic convenience function calls
  convenience_funcs <- list(
    sy_100_7 = c(100, 7),
    sy_200_7 = c(200, 7),
    sy_100_17 = c(100, 17),
    sy_200_17 = c(200, 17)
  )
  
  # Skip download tests to avoid network delays
  # Just test that functions exist
  for (func_name in names(convenience_funcs)[1]) {
    expect_true(exists(func_name, envir = asNamespace("neuroatlas")))
  }
  
  # Test 2: Parameter passing through convenience functions
  # Skip if we can't create a test space
  test_space <- tryCatch({
    neuroim2::NeuroSpace(
      dim = c(50, 50, 50),
      spacing = c(4, 4, 4),
      origin = c(-100, -100, -100)
    )
  }, error = function(e) NULL)
  
  if (!is.null(test_space)) {
    atlas_custom <- tryCatch({
      sy_100_7(resolution = "2", outspace = test_space, smooth = TRUE)
    }, error = function(e) NULL)
  } else {
    atlas_custom <- NULL
  }
  
  if (!is.null(atlas_custom)) {
    expect_equal(dim(atlas_custom$atlas), c(50, 50, 50))
    expect_true(inherits(atlas_custom, "schaefer"))
  }
  
  # Test 3: All convenience functions exist and are properly defined
  all_sy_funcs <- c(
    "sy_100_7", "sy_100_17", "sy_200_7", "sy_200_17",
    "sy_300_7", "sy_300_17", "sy_400_7", "sy_400_17",
    "sy_500_7", "sy_500_17", "sy_600_7", "sy_600_17",
    "sy_800_7", "sy_800_17", "sy_1000_7", "sy_1000_17"
  )
  
  for (func_name in all_sy_funcs) {
    expect_true(exists(func_name, envir = asNamespace("neuroatlas")))
    func <- get(func_name, envir = asNamespace("neuroatlas"))
    expect_true(is.function(func))
    
    # Check function signature
    args <- names(formals(func))
    expect_true(all(c("resolution", "outspace", "smooth", "use_cache") %in% args))
  }
})

test_that("Print methods provide accurate and formatted output", {
  skip_on_cran()
  
  # Test 1: print.atlas base method
  aseg <- tryCatch(get_aseg_atlas(), error = function(e) NULL)
  if (!is.null(aseg)) {
    output <- capture.output(print(aseg))
    
    # Should contain key information
    expect_true(any(grepl("Atlas Summary", output)))
    expect_true(any(grepl("Name:", output)))
    expect_true(any(grepl("Dimensions:", output)))
    expect_true(any(grepl("Regions:", output)))
    expect_true(any(grepl("hemisphere", output, ignore.case = TRUE)))
  }
  
  # Test 2: print.schaefer method
  schaefer <- tryCatch(get_schaefer_atlas(parcels = "100", networks = "7"),
                      error = function(e) NULL)
  if (!is.null(schaefer)) {
    output <- capture.output(print(schaefer))
    
    # Schaefer-specific information
    expect_true(any(grepl("Schaefer", output)))
    expect_true(any(grepl("Networks:", output)))
    expect_true(any(grepl("7", output)))  # Network count
  }
  
  # Test 3: print.glasser method
  glasser <- tryCatch(get_glasser_atlas(), error = function(e) NULL)
  if (!is.null(glasser)) {
    output <- capture.output(print(glasser))
    
    # Glasser-specific information
    expect_true(any(grepl("Glasser", output)))
    expect_true(any(grepl("Multi-Modal Parcellation", output, ignore.case = TRUE)))
    expect_true(any(grepl("360", output)))  # Region count
    expect_true(any(grepl("Example Regions", output)))
  }
  
  # Test 4: CLI formatting elements
  # Check for color/formatting codes (if cli/crayon are active)
  if (!is.null(glasser)) {
    raw_output <- capture.output(print(glasser), type = "message")
    # Look for ANSI codes or special characters used by cli
    # This is environment-dependent, so we just check structure
    expect_true(length(output) > 5)  # Should have multiple lines
  }
})
</file>

<file path="R/atlas_methods.R">
#' @rdname map_atlas
#' @param pos Logical. If `TRUE`, values are thresholded using raw values;
#'   otherwise the absolute values are used.
#' @export
map_atlas.atlas <- function(x, vals, thresh = c(0, 0), pos = FALSE, ...) {
  if (inherits(x, "schaefer")) {
    # Check if ggsegSchaefer is available before calling map_to_schaefer
    if (!requireNamespace("ggsegSchaefer", quietly = TRUE)) {
      stop("Package 'ggsegSchaefer' is required for mapping Schaefer atlases but is not installed.\n",
           "To install it, run:\n",
           "  remotes::install_github('LCBC-UiO/ggsegSchaefer')",
           call. = FALSE)
    }
    return(map_to_schaefer(x, vals, thresh = thresh, pos = pos))
  }

  stopifnot(length(vals) == length(x$orig_labels))
  fun <- if (pos) identity else abs
  
  # Handle different atlas structures
  result <- tibble::tibble(
    statistic = ifelse(fun(vals) <= thresh[1] | fun(vals) > thresh[2], NA, vals),
    label = x$orig_labels
  )
  
  # Add optional columns if they exist
  if (!is.null(x$labels)) {
    result$region <- x$labels
  }
  if (!is.null(x$hemi)) {
    result$hemi <- x$hemi
  }
  
  result
}

#' @rdname plot-methods
#' @export
plot.atlas <- function(x, y, ...) {
  if (inherits(x, "schaefer")) {
    return(ggseg_schaefer(x, ...))
  }
  stop("plot method not implemented for objects of class '", class(x)[1], "'")
}
</file>

<file path="R/ggschaefer.R">
# Global variables to avoid R CMD check NOTEs
utils::globalVariables(c("hemi", "orig_label", "hemi.x", "hemi.y", "x", "y", "group", "fill", "region", "label"))

#' Get ggseg-Compatible Schaefer Atlas
#'
#' @description
#' Retrieves the appropriate Schaefer atlas data structure compatible with ggseg
#' visualization based on the atlas name parameters.
#'
#' @param atlas An atlas object containing Schaefer parcellation information.
#'   The name should follow the format "schaeferN_M" where:
#'   \itemize{
#'     \item N is the number of networks (7 or 17)
#'     \item M is the number of parcels (100 to 1000 in steps of 100)
#'   }
#'
#' @return A ggseg brain atlas object for visualization
#'
#' @details
#' The function extracts the network count and parcel count from the atlas name
#' and returns the corresponding ggseg-compatible atlas object. Supports Schaefer
#' atlases with 7 or 17 networks and 100-1000 parcels (in steps of 100).
#'
#' @importFrom stringr str_extract_all
#' @export
get_ggseg_atlas <- function(atlas) {
  # Check if ggsegSchaefer is available
  if (!requireNamespace("ggsegSchaefer", quietly = TRUE)) {
    stop("Package 'ggsegSchaefer' is required for this function but is not installed.\n",
         "To install it, run:\n",
         "  remotes::install_github('LCBC-UiO/ggsegSchaefer')\n",
         "or use the ggseg r-universe:\n",
         "  options(repos = c(ggseg = 'https://ggseg.r-universe.dev',\n",
         "                    CRAN = 'https://cloud.r-project.org'))\n",
         "  install.packages('ggsegSchaefer')",
         call. = FALSE)
  }
  
  # Extract numbers from the atlas name (e.g., "Schaefer-100-7networks")
  matches <- stringr::str_extract_all(atlas$name, "\\d+")
  atlas_num <- unlist(matches)
  
  # Atlas name format is "Schaefer-{parcels}-{networks}networks"
  # So atlas_num[1] is parcels, atlas_num[2] is networks
  parcels <- as.numeric(atlas_num[1])
  networks <- as.numeric(atlas_num[2])
  
  # Check for valid inputs
  if ((parcels %in% seq(100, 1000, 100)) && (networks %in% c(7, 17))) {
    atlas_string <- paste0("schaefer", networks, "_", parcels)
    # Use :: operator to access the object from ggsegSchaefer
    atlas_obj <- tryCatch({
      # Try multiple ways to access the object
      if (exists(atlas_string, envir = asNamespace("ggsegSchaefer"))) {
        get(atlas_string, envir = asNamespace("ggsegSchaefer"))
      } else if (exists(atlas_string, envir = as.environment("package:ggsegSchaefer"))) {
        get(atlas_string, envir = as.environment("package:ggsegSchaefer"))
      } else {
        # Try using :: operator directly
        eval(parse(text = paste0("ggsegSchaefer::", atlas_string)))
      }
    }, error = function(e) {
      stop("Failed to load atlas '", atlas_string, "' from ggsegSchaefer: ", e$message,
           call. = FALSE)
    })
    return(atlas_obj)
  } else {
    stop("Invalid atlas name. Must be Schaefer atlas with 7 or 17 networks and 100-1000 parcels.")
  }
}

#' Map Values to Schaefer Atlas Format
#'
#' @description
#' Converts values associated with atlas regions into a format suitable for
#' visualization with the Schaefer atlas in ggseg.
#'
#' @param atlas An atlas object containing Schaefer parcellation information
#' @param vals Numeric vector of values to map to atlas regions
#' @param thresh Numeric vector of length 2 specifying (min, max) thresholds.
#'   Values outside this range will be set to NA. Default: c(0,0)
#' @param pos Logical. If TRUE, uses raw values; if FALSE, uses absolute values
#'   for thresholding. Default: FALSE
#'
#' @return A tibble with mapped values suitable for ggseg visualization
#'
#' @importFrom assertthat assert_that
#' @importFrom dplyr mutate left_join filter .data select coalesce
#' @importFrom tibble as_tibble
#' @importFrom ggseg as_brain_atlas
#' @export
map_to_schaefer <- function(atlas, vals, thresh=c(0,0), pos=FALSE) {
  assert_that(length(vals) == length(atlas$orig_labels),
              msg="Length of vals must match number of atlas regions")
  
  fun <- if (pos) identity else abs
  
  ggatl <- get_ggseg_atlas(atlas)
  
  # Create a mapping between our labels and ggseg labels
  # Our labels are like "LH_Vis_1", ggseg labels are like "lh_7Networks_LH_Vis_1"
  networks_str <- if (grepl("7networks", atlas$name, ignore.case = TRUE)) "7Networks_" else "17Networks_"
  
  ret <- tibble(
    statistic = vals,
    orig_label = atlas$orig_labels,
    hemi = atlas$hemi
  ) %>%
    mutate(
      # Convert our labels to match ggseg format
      ggseg_label = paste0(
        ifelse(hemi == "left", "lh_", "rh_"),
        networks_str,
        orig_label
      )
    )
  
  # Join with ggseg atlas data
  rboth <- ggatl$data %>%
    left_join(ret, by = c("label" = "ggseg_label")) %>%
    mutate(
      # Preserve original hemi column from ggseg data
      hemi = coalesce(.data$hemi.x, .data$hemi.y),
      statistic = ifelse(
        is.na(.data$statistic) | 
        fun(.data$statistic) <= thresh[1] | 
        fun(.data$statistic) > thresh[2],
        NA_real_, 
        .data$statistic
      )
    ) %>%
    select(-orig_label, -hemi.x, -hemi.y)  # Remove temporary columns
  
  # Return the tibble instead of the brain atlas object
  return(rboth)
}

#' Create Interactive Schaefer Atlas Visualization
#'
#' @description
#' Creates an interactive visualization of the Schaefer atlas using ggseg,
#' with optional value mapping and customizable appearance.
#'
#' @param atlas An atlas object containing Schaefer parcellation information
#' @param vals Numeric vector of values to visualize on the atlas
#' @param thresh Numeric vector of length 2 specifying (min, max) thresholds.
#'   Values outside this range will be set to NA. Default: c(0,0)
#' @param pos Logical. If TRUE, uses raw values; if FALSE, uses absolute values
#'   for thresholding. Default: FALSE
#' @param palette Character string specifying the color palette to use.
#'   Default: "Spectral"
#' @param interactive Logical. If TRUE, creates an interactive plot with tooltips.
#'   Default: TRUE
#' @param lim Numeric vector of length 2 specifying the range for color mapping.
#'   Default: range(vals)
#'
#' @return A ggplot2 object (if interactive=FALSE) or a ggiraph object
#'   (if interactive=TRUE) showing the visualization
#'
#' @examples
#' \dontrun{
#' # Load Schaefer atlas
#' atlas <- get_schaefer_atlas("7networks", 100)
#'
#' # Create random values for visualization
#' vals <- rnorm(100)
#'
#' # Create interactive plot
#' ggseg_schaefer(atlas, vals)
#'
#' # Create static plot with custom thresholds
#' ggseg_schaefer(atlas, vals, thresh=c(-1, 1), interactive=FALSE)
#' }
#'
#' @importFrom ggplot2 aes scale_fill_distiller ggplot theme_void coord_fixed
#' @importFrom ggseg ggseg
#' @importFrom ggiraph girafe opts_tooltip opts_hover opts_selection geom_polygon_interactive
#' @importFrom scales squish
#' @export
ggseg_schaefer <- function(atlas, vals, thresh=c(0,0), pos=FALSE,
                          palette="Spectral", interactive=TRUE, lim=range(vals)) {
  mapped_data <- map_to_schaefer(atlas, vals, thresh, pos)
  
  # Get the ggseg atlas and update its data
  gatl <- get_ggseg_atlas(atlas)
  gatl$data <- mapped_data
  
  # Check if we're using the forked version with interactive support
  has_interactive_support <- tryCatch({
    # Try to call ggseg with interactive parameter
    args <- list(
      atlas = gatl,
      position = "stacked",
      colour = "gray",
      interactive = interactive,
      guide = TRUE,
      mapping = aes(fill = .data$statistic)
    )
    
    # Add interactive aesthetics if using interactive mode
    if (interactive) {
      args$mapping <- aes(fill = .data$statistic, tooltip = .data$region, data_id = .data$label)
    }
    
    ggobj <- do.call(ggseg::ggseg, args)
    TRUE
  }, error = function(e) {
    # Fallback for CRAN version without interactive parameter
    FALSE
  })
  
  if (!has_interactive_support) {
    # Use CRAN version of ggseg and handle interactivity ourselves
    base_plot <- ggseg::ggseg(
      atlas = gatl,
      position = "stacked",
      colour = "gray",
      guide = TRUE,
      mapping = aes(fill = .data$statistic)
    )
    
    if (interactive) {
      # Create interactive version manually
      # We need to modify the ggplot object to use ggiraph geometries
      ggobj <- .make_ggseg_interactive(base_plot, gatl$data)
    } else {
      ggobj <- base_plot
    }
  } else {
    # Using forked version, ggobj is already created above
    ggobj <- ggobj
  }
  
  # Add color scale
  ggobj <- ggobj +
    scale_fill_distiller(
      palette = palette,
      limits = lim,
      direction = -1,
      oob = scales::squish
    )
  
  # Return the plot (already interactive if forked version was used)
  if (interactive && !has_interactive_support) {
    ggiraph::girafe(
      ggobj = ggobj,
      width_svg = 8,
      height_svg = 6,
      options = list(
        opts_tooltip(
          opacity = .7,
          css = "font-family: Arial, Helvetica, sans-serif;"
        ),
        opts_hover(css = "fill:yellow;"),
        opts_selection(
          css = "fill:red;",
          type = "single",
          only_shiny = FALSE
        )
      )
    )
  } else {
    ggobj
  }
}

#' Convert ggseg plot to interactive
#' @keywords internal
#' @noRd
#' @importFrom ggplot2 ggplot_build ggplot_gtable aes
#' @importFrom ggiraph geom_polygon_interactive
.make_ggseg_interactive <- function(plot, data) {
  # This is a simplified approach - recreate the plot with interactive geoms
  # Extract the plot data
  plot_data <- ggplot_build(plot)$data[[1]]
  
  # Merge with original data to get labels
  if ("group" %in% names(plot_data) && "group" %in% names(data)) {
    plot_data <- merge(plot_data, data, by = "group", all.x = TRUE)
  }
  
  # Create new interactive plot
  ggplot(plot_data, aes(x = .data$x, y = .data$y, group = .data$group)) +
    geom_polygon_interactive(
      aes(fill = .data$fill, tooltip = .data$region, data_id = .data$label),
      colour = "gray"
    ) +
    theme_void() +
    coord_fixed()
}
</file>

<file path="tests/testthat/test-dilation.R">
test_that("dilate_atlas works on Glasser atlas", {
  skip_on_cran()  # Skip on CRAN for demonstration purposes
  
  # Load the Glasser atlas
  gl <- get_glasser_atlas()
  
  # Create a simple mask that's just the atlas itself
  # This tests that dilate_atlas handles the case where there's nothing to dilate
  if (inherits(gl$atlas, "ClusteredNeuroVol")) {
    # Use the mask from the ClusteredNeuroVol
    mask <- gl$atlas@mask
  } else {
    # Create mask from atlas
    mask <- neuroim2::LogicalNeuroVol(gl$atlas > 0, space = neuroim2::space(gl$atlas))
  } 
  # Attempt dilation with small parameters just for testing
  dilated <- dilate_atlas(atlas = gl, mask = mask, radius = 2, maxn = 20)
  
  # Check that the result is an atlas object like the input
  expect_true(inherits(dilated, "atlas"))
  expect_true(inherits(dilated, "glasser"))
  
  # Check that the atlas slot contains a ClusteredNeuroVol
  expect_true(inherits(dilated$atlas, "ClusteredNeuroVol"))
  
  # Check dimensions are preserved
  expect_equal(dim(dilated$atlas), dim(gl$atlas))
})
</file>

<file path="R/aseg_subcort.R">
#' Get the FreeSurfer Subcortical Atlas (ASEG)
#'
#' @description
#' Loads and returns the FreeSurfer subcortical segmentation (ASEG) atlas, which provides
#' probabilistic labels for key subcortical structures in the brain. The atlas includes
#' bilateral structures such as the thalamus, caudate, putamen, and limbic regions,
#' as well as midline structures like the brainstem.
#'
#' @details
#' The ASEG atlas is derived from FreeSurfer's automatic subcortical segmentation
#' algorithm and has been transformed into standard space. Each voxel contains an
#' integer ID corresponding to a specific anatomical structure. The atlas includes
#' major subcortical structures for both hemispheres:
#' \itemize{
#'   \item Bilateral deep gray structures (thalamus, caudate, putamen, pallidum)
#'   \item Limbic structures (hippocampus, amygdala)
#'   \item Ventral structures (nucleus accumbens, ventral diencephalon)
#'   \item Midline structures (brainstem)
#' }
#'
#' @param outspace Optional \code{NeuroSpace} object specifying the desired output space
#'   for resampling the atlas. If NULL (default), returns the atlas in its native space.
#'
#' @return A list with classes 'aseg' and 'atlas' containing:
#' \describe{
#'   \item{atlas}{A \code{NeuroVol} object containing the 3D volume of atlas labels}
#'   \item{cmap}{A data frame with RGB color specifications for each region}
#'   \item{ids}{Integer vector of region IDs present in the atlas}
#'   \item{labels}{Character vector of anatomical labels corresponding to each ID}
#'   \item{hemi}{Character vector indicating hemisphere ('left', 'right', or NA) for each region}
#' }
#'
#' @examples
#' \dontrun{
#' # Load the atlas in native space
#' aseg <- get_aseg_atlas()
#'
#' # View the available region labels
#' aseg$labels
#'
#' # Get the unique region IDs
#' aseg$ids
#' }
#'
#' @references
#' Fischl, B., et al. (2002). Whole brain segmentation: automated labeling of
#' neuroanatomical structures in the human brain. Neuron, 33(3), 341-355.
#'
#' @seealso
#' \code{\link{map_atlas}} for mapping values onto atlas regions
#' \code{\link{get_roi}} for extracting specific regions of interest
#'
#' @importFrom neuroim2 read_vol
#' @importFrom tibble tribble
#' @export
get_aseg_atlas <- function(outspace=NULL) {
  fname <- system.file("extdata/atlas_aparc_aseg_prob33.nii.gz", package="neuroatlas")
  atlas <- neuroim2::read_vol(fname)

  if (!is.null(outspace)) {
    atlas <- resample(atlas, outspace)
  }

  ids <- sort(unique(as.vector(atlas))[-1])
  labels <- c(
    "Thalamus",
    "Caudate",
    "Putamen",
    "Pallidum",
    "Brainstem",
    "Hippocampus",
    "Amygdala",
    "Accumbens",
    "VentralDC",
    "Thalamus",
    "Caudate",
    "Putamen",
    "Pallidum",
    "Hippocampus",
    "Amygdala",
    "Accumbens",
    "VentralDC")

  hemi=c(rep("left", 4), NA, rep("left", 3), NA, rep("right", 8))
  cmap <- tibble::tribble(
    ~red, ~green, ~blue,
    0,   118, 14,
    122, 186, 220,
    236, 13,  176,
    12,  48,  255,
    119, 159, 176,
    220, 216, 20,
    220, 216, 20,
    255, 165, 0,
    165, 42,  42,
    0,   118, 14,
    122, 186, 220,
    236, 13,  176,
    13,  48,  255,
    220, 216, 20,
    103, 255, 255,
    255, 165, 0,
    165, 42,  42)

  ret <- list(
    name="ASEG",
    atlas=atlas,
    cmap=cmap,
    ids=ids,
    labels=labels,
    orig_labels=labels,
    hemi=hemi,
    network=NULL)

  class(ret) <- c("aseg", "atlas")
  ret
}
</file>

<file path="R/zzz.R">
#' @import reticulate
.onLoad <- function(libname, pkgname) {
  # Set the RETICULATE_PYTHON_ENV environment variable to use a persistent environment
  # This prevents reticulate from creating ephemeral environments each session
  # Only set if the environment actually exists
  if (Sys.getenv("RETICULATE_PYTHON_ENV") == "") {
    neuroatlas_env <- file.path(tools::R_user_dir("neuroatlas", "config"), "r-reticulate")
    if (dir.exists(neuroatlas_env)) {
      Sys.setenv(RETICULATE_PYTHON_ENV = neuroatlas_env)
    }
  }
  
  # Check if this is first time using neuroatlas with TemplateFlow
  neuroatlas_env <- file.path(tools::R_user_dir("neuroatlas", "config"), "r-reticulate")
  first_time_file <- file.path(tools::R_user_dir("neuroatlas", "config"), ".first_time_complete")
  
  if (!file.exists(first_time_file) && !dir.exists(neuroatlas_env)) {
    packageStartupMessage(
      "\nWelcome to neuroatlas!\n",
      "To use TemplateFlow features, you'll need to run:\n",
      "  neuroatlas::install_templateflow()\n",
      "This only needs to be done once and will create a persistent environment.\n",
      "For more info, run: neuroatlas::check_templateflow()\n"
    )
  }
}

#' Install Templateflow Python package
#'
#' Installs the Python packages `scipy` and `templateflow` into a persistent
#' virtual environment. This ensures the packages remain available across R sessions.
#'
#' @param method Installation method. Options are "auto" (default), "virtualenv", or "conda".
#'   Using "virtualenv" is recommended for persistent installations.
#' @param conda Path to a conda executable or \code{"auto"} to let
#'   \code{reticulate} locate one. Only used if method = "conda".
#' @param envname Name of the virtual environment. Defaults to "r-neuroatlas" for persistence.
#' @param force_reinstall Logical. If TRUE, forces reinstallation even if packages exist.
#'
#' @return Invisible \code{NULL} indicating success.
#'
#' @details
#' This function creates a persistent Python environment specifically for neuroatlas,
#' preventing the need to reinstall TemplateFlow in each R session. The environment
#' is stored in a user-specific directory that persists across sessions.
#'
#' @examples
#' \donttest{
#' # Install with default settings (recommended)
#' install_templateflow()
#' 
#' # Force reinstallation
#' install_templateflow(force_reinstall = TRUE)
#' }
#' @export
install_templateflow <- function(method = "auto", conda = "auto", 
                               envname = NULL, force_reinstall = FALSE) {
  
  # Determine environment name and path
  if (is.null(envname)) {
    env_path <- file.path(tools::R_user_dir("neuroatlas", "config"), "r-reticulate")
  } else {
    env_path <- envname
  }
  
  # Force virtualenv method if we're in an ephemeral environment
  current_env <- tryCatch(reticulate::py_config()$virtualenv, error = function(e) NULL)
  if (!is.null(current_env) && grepl("r-reticulate-ephemeral", current_env)) {
    message("Note: Currently using an ephemeral Python environment. ",
            "Installing to persistent environment at: ", env_path)
    if (method == "auto") {
      method <- "virtualenv"
      message("Switching to virtualenv method for persistent installation.")
    }
  }
  
  # Check if packages already installed (unless forcing reinstall)
  if (!force_reinstall && method != "conda") {
    # Try to use the environment and check for packages
    tryCatch({
      reticulate::use_virtualenv(env_path, required = FALSE)
      if (reticulate::py_module_available("templateflow") && 
          reticulate::py_module_available("scipy")) {
        message("TemplateFlow and scipy are already installed in: ", env_path)
        return(invisible(NULL))
      }
    }, error = function(e) {
      # Environment doesn't exist or packages not found, continue with installation
    })
  }
  
  # Create virtual environment if it doesn't exist
  if (method == "virtualenv" || (method == "auto" && is.null(reticulate::conda_binary()))) {
    if (!dir.exists(env_path)) {
      # Ensure parent directory exists
      parent_dir <- dirname(env_path)
      if (!dir.exists(parent_dir)) {
        dir.create(parent_dir, recursive = TRUE, showWarnings = FALSE)
      }
      message("Creating persistent virtual environment at: ", env_path)
      reticulate::virtualenv_create(envname = env_path)
    }
    
    message("Installing packages to persistent environment: ", env_path)
    reticulate::virtualenv_install(envname = env_path, 
                                 packages = c("scipy", "templateflow"),
                                 ignore_installed = force_reinstall)
  } else {
    # Use standard py_install for conda or when virtualenv not available
    message("Installing packages using method: ", method)
    reticulate::py_install(c("scipy", "templateflow"), 
                         method = method, 
                         conda = conda,
                         pip = TRUE,
                         envname = if (!is.null(envname)) envname else NULL)
  }
  
  message("Installation complete. Packages installed to: ", 
          if (method == "virtualenv" || (method == "auto" && is.null(reticulate::conda_binary()))) 
            env_path else "default Python environment")
  
  # Mark first time setup as complete
  config_dir <- tools::R_user_dir("neuroatlas", "config")
  first_time_file <- file.path(config_dir, ".first_time_complete")
  if (!file.exists(first_time_file)) {
    tryCatch({
      # Ensure directory exists before writing file
      if (!dir.exists(config_dir)) {
        dir.create(config_dir, recursive = TRUE, showWarnings = FALSE)
      }
      writeLines("", first_time_file)
    }, error = function(e) {
      # Ignore errors writing marker file
    })
  }
  
  invisible(NULL)
}

#' Check TemplateFlow Installation Status
#'
#' Checks whether TemplateFlow and required dependencies are properly installed
#' and provides information about the Python environment being used.
#'
#' @return Invisible NULL. Prints status information to the console.
#' @export
#' @examples
#' \donttest{
#' check_templateflow()
#' }
check_templateflow <- function() {
  cat("=== TemplateFlow Installation Status ===\n\n")
  
  # Check Python availability
  if (!reticulate::py_available(initialize = FALSE)) {
    cat("Python: NOT AVAILABLE\n")
    cat("  Run: reticulate::install_python()\n\n")
    return(invisible(NULL))
  }
  
  cat("Python: Available\n")
  
  # Check Python configuration
  py_config <- tryCatch(reticulate::py_config(), error = function(e) NULL)
  if (!is.null(py_config)) {
    if (!is.null(py_config$version)) {
      if (is.list(py_config$version)) {
        cat("Python version:", paste(py_config$version, collapse=" "), "\n")
      } else {
        cat("Python version:", py_config$version, "\n")
      }
    }
    cat("Python executable:", py_config$python, "\n")
    
    if (!is.null(py_config$virtualenv)) {
      if (grepl("ephemeral", py_config$virtualenv)) {
        cat("Virtual environment: EPHEMERAL (temporary)\n")
        cat("  WARNING: This is a temporary environment!\n")
        cat("  Packages installed here won't persist between sessions.\n")
      } else {
        cat("Virtual environment:", py_config$virtualenv, "\n")
      }
    }
  }
  
  cat("\n")
  
  # Check persistent environment
  neuroatlas_env <- file.path(tools::R_user_dir("neuroatlas", "config"), "r-reticulate")
  if (dir.exists(neuroatlas_env)) {
    cat("Persistent neuroatlas environment: EXISTS\n")
    cat("  Location:", neuroatlas_env, "\n")
  } else {
    cat("Persistent neuroatlas environment: NOT FOUND\n")
    cat("  Would be created at:", neuroatlas_env, "\n")
  }
  
  cat("\n")
  
  # Check module availability
  cat("Module status:\n")
  if (reticulate::py_module_available("scipy")) {
    cat("  scipy: INSTALLED\n")
  } else {
    cat("  scipy: NOT INSTALLED\n")
  }
  
  if (reticulate::py_module_available("templateflow")) {
    cat("  templateflow: INSTALLED\n")
    
    # Try to get version
    tryCatch({
      tf <- reticulate::import("templateflow")
      if (!is.null(tf$`__version__`)) {
        cat("    Version:", tf$`__version__`, "\n")
      }
    }, error = function(e) {
      # Ignore version errors
    })
  } else {
    cat("  templateflow: NOT INSTALLED\n")
  }
  
  cat("\n")
  
  # Check TEMPLATEFLOW_HOME
  tf_home <- Sys.getenv("TEMPLATEFLOW_HOME")
  if (tf_home != "") {
    cat("TEMPLATEFLOW_HOME:", tf_home, "\n")
    if (dir.exists(tf_home)) {
      cat("  Status: Directory exists\n")
    } else {
      cat("  Status: Directory does not exist\n")
    }
  } else {
    cat("TEMPLATEFLOW_HOME: Not set\n")
  }
  
  cat("\n")
  
  # Recommendations
  if (!reticulate::py_module_available("templateflow") || 
      !reticulate::py_module_available("scipy")) {
    cat("=== Recommendation ===\n")
    cat("Run: neuroatlas::install_templateflow()\n")
    cat("This will create a persistent environment and install required packages.\n")
  } else if (!is.null(py_config$virtualenv) && grepl("ephemeral", py_config$virtualenv)) {
    cat("=== Recommendation ===\n")
    cat("You're using a temporary environment. To make it persistent:\n")
    cat("Run: neuroatlas::install_templateflow()\n")
  } else {
    cat("=== Status: Ready ===\n")
    cat("TemplateFlow is properly installed and ready to use.\n")
  }
  
  invisible(NULL)
}
</file>

<file path="R/chart.R">
#' Plot Glasser Atlas Values
#'
#' @description
#' Creates an interactive visualization of values mapped onto the Glasser atlas
#' using echarts4r. The visualization shows both hemispheres in lateral and medial
#' views, arranged in a 2x2 grid.
#'
#' @param vals A data frame containing values to plot, must include columns:
#'   \itemize{
#'     \item label: character, matching ggseg Glasser atlas labels (e.g., "lh_L_V1")
#'     \item value: numeric, values to visualize for each region
#'   }
#'   If NULL (default), all regions will be assigned a value of 1
#' @param value_col Character string specifying the name of the column in vals containing
#'   the values to plot. Defaults to "value"
#' @param position Character string specifying layout type. Currently only "dispersed"
#'   is supported (stacked layout is planned for future versions)
#'
#' @return An echarts4r visualization object containing the 2x2 grid of brain views
#'
#' @examples
#' \dontrun{
#' # Basic visualization with uniform coloring
#' plot_glasser()
#'
#' # Create sample data (requires ggsegGlasser package)
#' if (requireNamespace("ggsegGlasser", quietly = TRUE)) {
#'   glasser_atlas <- get("glasser", envir = asNamespace("ggsegGlasser"))
#'   vals <- data.frame(
#'     label = glasser_atlas$data$label,
#'     value = rnorm(nrow(glasser_atlas$data))
#'   )
#'   # Plot the data
#'   plot_glasser(vals)
#' }
#'
#' # Using a different column name
#' vals$intensity <- vals$value
#' plot_glasser(vals, value_col = "intensity")
#' }
#'
#' @importFrom dplyr filter inner_join group_by summarize left_join rename mutate .data
#' @importFrom tidyr pivot_longer
#' @importFrom sf st_as_sf st_multipolygon st_sfc st_sf st_bbox st_geometry
#' @import ggseg
#' @export
plot_glasser <- function(vals=NULL, value_col = "value", position = "dispersed") {
  # Check and load required packages
  required_packages <- c("geojsonio", "echarts4r", "ggsegGlasser")
  missing_packages <- required_packages[!sapply(required_packages, requireNamespace, quietly = TRUE)]
  if (length(missing_packages) > 0) {
    if ("ggsegGlasser" %in% missing_packages) {
      stop("Package 'ggsegGlasser' is required for this function but is not installed.\n",
           "To install it, run:\n",
           "  remotes::install_github('ggseg/ggsegGlasser')\n",
           "or use the ggseg r-universe:\n",
           "  options(repos = c(ggseg = 'https://ggseg.r-universe.dev',\n",
           "                    CRAN = 'https://cloud.r-project.org'))\n",
           "  install.packages('ggsegGlasser')",
           call. = FALSE)
    } else {
      stop("The following packages are required but not installed: ", 
           paste(missing_packages, collapse = ", "))
    }
  }
  # No library() calls needed - will use :: notation

  # Get the ggseg Glasser atlas data
  glasser_atlas <- get("glasser", envir = asNamespace("ggsegGlasser"))
  ggseg_data <- glasser_atlas$data

  # Create default values if vals is NULL
  if (is.null(vals)) {
    vals <- data.frame(
      label = ggseg_data$label,
      value = rep(1, nrow(ggseg_data))
    )
    value_col <- "value"
  }

  if (!all(c("label", value_col) %in% colnames(vals))) {
    stop(sprintf("'vals' must contain columns 'label' and '%s'", value_col))
  }

  if (!position %in% c("dispersed", "stacked")) {
    warning("'position' must be either 'dispersed' or 'stacked'. Using 'dispersed'.")
    position <- "dispersed"
  }

  # Check if regions in vals match atlas regions
  missing_regions <- setdiff(vals$label, ggseg_data$label)
  if (length(missing_regions) > 0) {
    warning("Some regions in 'vals' are not present in the Glasser atlas")
  }

  # Join values with atlas data
  plot_data <- ggseg_data %>%
    left_join(vals, by = "label") %>%
    dplyr::rename(value = !!value_col)

  # Create the four views
  g1 <- geojsonio::geojson_json(dplyr::filter(plot_data, .data$hemi == "left" & .data$side == "lateral"))
  g2 <- geojsonio::geojson_json(dplyr::filter(plot_data, .data$hemi == "right" & .data$side == "lateral"))
  g3 <- geojsonio::geojson_json(dplyr::filter(plot_data, .data$hemi == "left" & .data$side == "medial"))
  g4 <- geojsonio::geojson_json(dplyr::filter(plot_data, .data$hemi == "right" & .data$side == "medial"))

  # Create the four charts
  chart1 <- get_chart(g1, plot_data, "value", "lat", TRUE)
  chart2 <- get_chart(g2, plot_data, "value", "med", FALSE)
  chart3 <- get_chart(g3, plot_data, "value", "lat2", FALSE)
  chart4 <- get_chart(g4, plot_data, "value", "med2", FALSE) %>%
    echarts4r::e_connect_group("4charts")

  # Arrange charts in 2x2 grid
  echarts4r::e_arrange(chart1, chart2, chart3, chart4,
                       rows = 2, cols = 2, width = "lg")
}

#' Helper Function to Create Individual Brain Charts
#' @keywords internal
#' @noRd
get_chart <- function(geo, data, var, name, show = TRUE) {
  data %>%
    echarts4r::e_charts(.data$label) %>%
    echarts4r::e_map_register(name, geo) %>%
    echarts4r::e_map_(var, map = name, nameProperty = "label") %>%
    echarts4r::e_visual_map_(var,
                             show = show,
                             padding = 0,
                             orient = "horizontal",
                             left = "center",
                             bottom = 0
    ) %>%
    echarts4r::e_theme("dark") %>%
    echarts4r::e_group("4charts")
}
</file>

<file path="R/glasser.R">
#' Load Glasser Atlas
#'
#' @description
#' Retrieves and loads the Glasser360 cortical parcellation atlas from the PennBBL
#' repository. The atlas provides a detailed parcellation of the human cerebral cortex
#' based on multi-modal neuroimaging data.
#'
#' @details
#' The Glasser atlas divides each hemisphere into 180 areas (360 total) based on
#' cortical architecture, function, connectivity, and topography. The atlas is
#' downloaded from the PennBBL xcpEngine repository and includes:
#' \itemize{
#'   \item Volume data in MNI space
#'   \item Region labels and hemisphere information
#'   \item Color specifications for visualization
#' }
#'
#' @param outspace Optional \code{NeuroSpace} object specifying desired output space.
#'   If provided, the atlas will be resampled to this space. Default: NULL
#'
#' @return A list with class 'glasser' and 'atlas' containing:
#' \describe{
#'   \item{name}{Character string "Glasser360"}
#'   \item{atlas}{A \code{ClusteredNeuroVol} object containing the parcellation}
#'   \item{cmap}{Data frame with RGB color specifications for each region}
#'   \item{ids}{Integer vector of region IDs (1:360)}
#'   \item{labels}{Character vector of anatomical labels}
#'   \item{hemi}{Character vector indicating hemisphere ('left' or 'right')}
#' }
#'
#' @references
#' Glasser, M. F., et al. (2016). A multi-modal parcellation of human cerebral
#' cortex. Nature, 536(7615), 171-178.
#'
#' @source
#' Atlas files are downloaded from:
#' \url{https://github.com/PennBBL/xcpEngine/tree/master/atlas/glasser360}
#'
#' @examples
#' \dontrun{
#' # Load atlas in native space
#' atlas <- get_glasser_atlas()
#'
#' # View region labels
#' head(atlas$labels)
#'
#' # Check number of regions per hemisphere
#' table(atlas$hemi)
#' }
#'
#' @importFrom neuroim2 read_vol ClusteredNeuroVol
#' @importFrom downloader download
#' @importFrom utils read.table
#' @importFrom grDevices col2rgb rainbow
#' @export
get_glasser_atlas <- function(outspace=NULL) {
  # Download and read atlas volume
  fname <- "glasser360MNI.nii.gz"
  rpath <- "https://github.com/PennBBL/xcpEngine/raw/master/atlas/glasser360/"
  path <- paste0(rpath, fname)
  
  des <- paste0(tempdir(), "/", fname)
  ret <- download(path, des)
  
  vol <- neuroim2::read_vol(des)
  
  if (!is.null(outspace)) {
    vol <- resample(vol, outspace)
  }
  
  # Download and process labels
  label_name <- "glasser360NodeNames.txt"
  des2 <- paste0(tempdir(), "/", label_name)
  ret <- download(paste0(rpath, label_name), des2)
  
  labels <- read.table(des2, as.is=TRUE)
  cols <- t(col2rgb(rainbow(nrow(labels))))
  colnames(cols) <- c("red", "green", "blue")
  cols <- as.data.frame(cols)
  hemi <- tolower(sapply(strsplit(labels[,1], "_"), "[[", 1))
  region <- sapply(strsplit(labels[,1], "_"), "[[", 2)
  orig_labels <- labels[,1]
  
  # Create label mapping
  cids <- 1:nrow(labels)
  label_map <- as.list(cids)
  names(label_map) <- region
  
  vol <- neuroim2::ClusteredNeuroVol(as.logical(vol), 
                                    clusters=vol[vol!=0], 
                                    label_map=label_map)
  
  # Return atlas object
  ret <- list(
    name="Glasser360",
    atlas=vol,
    cmap=cols,
    ids=1:nrow(labels),
    labels=region,
    orig_labels=orig_labels,
    hemi=hemi,
    network=NULL)
  
  class(ret) <- c("glasser", "atlas")
  ret
}

#' @rdname map_atlas
#' @importFrom ggiraph geom_polygon_interactive
#' @importFrom dplyr left_join mutate
#' @importFrom tibble tibble
#' @export
map_atlas.glasser <- function(x, vals, thresh=c(0,0), pos=FALSE, ...) {
  # Check if ggsegGlasser is available
  if (!requireNamespace("ggsegGlasser", quietly = TRUE)) {
    stop("Package 'ggsegGlasser' is required for this function but is not installed.\n",
         "To install it, run:\n",
         "  remotes::install_github('ggseg/ggsegGlasser')\n",
         "or use the ggseg r-universe:\n",
         "  options(repos = c(ggseg = 'https://ggseg.r-universe.dev',\n",
         "                    CRAN = 'https://cloud.r-project.org'))\n",
         "  install.packages('ggsegGlasser')",
         call. = FALSE)
  }
  
  fun <- if (pos) identity else abs
  
  ids <- ifelse(x$hemi == "left", 
                paste0("lh_L_", x$label), 
                paste0("rh_R_", x$label))
  
  ret <- tibble(statistic=vals, region=x$labels, label=ids, hemi=x$hemi)
  
  # Get glasser atlas from ggsegGlasser
  glasser_atlas <- get("glasser", envir = asNamespace("ggsegGlasser"))
  
  rboth <- glasser_atlas %>%
    as_tibble() %>%
    left_join(ret, by = c("region", "label", "hemi")) %>%
    mutate(statistic=ifelse(fun(.data$statistic) <= thresh[1] | 
                           fun(.data$statistic) > thresh[2], 
                           .data$statistic, NA)) %>%
    as_brain_atlas()
  
  rboth
}

#' Plot Glasser Atlas
#'
#' @description
#' Creates an interactive visualization of the Glasser atlas with mapped values
#' using ggseg and ggiraph.
#'
#' @param x A Glasser atlas object
#' @param y Ignored (required for compatibility with generic plot method)
#' @param vals Numeric vector of values to visualize. If NULL (default), all regions
#'   will be assigned a value of 1, creating a uniform visualization
#' @param thresh Numeric vector of length 2 for thresholding values
#' @param pos Logical. If TRUE, uses raw values for thresholding
#' @rdname plot-methods
#' @param position Character. Layout type ("stacked" or "dispersed")
#' @param colour Character. Border color for regions
#' @param guide Logical. Whether to show color guide
#' @param palette Character. Name of scico color palette
#' @param lim Numeric vector of length 2 for color scale limits. If NULL, will be
#'   set to range of vals
#' @param ... Additional arguments passed to methods
#' @return A ggiraph interactive plot object
#'
#' @importFrom tibble tibble
#' @importFrom magrittr %>%
#' @importFrom dplyr mutate left_join
#' @importFrom ggiraph girafe opts_tooltip opts_hover opts_selection
#' @importFrom ggplot2 aes
#' @importFrom scico scale_fill_scico
#' @import scico
#' @export
plot.glasser <- function(x, y, vals=NULL, thresh=c(0,0), pos=FALSE, 
                        position="stacked", colour="gray", guide=TRUE,
                        palette="cork", lim=NULL, ...) {
  if (is.null(vals)) {
    vals <- rep(1, length(x$labels))
  }
  
  if (is.null(lim)) {
    lim <- range(vals)
  }
  
  gatl <- map_atlas(x, vals, thresh=thresh, pos=pos)
  
  gg <- ggseg(atlas=gatl, 
              position=position, 
              colour=colour, 
              interactive=FALSE, 
              guide=guide,
              mapping=aes(fill=.data$statistic, 
                         tooltip=.data$region,
                         data_id=.data$label)) + 
    scale_fill_scico(palette=palette,
                     limits=lim,
                     direction=-1,
                     oob=scales::squish)
  
  girafe(ggobj=gg,
         width_svg=8, 
         height_svg=6, 
         options=list(
           opts_tooltip(opacity=.7,
                       css="font-family: Arial, Helvetica, sans-serif;"),
           opts_hover(css="fill:yellow;"),
           opts_selection(css="fill:red;", 
                         type="single", 
                         only_shiny=FALSE)))
}

#' @rdname print-methods
#' @importFrom crayon bold green blue red white yellow
#' @importFrom cli rule symbol
#' @export
print.glasser <- function(x, ...) {
  # Header with fancy border
  cat(cli::rule(left = crayon::bold(crayon::blue("Glasser Atlas Summary")), 
                col = "cyan", width = 65), "\n\n")
  
  # Basic info section
  cat(crayon::yellow(cli::symbol$info), " ", 
      crayon::bold("Atlas Type: "), 
      crayon::white("Glasser Multi-Modal Parcellation"), "\n", sep="")
  
  cat(crayon::yellow(cli::symbol$info), " ",
      crayon::bold("Resolution: "), 
      crayon::white("MNI Space"), "\n", sep="")
  
  # Volume dimensions
  dims <- dim(x$atlas)
  cat(crayon::yellow(cli::symbol$info), " ",
      crayon::bold("Dimensions: "), 
      crayon::white(paste0(dims[1], " x ", dims[2], " x ", dims[3])), "\n\n", sep="")
  
  # Region counts
  total_regions <- length(x$ids)
  left_regions <- sum(x$hemi == "left")
  right_regions <- sum(x$hemi == "right")
  
  cat(crayon::green(cli::symbol$circle_filled), " ",
      crayon::bold("Region Summary:"), "\n", sep="")
  
  cat(crayon::blue("|-"), " Total Regions:      ", 
      crayon::white(total_regions), "\n", sep="")
  cat(crayon::blue("|-"), " Left Hemisphere:    ", 
      crayon::white(left_regions), "\n", sep="")
  cat(crayon::blue("\\-"), " Right Hemisphere:   ", 
      crayon::white(right_regions), "\n\n", sep="")
  
  # Sample regions
  cat(crayon::green(cli::symbol$circle_filled), " ",
      crayon::bold("Example Regions:"), "\n", sep="")
  
  # Show first 3 regions from each hemisphere
  left_examples <- head(x$labels[x$hemi == "left"], 3)
  right_examples <- head(x$labels[x$hemi == "right"], 3)
  
  cat(crayon::blue("|-"), " Left:  ", 
      crayon::white(paste(left_examples, collapse=", ")), "...\n", sep="")
  cat(crayon::blue("\\-"), " Right: ", 
      crayon::white(paste(right_examples, collapse=", ")), "...\n", sep="")
  
  # Footer
  cat("\n", cli::rule(
    left = crayon::blue(cli::symbol$info), 
    right = "Use plot() for visualization",
    col = "cyan", width = 65), "\n", sep="")
}
</file>

<file path="R/all_generic.R">
#' Extract a region of interest (ROI) from an atlas
#'
#' @description
#' Extracts a specific region of interest from an atlas object based on label, ID,
#' and hemisphere information.
#'
#' @param x An atlas object
#' @param label Character string specifying the ROI label/name
#' @param id Numeric ID of the ROI in the atlas
#' @param hemi Character string specifying hemisphere ('left' or 'right')
#'
#' @return Returns a subset of the atlas containing only the specified ROI
#'
#' @examples
#' \dontrun{
#' # Load the aseg atlas
#' atlas <- get_aseg_atlas()
#'
#' # Extract the hippocampus ROI
#' roi <- get_roi(atlas, label = "Hippocampus")
#' }
#' @export
get_roi <- function(x, label=NULL, id=NULL, hemi=NULL) {
  UseMethod("get_roi")
}

#' Map values to an atlas
#'
#' @description
#' Maps a set of values to regions/parcels in an atlas object. This can be used
#' to visualize data (like statistics or measurements) across atlas regions.
#'
#' @param x An atlas object to map values onto
#' @param vals Numeric vector of values to map to atlas regions. Length should match
#'   the number of regions in the atlas
#' @param thresh Optional numeric vector of length 2 specifying (min, max) thresholds
#'   for the mapped values. Values outside this range will be clamped.
#' @param ... Additional arguments passed to methods
#'
#' @return Returns the atlas object with mapped values
#'
#' @examples
#' \dontrun{
#' # Load the aseg atlas
#' atlas <- get_aseg_atlas()
#' vals <- rnorm(length(atlas$orig_labels))
#'
#' # Map values with a threshold of -2 to 2
#' mapped <- map_atlas(atlas, vals, thresh = c(-2, 2))
#' }
#' @export
map_atlas <- function(x, vals, thresh, ...) {
  UseMethod("map_atlas")
}

#' Reduce a NeuroVol or NeuroVec by an Atlas
#'
#' Applies a summary function to data within each ROI defined by an atlas.
#' This is an S3 generic function.
#'
#' @param atlas An atlas object or another object for which a method is defined.
#' @param data_vol A \code{NeuroVol} (3D) or \code{NeuroVec} (4D) with the data to be summarized.
#'   When a 3D volume is supplied the result contains a single row; 4D inputs yield one
#'   row per time point.
#' @param stat_func The function to apply to the data within each ROI (e.g., \code{mean},
#'   \code{sd}, \code{sum}).
#' @param ... Additional arguments passed to \code{stat_func}.
#' @param format Character string specifying output format: "wide" or "long". 
#'   If NULL (default), uses "long" for NeuroVol and "wide" for NeuroVec.
#'
#' @return A \code{tibble} with format depending on the \code{format} parameter:
#'   \itemize{
#'     \item \code{"wide"}: Regions as columns. For NeuroVec, rows are time points.
#'     \item \code{"long"}: Columns are \code{region} and \code{value} (NeuroVol) or 
#'           \code{time}, \code{region}, and \code{value} (NeuroVec).
#'   }
#'
#' @examples
#' \dontrun{
#' # Load an atlas
#' atlas <- get_schaefer_atlas(parcels = "200", networks = "7")
#'
#' # Create example data (random values in brain space)
#' brain_data <- neuroim2::NeuroVol(rnorm(prod(dim(atlas$atlas))),
#'                                  space = space(atlas$atlas))
#'
#' # Compute mean values within each atlas region
#' region_means <- reduce_atlas(atlas, brain_data, mean)
#'
#' # Compute standard deviation within each region
#' region_sds <- reduce_atlas(atlas, brain_data, sd, na.rm = TRUE)
#' }
#'
#' @seealso
#' \code{\link{map_atlas}} for mapping values to atlas regions,
#' \code{\link{get_roi}} for extracting specific regions
#'
#' @importFrom stats setNames
#'
#' @export
reduce_atlas <- function(atlas, data_vol, stat_func, ..., format = NULL) {
  UseMethod("reduce_atlas")
}
</file>

<file path="tests/testthat/test-reduce-atlas.R">
test_that("reduce_atlas computes summary statistics with default format", {
  skip_on_cran()
  atl <- get_aseg_atlas()
  vol <- neuroim2::NeuroVol(array(rnorm(prod(dim(atl$atlas))), dim=dim(atl$atlas)),
                             space = neuroim2::space(atl$atlas))
  
  # Default should be long format for NeuroVol
  stats <- reduce_atlas(atl, vol, mean)
  
  expect_s3_class(stats, "tbl_df")
  expect_equal(ncol(stats), 2)  # region, value
  expect_equal(nrow(stats), length(atl$ids))
  expect_equal(colnames(stats), c("region", "value"))
  expect_equal(stats$region, atl$orig_labels)
})

test_that("reduce_atlas names columns for matrix output", {
  skip_on_cran()
  skip("NeuroVec creation issue - skipping for now")
  
  atl <- get_aseg_atlas()
  # Create two volumes and concatenate them
  vol1 <- neuroim2::NeuroVol(array(rnorm(prod(dim(atl$atlas))), dim=dim(atl$atlas)),
                              space = neuroim2::space(atl$atlas))
  vol2 <- neuroim2::NeuroVol(array(rnorm(prod(dim(atl$atlas))), dim=dim(atl$atlas)),
                              space = neuroim2::space(atl$atlas))
  vec <- neuroim2::concat(vol1, vol2, along=4)
  stats <- reduce_atlas(atl, vec, mean)

  expect_s3_class(stats, "tbl_df")
  expect_equal(nrow(stats), 2)
  expect_equal(colnames(stats), c("time", atl$orig_labels))
})


test_that("reduce_atlas errors with mismatched dimensions", {
  skip_on_cran()
  atl <- get_aseg_atlas()
  wrong_dim <- dim(atl$atlas) + c(1, 0, 0)
  new_space <- neuroim2::NeuroSpace(dim = wrong_dim,
                                    spacing = neuroim2::spacing(neuroim2::space(atl$atlas)))
  vol <- neuroim2::NeuroVol(array(0, dim = wrong_dim), space = new_space)
  expect_error(reduce_atlas(atl, vol, mean), "dimensions")
})

test_that("reduce_atlas works on Glasser atlas", {
  skip_on_cran()
  gl <- get_glasser_atlas()
  vol <- neuroim2::NeuroVol(array(rnorm(prod(dim(gl$atlas))), dim=dim(gl$atlas)),
                             space = neuroim2::space(gl$atlas))
  
  # Default is long format for NeuroVol
  stats <- reduce_atlas(gl, vol, mean)

  expect_s3_class(stats, "tbl_df")
  expect_equal(ncol(stats), 2)  # region, value columns
  expect_equal(nrow(stats), length(gl$ids))
  expect_equal(colnames(stats), c("region", "value"))
})

test_that("reduce_atlas supports wide format", {
  skip_on_cran()
  atl <- get_aseg_atlas()
  vol <- neuroim2::NeuroVol(array(rnorm(prod(dim(atl$atlas))), dim=dim(atl$atlas)),
                             space = neuroim2::space(atl$atlas))
  
  # Explicitly request wide format
  stats <- reduce_atlas(atl, vol, mean, format = "wide")
  
  expect_s3_class(stats, "tbl_df")
  expect_equal(ncol(stats), length(atl$ids))
  expect_equal(nrow(stats), 1)
  expect_equal(colnames(stats), atl$orig_labels)
})

test_that("reduce_atlas supports long format for NeuroVec", {
  skip_on_cran()
  skip("NeuroVec creation issue - skipping for now")
  
  atl <- get_aseg_atlas()
  # Would create NeuroVec here
  # vec <- ...
  # stats <- reduce_atlas(atl, vec, mean, format = "long")
  
  # expect_s3_class(stats, "tbl_df")
  # expect_equal(ncol(stats), 3)  # time, region, value
  # expect_equal(colnames(stats), c("time", "region", "value"))
})

# test_that("reduce_atlas works on surface atlas", {
#   skip_on_cran()
#   atl <- get_schaefer_surfatlas(parcels = "100", networks = "7", surf = "inflated")
#   nvert <- length(atl$lh_atlas@data) + length(atl$rh_atlas@data)
#   dat <- rnorm(nvert)
#   stats <- reduce_atlas(atl, dat, mean)
#   expect_s3_class(stats, "tbl_df")
#   expect_equal(ncol(stats), length(atl$ids))
#   expect_equal(nrow(stats), 1)
# })
</file>

<file path="R/olsen_mtl.R">
#' Olsen Medial Temporal Lobe Atlas
#'
#' @description
#' A detailed parcellation atlas of the medial temporal lobe (MTL) regions,
#' including hippocampus and surrounding cortical areas, based on the work of
#' Rosanna Olsen and colleagues.
#'
#' @details
#' The atlas provides a detailed segmentation of MTL structures in MNI space at 1mm
#' resolution. It includes bilateral parcellation of:
#' \itemize{
#'   \item Hippocampal subfields
#'   \item Perirhinal cortex
#'   \item Entorhinal cortex
#'   \item Parahippocampal cortex
#' }
#'
#' @format A list with class 'atlas' containing:
#' \describe{
#'   \item{name}{Character string identifying the atlas}
#'   \item{atlas}{NeuroVol object containing the parcellation in 1mm MNI space}
#'   \item{labels}{Character vector of anatomical region labels}
#'   \item{orig_labels}{Full region labels including hemisphere information}
#'   \item{ids}{Integer vector of region IDs (1:16)}
#'   \item{hemi}{Character vector indicating hemisphere ('left' or 'right')}
#' }
#'
#' @source
#' Olsen, R. K., et al. (2013). The role of relational binding in item memory:
#' Evidence from face recognition in a case of developmental amnesia.
#' Journal of Neuroscience, 33(36), 14107-14111.
#'
#' @examples
#' \donttest{
#' # Load the atlas data
#' data(olsen_mtl)
#'
#' # View available regions
#' olsen_mtl$labels
#'
#' # Check distribution across hemispheres
#' table(olsen_mtl$hemi)
#' }
#'
#' @keywords datasets
"olsen_mtl"

#' Load Olsen MTL Atlas
#'
#' @description
#' Loads the Olsen medial temporal lobe atlas and optionally resamples it to a
#' different space.
#'
#' @param outspace Optional \code{NeuroSpace} object specifying desired output space.
#'   If NULL (default), returns atlas in native 1mm MNI space.
#'
#' @return A list with class 'atlas' containing the MTL parcellation
#'
#' @examples
#' \donttest{
#' # Load in native space
#' mtl <- get_olsen_mtl()
#'
#' # Load and resample to MNI152NLin2009cAsym space (requires neuroim2)
#' # space <- neuroim2::read_template_space("MNI152NLin2009cAsym")
#' # mtl_resampled <- get_olsen_mtl(outspace = space)
#' }
#'
#' @seealso
#' \code{\link{get_hipp_atlas}} for hippocampus-specific parcellation
#'
#' @importFrom utils data
#' @export
get_olsen_mtl <- function(outspace=NULL) {
  olsen_mtl <- NULL  # To avoid R CMD check NOTE
  utils::data("olsen_mtl", envir = environment())
  if (is.null(outspace)) {
    olsen_mtl
  } else {
    atres <- resample(olsen_mtl$atlas, outspace)
    tmp <- olsen_mtl
    tmp$atlas <- atres
    tmp
  }
}

#' Extract Hippocampal Parcellation
#'
#' @description
#' Creates a hippocampus-specific atlas from the Olsen MTL atlas, with optional
#' anterior-posterior subdivisions.
#'
#' @details
#' This function extracts hippocampal regions from the full MTL atlas and can
#' subdivide them into anterior-posterior segments. The resulting atlas maintains
#' bilateral organization and can be used for targeted hippocampal analyses.
#'
#' @param outspace Optional \code{NeuroSpace} object for resampling
#' @param apsections Integer specifying number of anterior-posterior divisions.
#'   Default: 1 (no subdivision)
#'
#' @return A list with class c("hippocampus", "atlas") containing:
#' \describe{
#'   \item{name}{Character string "hippocampus"}
#'   \item{atlas}{NeuroVol object with hippocampal parcellation}
#'   \item{ids}{Integer vector of region IDs}
#'   \item{labels}{Character vector of region labels}
#'   \item{hemi}{Character vector of hemisphere designations}
#'   \item{cmap}{Matrix of RGB colors for visualization}
#'   \item{orig_labels}{Full labels including hemisphere information}
#' }
#'
#' @examples
#' \dontrun{
#' # Basic hippocampal atlas
#' hipp <- get_hipp_atlas()
#'
#' # With anterior-posterior subdivisions
#' hipp_ap <- get_hipp_atlas(apsections = 3)
#' }
#'
#' @importFrom neuroim2 index_to_coord
#' @importFrom grDevices col2rgb rainbow
#' @export
get_hipp_atlas <- function(outspace=NULL, apsections=1) {
  olsen_mtl <- NULL  # To avoid R CMD check NOTE
  # Load and potentially resample base atlas
  x <- if (is.null(outspace)) {
    utils::data("olsen_mtl", envir = environment())
    olsen_mtl
  } else {
    utils::data("olsen_mtl", envir = environment())
    atres <- resample(olsen_mtl$atlas, outspace)
    tmp <- olsen_mtl
    tmp$atlas <- atres
    tmp
  }

  # Extract hippocampal regions
  atlas <- x$atlas
  atlas[atlas %in% c(1,2,3,6,8,9,10,11,14,16)] <- 1
  atlas[!(atlas %in% c(1,2,3,6,8,9,10,11,14,16))] <- 0

  ind <- which(atlas > 0)
  grid <- neuroim2::index_to_coord(atlas, which(atlas > 0))

  # Create anterior-posterior subdivisions if requested
  if (apsections > 1) {
    qz <- cut(grid[,2], apsections)
    levels(qz) <- paste0(seq(1,apsections))
    for (lev in levels(qz)) {
      atlas[ind[qz == lev]] <- as.numeric(lev)
    }
    atlas[ind[grid[,1] > 0]] <- atlas[ind[grid[,1] > 0]] + apsections
  } else {
    atlas[ind[grid[,1] > 0]] <- 2
  }

  # Create return object
  ret <- list(
    name = "hippocampus",
    atlas = atlas,
    ids = seq(1, apsections*2),
    labels = c(paste0("hippocampus_", seq(1,apsections)),
              paste0("hippocampus_", seq(1,apsections))),
    hemi = c(rep("left", apsections), rep("right", apsections)),
    cmap = t(col2rgb(rainbow(apsections*2))),
    network = NULL
  )

  ret$orig_labels <- paste0(ret$hemi, "_", ret$labels)
  class(ret) <- c("hippocampus", "atlas")
  ret
}
</file>

<file path="R/template_flow.R">
#' @importFrom tools R_user_dir
#' @importFrom reticulate import py_available py_module_available py_has_attr py_get_attr py_list_attributes py_to_r is_py_object
#' @importFrom memoise memoise
#' @importFrom lifecycle deprecate_warn
#' @importFrom utils modifyList head askYesNo
.tflow_env <- new.env(parent = emptyenv())

#' Get or Create neuroatlas Cache Directory
#'
#' Returns a path to a neuroatlas-specific cache directory. If the directory
#' (or a specified subdirectory) doesn't exist, it will be created.
#' This function uses `tools::R_user_dir` to ensure a user-specific,
#' OS-appropriate cache location.
#'
#' @param subdir Optional character string. If provided, a subdirectory named
#'   `subdir` will be created/used within the main neuroatlas cache directory.
#' @return A character string representing the path to the cache directory.
#' @keywords internal
.neuroatlas_cache_dir <- function(subdir = NULL) {
  base_cache_dir <- tools::R_user_dir("neuroatlas", "cache")

  cache_path <- base_cache_dir
  if (!is.null(subdir) && nzchar(subdir)) {
    cache_path <- file.path(base_cache_dir, subdir)
  }

  if (!dir.exists(cache_path)) {
    dir.create(cache_path, recursive = TRUE, showWarnings = FALSE)
  }

  return(cache_path)
}

#' Initialize and Get TemplateFlow API Handle
#'
#' Establishes connection to the Python TemplateFlow API via reticulate.
#' Stores the API handle and cache path in an internal environment.
#' It also sets the TEMPLATEFLOW_HOME environment variable to ensure the
#' Python library uses the neuroatlas-managed cache directory.
#'
#' @param cache_dir The directory to use for caching TemplateFlow files managed by neuroatlas.
#'                  Defaults to `.neuroatlas_cache_dir("templateflow")`.
#'                  If provided, this path will be used for TEMPLATEFLOW_HOME.
#' @param force_reinit Logical, whether to force re-initialization of the Python API handle.
#' @return Invisibly returns the TemplateFlow S3 object.
#' @keywords internal
.init_templateflow_api <- function(cache_dir = NULL, force_reinit = FALSE) {
  # Try to use persistent virtual environment if it exists
  neuroatlas_env <- file.path(tools::R_user_dir("neuroatlas", "config"), "r-reticulate")
  if (dir.exists(neuroatlas_env)) {
    tryCatch({
      reticulate::use_virtualenv(neuroatlas_env, required = FALSE)
    }, error = function(e) {
      # Continue with default Python if virtual environment fails
    })
  }
  
  # Determine and set the cache directory first, as it influences TEMPLATEFLOW_HOME
  current_tf_home <- Sys.getenv("TEMPLATEFLOW_HOME")
  target_cache_dir <- ""

  if (!is.null(cache_dir)) {
    # User explicitly provided a cache_dir for this initialization
    target_cache_dir <- cache_dir
    .tflow_env$cache_dir <- target_cache_dir # Store for the R object
    if (!dir.exists(target_cache_dir)) {
      dir.create(target_cache_dir, recursive = TRUE, showWarnings = FALSE)
    }
  } else if (!is.null(.tflow_env$cache_dir) && !force_reinit) {
    # Use previously initialized cache_dir if not forcing reinit and no new one provided
    target_cache_dir <- .tflow_env$cache_dir
  } else {
    # Default: use .neuroatlas_cache_dir("templateflow")
    target_cache_dir <- .neuroatlas_cache_dir("templateflow")
    .tflow_env$cache_dir <- target_cache_dir # Store for the R object
  }

  # Set TEMPLATEFLOW_HOME before importing the Python module,
  # but only if it's not already set or if we are forcing a change.
  # If TEMPLATEFLOW_HOME is already set externally, respect it unless cache_dir is given.
  if (current_tf_home == "" || !is.null(cache_dir) || force_reinit) {
      if (current_tf_home != target_cache_dir) {
          Sys.setenv(TEMPLATEFLOW_HOME = target_cache_dir)
          if (!is.null(.tflow_env$api)) {
            force_reinit <- TRUE
            message("TEMPLATEFLOW_HOME changed to: ", target_cache_dir, ". Re-initializing Python API.")
          }
      }
  } else if (current_tf_home != "" && current_tf_home != target_cache_dir && is.null(cache_dir)) {
    message("Using externally set TEMPLATEFLOW_HOME: ", current_tf_home)
    .tflow_env$cache_dir <- current_tf_home
    target_cache_dir <- current_tf_home
  }

  if (is.null(.tflow_env$api) || force_reinit) {
    if (!reticulate::py_available(initialize = TRUE)) {
      stop("Python is not available. The 'reticulate' package needs Python to access TemplateFlow.\n",
           "Please ensure Python is installed on your system.\n",
           "You can check Python availability with: reticulate::py_available()")
    }
    
    # Check if templateflow is available, with helpful error message
    if (!reticulate::py_module_available("templateflow")) {
      # Check if we're in an ephemeral environment
      current_env <- tryCatch(reticulate::py_config()$virtualenv, error = function(e) NULL)
      if (!is.null(current_env) && grepl("ephemeral", current_env)) {
        stop("Python module 'templateflow' is not installed in the current ephemeral environment.\n",
             "This is a temporary environment that doesn't persist between R sessions.\n\n",
             "To fix this permanently, run: neuroatlas::install_templateflow()\n",
             "This will create a persistent virtual environment for neuroatlas.\n\n",
             "For a quick temporary fix in this session only, run:\n",
             "  reticulate::py_install(c('scipy', 'templateflow'))")
      } else {
        stop("Python module 'templateflow' is not installed.\n",
             "To install it, run: neuroatlas::install_templateflow()\n",
             "This will create a persistent environment to avoid reinstalling each session.")
      }
    }
    
    tryCatch({
      # Import without automatic conversion so downstream code can
      # reliably inspect Python objects (e.g., pathlib.Path)
      .tflow_env$py_api <- reticulate::import("templateflow.api", convert = FALSE)
    }, error = function(e) {
      stop("Failed to import templateflow.api: ", e$message, "\n",
           "This may be due to network issues or corrupted installation.\n",
           "Try reinstalling with: neuroatlas::install_templateflow(force_reinstall = TRUE)")
    })
  }

  invisible(NULL)
}

#' Check TemplateFlow Connectivity
#'
#' Internal function to test if TemplateFlow API is accessible and functioning.
#' This helps distinguish between network issues and other problems.
#'
#' @return Logical. TRUE if TemplateFlow API is accessible, FALSE otherwise.
#' @keywords internal
.check_templateflow_connectivity <- function() {
  # First check if API is initialized
  if (is.null(.tflow_env$py_api)) {
    tryCatch({
      .init_templateflow_api()
    }, error = function(e) {
      return(FALSE)
    })
  }

  # If still no API, return FALSE
  if (is.null(.tflow_env$py_api)) {
    return(FALSE)
  }

  # Try a simple API call to check connectivity
  tryCatch({
    # Try to get the list of templates - this requires network access
    templates <- .tflow_env$py_api$templates()
    # If we got here, connectivity is good
    return(TRUE)
  }, error = function(e) {
    # Check if it's a network-related error
    if (grepl("(URLError|ConnectionError|timeout|network|internet)", e$message, ignore.case = TRUE)) {
      message("TemplateFlow appears to be unreachable. Check your internet connection.")
    }
    return(FALSE)
  })
}

# Memoised TemplateFlow Path Fetching ----

#' Perform TemplateFlow API Call and Convert to Path
#'
#' Internal function that calls the Python TemplateFlow API's get() method,
#' handles errors, and converts the result (potentially a list of paths)
#' to a single R file path string. If multiple paths are returned by TemplateFlow,
#' a warning is issued and the first path is used.
#'
#' @param tf_api_obj The Python TemplateFlow API object from reticulate.
#' @param query_params_list A named list of query parameters for `tf_api_obj$get()`.
#' @return A single character string representing the file path.
#' @keywords internal
.perform_tf_get_and_convert_to_path <- function(tf_api_obj, query_params_list) {
  py_result_path_obj <- NULL

  # Capture Python errors from the API call
  py_result_path_obj <- tryCatch({
    do.call(tf_api_obj$get, query_params_list)
  }, error = function(e) {
    stop(structure(
      list(message = paste0("TemplateFlow API error: ", conditionMessage(e),
                            "\nQuery args: ", paste(names(query_params_list), query_params_list, sep="=", collapse=", ")),
           call = NULL,
           query_args = query_params_list,
           python_error = e),
      class = c("templateflow_api_error", "error", "condition")
    ))
  })

  if (is.null(py_result_path_obj)) {
    stop(structure(
      list(message = paste0("TemplateFlow found no files for the given query.",
                            "\nQuery args: ", paste(names(query_params_list), query_params_list, sep="=", collapse=", ")),
           call = NULL,
           query_args = query_params_list),
      class = c("templateflow_no_files_error", "error", "condition")
    ))
  }

  # If automatic conversion returned an R object, handle robustly
  if (!reticulate::is_py_object(py_result_path_obj)) {
    # Common cases: a character vector or list of character paths
    if (is.character(py_result_path_obj)) {
      if (length(py_result_path_obj) == 0) {
        stop(structure(
          list(message = paste0("TemplateFlow returned no paths for the query.",
                                "\nQuery args: ", paste(names(query_params_list), query_params_list, sep="=", collapse=", ")),
               call = NULL,
               query_args = query_params_list),
          class = c("templateflow_no_files_error", "error", "condition")
        ))
      }
      if (length(py_result_path_obj) > 1) {
        warning("TemplateFlow returned multiple files (", length(py_result_path_obj), ") for the query, using the first one: ", py_result_path_obj[[1]], call. = FALSE)
      }
      return(py_result_path_obj[[1]])
    }
    if (is.list(py_result_path_obj)) {
      # Flatten any character elements and pick the first valid one
      flat <- unlist(py_result_path_obj, recursive = TRUE, use.names = FALSE)
      flat <- as.character(flat)
      flat <- flat[!is.na(flat) & nzchar(flat)]
      if (length(flat) == 0) {
        stop(structure(
          list(message = paste0("TemplateFlow returned a list but no usable path strings were found.",
                                "\nQuery args: ", paste(names(query_params_list), query_params_list, sep="=", collapse=", ")),
               call = NULL,
               query_args = query_params_list),
          class = c("templateflow_processing_error", "error", "condition")
        ))
      }
      if (length(flat) > 1) {
        warning("TemplateFlow returned multiple files (", length(flat), ") for the query, using the first one: ", flat[[1]], call. = FALSE)
      }
      return(flat[[1]])
    }
    # As a last resort, coerce to character
    coerced <- tryCatch(as.character(py_result_path_obj), error = function(e) NULL)
    if (!is.null(coerced) && length(coerced) >= 1 && nzchar(coerced[[1]])) {
      return(coerced[[1]])
    }
    stop(structure(
      list(message = paste0("TemplateFlow returned an unexpected R object that could not be interpreted as a path.",
                            "\nClass: ", paste(class(py_result_path_obj), collapse=","),
                            "\nQuery args: ", paste(names(query_params_list), query_params_list, sep="=", collapse=", ")),
           call = NULL,
           query_args = query_params_list),
      class = c("templateflow_processing_error", "error", "condition")
    ))
  }

  # Python object branch: handle list vs single Path-like object
  final_py_path_obj_to_convert <- NULL
  if (inherits(py_result_path_obj, "python.builtin.list")) {
    num_paths <- length(py_result_path_obj)
    if (num_paths > 1) {
      first_path_str <- tryCatch({
        if (reticulate::py_has_attr(py_result_path_obj[[1]], "as_posix")) {
          reticulate::py_to_r(py_result_path_obj[[1]]$as_posix())
        } else {
          reticulate::py_to_r(py_result_path_obj[[1]])
        }
      }, error = function(e) "<unavailable>")
      warning("TemplateFlow returned multiple files (", num_paths, ") for the query, using the first one: ", first_path_str, call. = FALSE)
      final_py_path_obj_to_convert <- py_result_path_obj[[1]]
    } else if (num_paths == 1) {
      final_py_path_obj_to_convert <- py_result_path_obj[[1]]
    } else {
      stop(structure(
        list(message = paste0("TemplateFlow returned an empty list of files for the query.",
                              "\nQuery args: ", paste(names(query_params_list), query_params_list, sep="=", collapse=", ")),
             call = NULL,
             query_args = query_params_list),
        class = c("templateflow_no_files_error", "error", "condition")
      ))
    }
  } else {
    final_py_path_obj_to_convert <- py_result_path_obj
  }

  if (is.null(final_py_path_obj_to_convert)) {
    stop(structure(
      list(message = paste0("Failed to determine a single path from TemplateFlow's response.",
                            "\nQuery args: ", paste(names(query_params_list), query_params_list, sep="=", collapse=", ")),
           call = NULL,
           query_args = query_params_list),
      class = c("templateflow_processing_error", "error", "condition")
    ))
  }

  # Convert Python Path-like object to an R string path
  r_path_string <- tryCatch({
    if (reticulate::py_has_attr(final_py_path_obj_to_convert, "as_posix")) {
      reticulate::py_to_r(final_py_path_obj_to_convert$as_posix())
    } else {
      # Fallback: try direct conversion
      reticulate::py_to_r(final_py_path_obj_to_convert)
    }
  }, error = function(e_conv) {
    stop(structure(
      list(message = paste0("Failed to convert Python path object to R string: ", e_conv$message,
                            "\nQuery args: ", paste(names(query_params_list), query_params_list, sep="=", collapse=", ")),
           call = NULL,
           query_args = query_params_list,
           conversion_error = e_conv),
      class = c("templateflow_conversion_error", "error", "condition")
    ))
  })

  return(r_path_string)
}

#' Memoised version of .perform_tf_get_and_convert_to_path
#' @keywords internal
.memoised_fetch_templateflow_path <- memoise::memoise(.perform_tf_get_and_convert_to_path)


# TemplateFlow S3 Object and Methods ----

#' Create a TemplateFlow Interface Object
#'
#' Initializes and returns an S3 object of class \code{templateflow} which acts as
#' a gateway to the TemplateFlow Python API and manages configurations.
#'
#' @param cache_dir Optional. Path to a directory for caching TemplateFlow downloads.
#'                  If NULL (default), uses a neuroatlas-specific cache directory obtained
#'                  via \code{.neuroatlas_cache_dir("templateflow")}.
#'                  This will also set the \code{TEMPLATEFLOW_HOME} environment variable for the Python session.
#' @param verbosity Optional. An integer for verbosity level (not yet implemented).
#' @param default_template Optional. A string for a default template to use (not yet implemented).
#'
#' @return An S3 object of class \code{templateflow} containing:
#'   \itemize{
#'     \item \code{api}: The raw Python TemplateFlow API handle from \code{reticulate}.
#'     \item \code{cache_path}: The R-side cache path being used.
#'     \item \code{options}: A list of user-provided options.
#'   }
#' @export
#' @examples
#' \dontrun{
#'   # Ensure Python and templateflow module are available
#'   if (reticulate::py_available(initialize = TRUE) &&
#'       reticulate::py_module_available("templateflow")) {
#'     tf <- create_templateflow()
#'     print(tf)
#'   } else {
#'     message("Python or templateflow module not available. Skipping example.")
#'   }
#' }
create_templateflow <- function(cache_dir = NULL, verbosity = 0, default_template = NULL) {
  .init_templateflow_api(cache_dir = cache_dir) # Ensures API handle and cache_dir are in .tflow_env

  obj <- list(
    api = .tflow_env$py_api, # Direct access to the Python API object
    cache_path = .tflow_env$cache_dir,
    options = list(
      verbosity = verbosity,
      default_template = default_template
    )
  )

  class(obj) <- "templateflow"
  return(obj)
}

#' Print a TemplateFlow Object
#'
#' Provides a brief summary of the TemplateFlow interface object.
#'
#' @param x An object of class \code{templateflow}.
#' @param ... Additional arguments (unused).
#' @export
print.templateflow <- function(x, ...) {
  cat("<neuroatlas TemplateFlow Interface>\n")
  cat("  Cache Path: ", x[["cache_path"]], "\n")
  # Basic check if API object seems valid
  api_obj <- x[["api"]]
  api_status <- tryCatch({
    if (!is.null(api_obj) && reticulate::py_has_attr(api_obj, "get")) {
      "Connected (Python API handle initialized)"
    } else {
      "Disconnected (Python API handle NOT initialized or invalid)"
    }
  }, error = function(e) "Error checking API status")
  cat("  API Status: ", api_status, "\n")

  # Attempt to list some available templates (T5.1.3)
  if (api_status == "Connected (Python API handle initialized)") {
    example_templates <- NULL
    tryCatch({
      # Use the new tflow_spaces function, pass the api_handle
      all_templates <- tflow_spaces(api_handle = x)
      if (!is.null(all_templates) && length(all_templates) > 0) {
        cat("  Available Templates (Examples): ", paste(utils::head(all_templates, 5), collapse=", "))
        if (length(all_templates) > 5) {
          cat(", ... (Total: ", length(all_templates), ")\n", sep="")
        } else {
          cat(" (Total: ", length(all_templates), ")\n", sep="")
        }
      } else if (!is.null(all_templates)) { # empty list returned
        cat("  Available Templates: None found or list is empty.\n")
      } # If NULL, a warning was already issued by tflow_spaces
    }, error = function(e) {
      cat("  Available Templates: Error retrieving list - ", e$message, "\n")
    })
  } else {
    cat("  Available Templates: Cannot list (API not connected).\n")
  }

  invisible(x)
}

#' Access Attributes of the TemplateFlow Object
#'
#' Allows R-native access (via \code{$}) to attributes and methods of the
#' underlying Python TemplateFlow API object.
#'
#' @param x An object of class \code{templateflow}.
#' @param name The name of the attribute or method to access on the Python object.
#' @return The attribute or method from the Python TemplateFlow API object.
#' @export
#' @method $ templateflow
#' @examples
#' \dontrun{
#'   # Ensure Python and templateflow module are available
#'   if (reticulate::py_available(initialize = TRUE) &&
#'       reticulate::py_module_available("templateflow")) {
#'     tf <- create_templateflow()
#'     # Example: Access the 'get' method (it's a Python function)
#'     # print(tf$get)
#'     # Example: List available templates (calls tf$api$templates())
#'     # print(tf$templates())
#'   } else {
#'     message("Python or templateflow module not available. Skipping example.")
#'   }
#' }
`$.templateflow` <- function(x, name) {
  # Direct access to underlying list structure to avoid recursion
  base_list <- unclass(x)
  
  # Special handling for 'api' to avoid infinite recursion
  if (name == "api") {
    return(base_list[["api"]])
  }
  
  # Get api object directly from base list
  api_obj <- base_list[["api"]]
  if (is.null(api_obj)) {
    stop("TemplateFlow API handle is not initialized. Call create_templateflow() again.")
  }
  if (!reticulate::py_has_attr(api_obj, name)) {
    # Before stopping, check if it's a valid template ID to provide a better error or future enhancement
    # For now, just indicate attribute not found on the API object itself.
    available_attrs <- reticulate::py_list_attributes(api_obj)
    stop(paste0("No attribute or method named '", name, "' found on the TemplateFlow API object. ",
                "Available attributes: ", paste(available_attrs, collapse=", ")))
  }
  reticulate::py_get_attr(api_obj, name)
}

#' Access Attributes of the TemplateFlow Object using [[
#'
#' Allows R-native access (via \code{[[}) to attributes and methods of the
#' underlying Python TemplateFlow API object.
#'
#' @param x An object of class \code{templateflow}.
#' @param name The name of the attribute or method to access on the Python object.
#' @return The attribute or method from the Python TemplateFlow API object.
#' @export
#' @method [[ templateflow
#' @examples
#' \dontrun{
#'   # Ensure Python and templateflow module are available
#'   if (reticulate::py_available(initialize = TRUE) &&
#'       reticulate::py_module_available("templateflow")) {
#'     tf <- create_templateflow()
#'     # Example: Access the 'get' method (it's a Python function)
#'     # print(tf[["get"]])
#'   } else {
#'     message("Python or templateflow module not available. Skipping example.")
#'   }
#' }
`[[.templateflow` <- function(x, name) {
  # Direct access to underlying list structure to avoid recursion
  base_list <- unclass(x)
  
  # Try to get the element directly - no names() call
  result <- try(base_list[[name]], silent = TRUE)
  if (!inherits(result, "try-error")) {
    # Return the result even if NULL (for "api" field access)
    return(result)
  }
  
  # For API access, get the api object directly
  api_obj <- base_list[["api"]]
  if (is.null(api_obj)) {
    stop("TemplateFlow API handle is not initialized. Call create_templateflow() again.")
  }
  
  # Access Python API attributes
  if (!reticulate::py_has_attr(api_obj, name)) {
    available_attrs <- reticulate::py_list_attributes(api_obj)
    stop(paste0("No attribute or method named '", name, "' found on the TemplateFlow API object. ",
                "Available attributes: ", paste(available_attrs, collapse=", ")))
  }
  reticulate::py_get_attr(api_obj, name)
}

#' List Attributes of the TemplateFlow API Object
#'
#' Lists the names of attributes and methods available on the underlying
#' Python TemplateFlow API object.
#'
#' @param x An object of class \code{templateflow}.
#' @return A character vector of available attribute and method names.
#' @export
#' @method names templateflow
#' @examples
#' \dontrun{
#'   # Ensure Python and templateflow module are available
#'   if (reticulate::py_available(initialize = TRUE) &&
#'       reticulate::py_module_available("templateflow")) {
#'     tf <- create_templateflow()
#'     # print(names(tf))
#'   } else {
#'     message("Python or templateflow module not available. Skipping example.")
#'   }
#' }
names.templateflow <- function(x) {
  # Direct access to underlying list structure to avoid recursion
  base_list <- unclass(x)
  api_obj <- base_list[["api"]]
  
  if (is.null(api_obj)) {
    stop("TemplateFlow API handle is not initialized. Call create_templateflow() again.")
  }
  reticulate::py_list_attributes(api_obj)
}

#' Fetch a Template from TemplateFlow
#'
#' Unified function to retrieve neuroimaging templates and related files from
#' the TemplateFlow repository. This function provides a more R-native interface
#' to the underlying Python \code{templateflow.api.get()} method.
#'
#' @param space Character string. The primary TemplateFlow identifier for the template space
#'   (e.g., \code{"MNI152NLin2009cAsym"}). Default: \code{"MNI152NLin2009cAsym"}.
#' @param variant Character string. A high-level descriptor for common template types.
#'   Supported: \code{"brain"} (default), \code{"head"}, \code{"mask"}, \code{"probseg"}, \code{"dseg"}.
#'   This is used to infer \code{desc} and sometimes \code{suffix} if they are not explicitly provided.
#' @param modality Character string. The imaging modality or primary suffix for the template file.
#'   Supported: \code{"T1w"} (default), \code{"T2w"}, \code{"mask"} (often used with \code{variant="mask"}).
#'   This is used to infer \code{suffix} if not explicitly provided.
#' @param resolution Numeric or character. The resolution of the template in mm (e.g., \code{1}, \code{2}, \code{"1"}, \code{"01"}). Default: \code{1}.
#' @param cohort Character string. Optional cohort identifier (e.g., \code{"adhokshaj"}).
#' @param desc Character string. Specific TemplateFlow \code{desc} field. If provided, this overrides
#'   any \code{desc} inferred from \code{variant}.
#' @param label Character string. Specific TemplateFlow \code{label} field (e.g., \code{"GM"}, \code{"WM"}, \code{"CSF"} for \code{variant="probseg"} or \code{variant="dseg"}).
#' @param atlas Character string. Specific TemplateFlow \code{atlas} field (e.g., \code{"Schaefer2018"}).
#' @param suffix Character string. Specific TemplateFlow \code{suffix} field. If provided, this overrides
#'   any \code{suffix} inferred from \code{modality} or \code{variant}.
#' @param extension Character string. The file extension. Default: \code{".nii.gz"}.
#' @param path_only Logical. If \code{TRUE}, returns the file path to the template as a string
#'   instead of loading it as a \code{NeuroVol} object. Default: \code{FALSE}.
#' @param use_cache Logical. (Currently primarily for future R-level memoisation).
#'   TemplateFlow's Python API has its own caching. Default: `TRUE`.
#'   Actual R-level path memoisation is now active.
#' @param api_handle An optional S3 object of class `templateflow` obtained from
#'   `create_templateflow()`. If `NULL` (default), a default instance is created internally.
#' @param ... Additional arguments passed directly to the Python `templateflow.api.get()` method
#'   (e.g., `raise_on_empty = TRUE`). This allows specifying any valid TemplateFlow query
#'   entity not explicitly listed as a parameter (e.g., `hemi`, `den`).
#'
#' @details
#' The function performs several pre-flight checks:
#'   - Validates the existence of the specified `space` using `tf$api$templates()`.
#'   - Validates the specified `resolution` against available resolutions for that `space` using `tf$api$resolutions()`.
#'   - These checks issue warnings and may be skipped if the necessary metadata cannot be retrieved from TemplateFlow.
#'
#' Caching behavior:
#'   - This function uses `memoise` to cache the resolved file paths from TemplateFlow at the R level for the current session.
#'   - The underlying Python TemplateFlow library also maintains its own disk cache, typically configured via the
#'     `TEMPLATEFLOW_HOME` environment variable (which this package helps manage).
#'
#' @return If any of `space`, `variant`, `modality`, `resolution`, or `label` are vectors
#'   of length > 1 (and only one of them is vectorized per call), a named list of results is returned.
#'   The names of the list elements correspond to the values of the vectorized parameter.
#'   If all parameters are scalar (or vectors of length 1), a single \code{neuroim2::NeuroVol} object
#'   or a file path string is returned directly (depending on \code{path_only}).
#'
#' @importFrom reticulate py_get_attr
#' @importFrom neuroim2 NeuroVol
#' @export
#' @examples
#' \dontrun{
#'   # Ensure Python and templateflow module are available
#'   if (reticulate::py_available(initialize = TRUE) &&
#'       reticulate::py_module_available("templateflow")) {
#'
#'     # Get default MNI T1w brain template (scalar call)
#'     mni_brain <- get_template()
#'     print(mni_brain)
#'
#'     # Vectorized call: Get MNI brain and mask variants
#'     # mni_variants <- get_template(variant = c("brain", "mask"))
#'     # print(names(mni_variants))
#'     # print(mni_variants$brain)
#'     # print(mni_variants$mask)
#'
#'     # Vectorized call: Get MNI T1w at 1mm and 2mm resolutions
#'     # mni_resolutions <- get_template(resolution = c(1, 2))
#'     # print(mni_resolutions$`1`)
#'     # print(mni_resolutions$`2`)
#'
#'     # Vectorized call: Get GM and CSF probseg for MNI
#'     # mni_probsegs <- get_template(variant = "probseg", label = c("GM", "CSF"))
#'     # print(mni_probsegs$GM)
#'
#'     # Path only example with vectorization
#'     # mni_mask_paths <- get_template(space = "MNI152NLin2009cAsym",
#'     #                              variant = "mask",
#'     #                              resolution = c(1,2),
#'     #                              path_only = TRUE)
#'     # print(mni_mask_paths)
#'
#'   } else {
#'     message("Python or templateflow module not available. Skipping example.")
#'   }
#' }
get_template <- function(space = "MNI152NLin2009cAsym",
                         variant = "brain",
                         modality = "T1w",
                         resolution = 1,
                         cohort = NULL,
                         desc = NULL,
                         label = NULL,
                         atlas = NULL,
                         suffix = NULL,
                         extension = ".nii.gz",
                         path_only = FALSE,
                         use_cache = TRUE,
                         api_handle = NULL,
                         ...) {

  # --- Vectorized Argument Handling ---
  vectorizable_params <- list(
    space = space,
    variant = variant,
    modality = modality,
    resolution = resolution,
    label = label
  )
  vector_lengths <- sapply(vectorizable_params, length)
  is_vectorized <- vector_lengths > 1
  num_vectorized <- sum(is_vectorized)

  if (num_vectorized > 1) {
    stop("Vectorization is supported for only one parameter at a time. ",
         "Use lapply() or purrr::map() for multiple parameters.")
  }

  if (num_vectorized == 1) {
    vec_param_name <- names(is_vectorized)[is_vectorized]
    vec_values <- vectorizable_params[[vec_param_name]]

    # Capture extra arguments
    extra_args <- list(...)

    # Build results list by calling scalar version
    results_list <- lapply(vec_values, function(val) {
      # Build arguments for scalar call
      args <- list(
        space = if (vec_param_name == "space") val else space[1],
        variant = if (vec_param_name == "variant") val else variant[1],
        modality = if (vec_param_name == "modality") val else modality[1],
        resolution = if (vec_param_name == "resolution") val else resolution[1],
        label = if (vec_param_name == "label") val else label[1],
        cohort = cohort,
        desc = desc,
        atlas = atlas,
        suffix = suffix,
        extension = extension,
        path_only = path_only,
        use_cache = use_cache,
        api_handle = api_handle
      )

      # Add extra arguments
      args <- c(args, extra_args)

      # Remove NULLs
      args <- Filter(Negate(is.null), args)

      # Call the scalar implementation
      do.call(.get_template_scalar, args)
    })

    names(results_list) <- as.character(vec_values)
    return(results_list)
  }

  # --- No vectorization - proceed with scalar implementation ---
  .get_template_scalar(
    space = space,
    variant = variant,
    modality = modality,
    resolution = resolution,
    label = label,
    cohort = cohort,
    desc = desc,
    atlas = atlas,
    suffix = suffix,
    extension = extension,
    path_only = path_only,
    use_cache = use_cache,
    api_handle = api_handle,
    ...
  )
}

# Internal scalar implementation
.get_template_scalar <- function(space, variant, modality, resolution,
                                label, cohort, desc, atlas, suffix,
                                extension, path_only, use_cache,
                                api_handle, ...) {

  # Get or validate API handle
  if (is.null(api_handle)) {
    tf <- create_templateflow()
  } else {
    if (!inherits(api_handle, "templateflow")) {
      stop("'api_handle' must be a 'templateflow' object from create_templateflow()")
    }
    tf <- api_handle
  }

  if (is.null(tf[["api"]])) {
    stop("TemplateFlow API not initialized. Check Python/templateflow installation.")
  }

  # Validate template space
  .validate_template_space(tf, space)

  # Validate resolution if provided
  if (!is.null(resolution)) {
    .validate_resolution(tf, space, resolution)
  }

  # Infer parameters
  params <- .infer_template_params(
    variant = variant,
    modality = modality,
    desc = desc,
    suffix = suffix,
    label = label
  )

  # Build query arguments
  query_args <- .build_query_args(
    space = space,
    resolution = resolution,
    desc = params$desc,
    suffix = params$suffix,
    label = label,
    atlas = atlas,
    cohort = cohort,
    extension = extension,
    ...
  )


  # Fetch template path
  file_path <- if (use_cache) {
    tryCatch({
      .memoised_fetch_templateflow_path(tf_api_obj = tf[["api"]], query_params_list = query_args)
    }, templateflow_api_error = function(e) {
      stop(conditionMessage(e))
    }, templateflow_no_files_error = function(e) {
      stop(conditionMessage(e))
    }, templateflow_processing_error = function(e) {
      stop(conditionMessage(e))
    }, templateflow_conversion_error = function(e) {
      stop(conditionMessage(e))
    }, error = function(e) {
      stop("TemplateFlow error: ", conditionMessage(e))
    })
  } else {
    .perform_tf_get_and_convert_to_path(tf_api_obj = tf[["api"]], query_params_list = query_args)
  }

  if (path_only) {
    return(file_path)
  } else {
    # Convert to NeuroVol using the helper
    return(as_neurovol(file_path))
  }
}

#' Internal Helper to Convert Python Object/Path to NeuroVol
#'
#' This function takes a file path (string) or a Python object that can be resolved
#' to a NIfTI file path (e.g., a Python Path object from TemplateFlow) and reads it
#' into a \code{neuroim2::NeuroVol} object.
#'
#' @param path_or_py_obj A file path string or a Python object (e.g., \code{pathlib.Path}).
#' @return A \code{neuroim2::NeuroVol} object.
#' @importFrom neuroim2 read_vol
#' @importFrom reticulate py_to_r
#' @keywords internal
.as_neurovol_unmemoised <- function(path_or_py_obj) {
  file_path <- NULL
  if (is.character(path_or_py_obj)) {
    file_path <- path_or_py_obj
  } else if (reticulate::is_py_object(path_or_py_obj) && reticulate::py_has_attr(path_or_py_obj, "as_posix")) {
    # Assuming it's a pathlib.Path-like object from templateflow's get()
    file_path <- reticulate::py_to_r(path_or_py_obj$as_posix())
  } else if (reticulate::is_py_object(path_or_py_obj)){
    # Fallback for other Python objects that might be string paths
    file_path <- tryCatch(reticulate::py_to_r(path_or_py_obj), error = function(e) NULL)
    if (!is.character(file_path)){
        stop("Input 'path_or_py_obj' is a Python object but could not be converted to a file path string.")
    }
  } else {
    stop("Input 'path_or_py_obj' must be a file path string or a suitable Python object.")
  }

  if (!file.exists(file_path)) {
    stop("Resolved file path does not exist: ", file_path)
  }

  # Read the NIfTI file using neuroim2::read_vol
  vol <- tryCatch({
    neuroim2::read_vol(file_path)
  }, error = function(e) {
    stop("Failed to read NIfTI file (", file_path, ") into NeuroVol: ", e$message)
  })

  return(vol)
}

#' Memoised version of .as_neurovol_unmemoised
#' This is the function that should be called by get_template
#' @keywords internal
as_neurovol <- memoise::memoise(.as_neurovol_unmemoised)

#' Access Templateflow Brain Templates (DEPRECATED - Legacy Signature)
#'
#' @description
#' \\strong{DEPRECATED}: This function signature is deprecated. Please use the new
#' \code{\link{get_template}} function which offers a more comprehensive
#' and R-native interface. The new function handles common variants and
#' modalities more directly.
#'
#' @param name Character string specifying template name. Default: "MNI152NLin2009cAsym"
#' @param desc Character string describing template variant. Default: "brain"
#' @param resolution Numeric resolution in mm. Default: 1
#' @param label Character string specifying tissue label for probability maps
#' @param atlas Character string specifying atlas name
#' @param suffix Character string specifying image type. Default: "T1w"
#' @param extension Character string specifying file extension. Default: ".nii.gz"
#'
#' @return A NeuroVol object containing the requested template
#'
#' @seealso The new \code{\link{get_template}} with updated signature.
#' @md
#' @keywords internal
#' @export
#' @rdname get_template_legacy
get_template_legacy <- function(name="MNI152NLin2009cAsym", desc="brain", resolution=1,
                               label=NULL, atlas=NULL, suffix="T1w",
                               extension=".nii.gz") {
  # T8.1.3: Add lifecycle deprecation warning
  lifecycle::deprecate_warn(
    when = "0.10.0", # Replace with actual version when this is released
    what = "get_template(name)",
    with = "get_template(space)",
    details = paste0(
      "The signature get_template(name, desc, resolution, ...) is deprecated.\n",
      "Please use the new signature: get_template(space, variant, modality, resolution, ...), where 'space' replaces 'name'."
    )
  )

  # Note: The function signature above is the OLD one.
  # We are calling the NEW get_template() which is defined *earlier* in this file.
  # Need to ensure `neuroatlas::` is not strictly necessary if this file is sourced in order,
  # but explicit call can be safer during refactoring if file is split or order changes.
  # For now, direct call as it *should* resolve to the newer one due to R's environment lookup.

  # The new get_template will use explicit desc/suffix if provided,
  # overriding variant/modality inference from its own defaults.
  neuroatlas::get_template(space = name,
                           desc = desc,
                           resolution = resolution,
                           label = label,
                           atlas = atlas,
                           suffix = suffix,
                           extension = extension,
                           # Pass through other defaults from the new get_template explicitly if needed,
                           # or rely on the new get_template's defaults for variant, modality etc.
                           # when desc/suffix are specific enough.
                           variant = NULL, # Explicitly NULL so new get_template doesn't use its default variant logic if desc is set
                           modality = NULL # Explicitly NULL so new get_template doesn't use its default modality logic if suffix is set
                           )
}

#' Get Brain Mask from Template (DEPRECATED)
#'
#' @description
#' \\strong{DEPRECATED}: Please use \code{\link{get_template}(variant = "mask", ...)} instead.
#'
#' Convenience function to retrieve a binary brain mask for a specified template.
#'
#' @param name Character string specifying template name. Default: "MNI152NLin2009cAsym"
#' @param resolution Numeric resolution in mm. Default: 1
#' @param extension Character string specifying file extension. Default: ".nii.gz"
#' @return A NeuroVol object containing the binary brain mask
#' @seealso The new \code{\link{get_template}}
#' @md
#' @keywords internal
#' @export
get_template_brainmask <- function(name="MNI152NLin2009cAsym", resolution=1,
                                  extension=".nii.gz") {
  lifecycle::deprecate_warn(
    when = "0.10.0",
    what = "get_template_brainmask(name)",
    with = "get_template()"
  )
  neuroatlas::get_template(space = name, variant = "mask", resolution = resolution,
                           extension = extension)
}

#' Get Tissue Probability Map from Template (DEPRECATED)
#'
#' @description
#' \\strong{DEPRECATED}: Please use \code{\link{get_template}(variant = "probseg", label = ..., ...)} instead.
#'
#' Retrieves probability maps for different tissue types (GM, WM, CSF).
#'
#' @inheritParams get_template_brainmask
#' @param label Character string specifying tissue type ("GM", "WM", or "CSF"). Default: "GM"
#' @return A NeuroVol object containing the probability map
#' @seealso The new \code{\link{get_template}}
#' @md
#' @keywords internal
#' @export
get_template_probseg <- function(name="MNI152NLin2009cAsym", label="GM",
                                resolution=1, extension=".nii.gz") {
  lifecycle::deprecate_warn(
    when = "0.10.0",
    what = "get_template_probseg(name)",
    with = "get_template()"
  )
  neuroatlas::get_template(space = name, variant = "probseg", label = label,
                           resolution = resolution, extension = extension)
}

#' Get Schaefer Parcellation in Template Space (DEPRECATED)
#'
#' @description
#' \\strong{DEPRECATED}: Please use \code{\link{get_template}(atlas = "Schaefer2018", desc = ..., suffix = "dseg", ...)} instead.
#'
#' Retrieves Schaefer cortical parcellation mapped to a specified template space.
#'
#' @inheritParams get_template_brainmask
#' @param parcels Number of parcels (400 default)
#' @param networks Number of networks (17 default)
#' @return A NeuroVol object containing the parcellation
#' @seealso The new \code{\link{get_template}}
#' @md
#' @keywords internal
#' @export
get_template_schaefer <- function(name="MNI152NLin2009cAsym", resolution=1,
                                 parcels=400, networks=17, extension=".nii.gz") {
  lifecycle::deprecate_warn(
    when = "0.10.0",
    what = "get_template_schaefer(name)",
    with = "get_template()"
  )
  desc_str <- paste0(parcels, "Parcels", networks, "Networks")
  neuroatlas::get_template(space = name, desc = desc_str, atlas = "Schaefer2018",
                           suffix = "dseg", resolution = resolution, extension = extension)
}

#' List Available Templates
#'
#' @description
#' Returns a list of all available templates in the Templateflow repository.
#'
#' @return A character vector of available template names
#' @export
#' @keywords internal
templates <- function() {
  lifecycle::deprecate_warn(
    when = "0.10.0",
    what = "templates()",
    with = "tflow_spaces()"
  )
  # Ensure .tflow_env$py_api is initialized if this is called directly
  if (is.null(.tflow_env$py_api)) {
    create_templateflow() # Initialize if not already
  }
  if (is.null(.tflow_env$py_api)) { # Still NULL after trying
      warning("TemplateFlow API not available. Cannot list templates.")
      return(character(0))
  }
  .tflow_env$py_api$templates()
}

#' Get Template Head Image (DEPRECATED)
#'
#' @description
#' \\strong{DEPRECATED}: Please use \code{\link{get_template}(variant = "head", ...)} instead.
#'
#' Convenience function to get the full head (non-brain-extracted) template.
#'
#' @inheritParams get_template_brainmask
#' @return A NeuroVol object containing the head template
#' @seealso The new \code{\link{get_template}}
#' @md
#' @keywords internal
#' @export
get_template_head <- function(name="MNI152NLin2009cAsym", resolution=1,
                            extension=".nii.gz") {
  lifecycle::deprecate_warn(
    when = "0.10.0",
    what = "get_template_head(name)",
    with = "get_template()"
  )
  neuroatlas::get_template(space = name, variant = "head", resolution = resolution,
                           extension = extension)
}

#' Get CSF Probability Map (DEPRECATED)
#'
#' @description
#' \\strong{DEPRECATED}: Please use \code{\link{get_template}(variant = "probseg", label = "CSF", ...)} instead.
#'
#' Convenience function to get CSF probability map.
#'
#' @inheritParams get_template_brainmask
#' @return A NeuroVol object containing the CSF probability map
#' @seealso The new \code{\link{get_template}}
#' @md
#' @keywords internal
#' @export
get_template_csf <- function(name="MNI152NLin2009cAsym", resolution=1,
                            extension=".nii.gz") {
  lifecycle::deprecate_warn(
    when = "0.10.0",
    what = "get_template_csf(name)",
    with = "get_template()"
  )
  neuroatlas::get_template(space = name, variant = "probseg", label = "CSF",
                           resolution = resolution, extension = extension)
}

#' Get Gray Matter Probability Map (DEPRECATED)
#'
#' @description
#' \\strong{DEPRECATED}: Please use \code{\link{get_template}(variant = "probseg", label = "GM", ...)} instead.
#'
#' Convenience function to get gray matter probability map.
#'
#' @inheritParams get_template_brainmask
#' @return A NeuroVol object containing the gray matter probability map
#' @seealso The new \code{\link{get_template}}
#' @md
#' @keywords internal
#' @export
get_template_gm <- function(name="MNI152NLin2009cAsym", resolution=1,
                           extension=".nii.gz") {
  lifecycle::deprecate_warn(
    when = "0.10.0",
    what = "get_template_gm(name)",
    with = "get_template()"
  )
  neuroatlas::get_template(space = name, variant = "probseg", label = "GM",
                           resolution = resolution, extension = extension)
}

#' Get White Matter Probability Map (DEPRECATED)
#'
#' @description
#' \\strong{DEPRECATED}: Please use \code{\link{get_template}(variant = "probseg", label = "WM", ...)} instead.
#'
#' Convenience function to get white matter probability map.
#'
#' @inheritParams get_template_brainmask
#' @return A NeuroVol object containing the white matter probability map
#' @seealso The new \code{\link{get_template}}
#' @md
#' @keywords internal
#' @export
get_template_wm <- function(name="MNI152NLin2009cAsym", resolution=1,
                           extension=".nii.gz") {
  lifecycle::deprecate_warn(
    when = "0.10.0",
    what = "get_template_wm(name)",
    with = "get_template()"
  )
  neuroatlas::get_template(space = name, variant = "probseg", label = "WM",
                           resolution = resolution, extension = extension)
}

# Typed Helper Functions for TemplateFlow

#' @rdname get_template
#' @param template_id The main TemplateFlow template identifier for the surface
#'        (e.g., "fsLR", "fsaverage"). This is passed as the `space` argument to `get_template`.
#' @param surface_type A character string indicating the type of surface to retrieve.
#'        Common values include: "pial", "white", "inflated", "midthickness", "sphere".
#'        This is passed as the `desc` argument to `get_template`.
#' @param hemi Character string, "L" for left hemisphere or "R" for right hemisphere.
#'        Passed as `hemi` to `get_template`.
#' @param density (Optional) Character string specifying the surface density
#'        (e.g., "32k" for fsLR, "164k" for fsaverage). Passed as `den` to `get_template`.
#' @param resolution (Optional) Character string specifying the resolution, primarily for
#'        fsaverage variants (e.g., "06" for fsaverage6, which is `tpl-fsaverage_res-06...`).
#'        Passed as `resolution` to `get_template`.
#' @param load_as_path Logical, whether to return only the path to the file.
#'        Defaults to `TRUE` as `NeuroVol` objects are not typically used for surface geometry.
#'        If `FALSE`, attempts to load using `as_neurovol` (via `get_template`).
#' @return If `load_as_path` is `TRUE`, a character string (path) or a list of character strings (paths).
#'         If `load_as_path` is `FALSE`, the result of `as_neurovol` (which might be a `NeuroVol`
#'         if `neuroim2::read_vol` supports the format, or could error if not).
#'         Returns `NULL` if no template is found.
#' @export
#' @examples
#' \donttest{
#'   # Get the pial surface for the left hemisphere of fsLR 32k template (as path)
#'   # fslr_pial_L_path <- get_surface_template(template_id = "fsLR", surface_type = "pial",
#'   #                                        hemi = "L", density = "32k")
#'   # print(fslr_pial_L_path)
#'
#'   # Get the white surface for fsaverage6 (res="06", den="41k") right hemisphere
#'   # fsaverage6_white_R_path <- get_surface_template(template_id = "fsaverage",
#'   #                                               surface_type = "white",
#'   #                                               hemi = "R",
#'   #                                               resolution = "06", # for fsaverage6
#'   #                                               density = "41k")   # for fsaverage6
#'   # print(fsaverage6_white_R_path)
#' }
get_surface_template <- function(template_id, surface_type, hemi,
                                 density = NULL, resolution = NULL,
                                 ...,
                                 load_as_path = TRUE) {

  if (!is.character(template_id) || length(template_id) != 1) {
    stop("'template_id' must be a single character string.")
  }
  if (!is.character(surface_type) || length(surface_type) != 1) {
    stop("'surface_type' must be a single character string.")
  }
  if (!hemi %in% c("L", "R")) {
    stop("'hemi' must be either 'L' or 'R'.")
  }

  # Construct the call to the main get_template function
  # We pass hemi, den (from density), and other ... args directly.
  # resolution is also a direct pass-through for get_template.
  call_args <- list(
    space = template_id,
    desc = surface_type,
    suffix = "surf",        # Common suffix for surface geometry files
    extension = ".gii",     # Common extension for Gifti surface files
    resolution = resolution,
    load_as_neurovol = !load_as_path,
    hemi = hemi
    # den will be added from density if not NULL
  )

  if (!is.null(density)) {
    call_args$den <- density
  }

  # Combine with other arguments from ...
  # utils::modifyList will give precedence to arguments in the first list (call_args)
  # if there are any name clashes with ellipsis_args. We want ellipsis_args to add new ones.
  ellipsis_args <- list(...)
  final_args <- utils::modifyList(ellipsis_args, call_args) # puts call_args last, so it overwrites
  # we want ellipsis to be able to override if user passes e.g. suffix explicitly
  # so, the order in modifyList matters. The second list's values take precedence for shared names.
  # Let's ensure explicit params here take precedence over ellipsis, then add non-conflicting ellipsis.

  # Start with our fixed/derived args
  base_call_args <- list(
    space = template_id,
    desc = surface_type,
    suffix = "surf",
    extension = ".gii",
    load_as_neurovol = !load_as_path,
    hemi = hemi
  )

  # Add resolution if provided (it's a named param in get_template)
  if (!is.null(resolution)) {
    base_call_args$resolution <- resolution
  }

  # Add density as 'den' (this goes into ... of get_template)
  additional_tf_params <- list()
  if (!is.null(density)) {
    additional_tf_params$den <- density
  }

  # Combine ... from this function call with our derived additional_tf_params
  # an argument explicitly in ... will override one from additional_tf_params if names clash
  final_ellipsis_args <- utils::modifyList(additional_tf_params, ellipsis_args)

  # Now combine base_call_args with the final_ellipsis_args
  # Explicit arguments in base_call_args should not be overwritten by final_ellipsis_args
  # So, we add final_ellipsis_args to base_call_args, but only if name not already in base_call_args
  for (arg_name in names(final_ellipsis_args)) {
      if (!arg_name %in% names(base_call_args)) {
          base_call_args[[arg_name]] <- final_ellipsis_args[[arg_name]]
      } else {
          # Potentially warn if ... tries to override a core derived parameter like desc, suffix, etc.
          # For now, we assume user knows what they are doing if they pass e.g. desc in ...
          # However, the new get_template structure with explicit variant/modality handles this better.
          # Here, we let ... override for things like 'den' but not core structure.
          # The most robust is just to pass all ... directly to get_template and let it manage.
          # The current structure of get_template is: named args, then ...
          # So, `den` should be passed via `...` to get_surface_template and then to get_template.
      }
  }

  # Simpler: construct arguments for do.call ensuring 'den' and other ... are correctly passed
  final_args_for_get_template <- list(
    space = template_id,
    desc = surface_type,
    suffix = "surf",
    extension = ".gii",
    resolution = resolution, # Explicitly pass, even if NULL, get_template handles it
    load_as_neurovol = !load_as_path,
    hemi = hemi
  )
  if (!is.null(density)) {
    final_args_for_get_template$den <- density # Add 'den' if density is provided
  }

  # Merge with any other ... arguments passed to get_surface_template
  # Arguments in final_args_for_get_template take precedence over those in list(...)
  # if there are name clashes, which is desired for core parameters.
  # For new parameters from ..., they will be added.
  combined_args <- utils::modifyList(list(...), final_args_for_get_template)

  do.call(get_template, combined_args)
}

# Cache Management Functions ----

#' Clear neuroatlas TemplateFlow Cache
#'
#' Removes all files and subdirectories from the `neuroatlas` package's cache
#' directory used for TemplateFlow downloads. This function also clears the
#' in-memory memoisation cache for TemplateFlow path lookups.
#'
#' The TemplateFlow cache directory is typically located within the path returned by
#' `tools::R_user_dir("neuroatlas", "cache")`, in a subdirectory named "templateflow".
#'
#' @param confirm Logical. If `TRUE` (the default), the function will ask for
#'   interactive confirmation before deleting files if the session is interactive.
#'   If `FALSE`, or if the session is not interactive, deletion will proceed without confirmation.
#' @return Invisibly returns `TRUE` if the cache was cleared or attempted to be cleared,
#'   and `FALSE` if the operation was aborted by the user during confirmation.
#' @export
#' @examples
#' \dontrun{
#'   # Clear the TemplateFlow cache (will ask for confirmation if interactive)
#'   # clear_templateflow_cache()
#'
#'   # Clear without confirmation
#'   # clear_templateflow_cache(confirm = FALSE)
#' }
clear_templateflow_cache <- function(confirm = TRUE) {
  tf_cache_dir <- .neuroatlas_cache_dir("templateflow")

  proceed <- FALSE
  if (interactive() && confirm) {
    response <- utils::askYesNo(
      paste0("Are you sure you want to delete all files in the neuroatlas TemplateFlow cache (",
             tf_cache_dir, ") and clear the memoisation cache?"),
      default = FALSE
    )
    if (!is.na(response) && response) {
      proceed <- TRUE
    }
  } else {
    proceed <- TRUE # Non-interactive or confirm=FALSE
  }

  if (!proceed) {
    message("Cache clearing aborted by user.")
    return(invisible(FALSE))
  }

  if (dir.exists(tf_cache_dir)) {
    message("Deleting contents of: ", tf_cache_dir)
    # List all files and directories, including hidden ones, but not . and ..
    items_to_delete <- list.files(tf_cache_dir, all.files = TRUE, no.. = TRUE, full.names = TRUE)
    if (length(items_to_delete) > 0) {
      unlink(items_to_delete, recursive = TRUE, force = TRUE)
      message("Successfully deleted items from disk cache.")
    } else {
      message("Disk cache directory was empty.")
    }
  } else {
    message("Cache directory not found (already clear or never created): ", tf_cache_dir)
  }

  # Clear the memoise cache for the specific function
  if (exists(".memoised_fetch_templateflow_path", where = globalenv()) ||
      exists(".memoised_fetch_templateflow_path", where = asNamespace("neuroatlas"))) {
    tryCatch({
      memoise::forget(.memoised_fetch_templateflow_path)
      message("Successfully cleared in-memory memoisation cache for TemplateFlow paths.")
    }, error = function(e) {
      warning("Could not clear memoisation cache: ", e$message)
    })
  } else {
    message("Memoised function not found; skipping memoisation cache clearing.")
  }

  invisible(TRUE)
}

#' Show neuroatlas TemplateFlow Cache Path
#'
#' Returns the path to the `neuroatlas` package's cache directory used for
#' TemplateFlow downloads. This is typically located within the path returned by
#' `tools::R_user_dir("neuroatlas", "cache")`, in a subdirectory named "templateflow".
#'
#' @return A character string representing the path to the TemplateFlow cache directory.
#' @export
#' @examples
#' cat("TemplateFlow cache is at:", show_templateflow_cache_path(), "\n")
show_templateflow_cache_path <- function() {
  .neuroatlas_cache_dir("templateflow")
}

# Discoverability Functions ----

#' List Available TemplateFlow Template Spaces
#'
#' Retrieves a list of all available template space identifiers from the TemplateFlow archive.
#' These identifiers are top-level names like "MNI152NLin2009cAsym", "fsLR", etc.
#'
#' @param pattern (Optional) A character string containing a regular expression
#'   to filter the template space names. If `NULL` (default), all names are returned.
#' @param api_handle (Optional) An existing `templateflow` S3 object created by
#'   `create_templateflow()`. If `NULL`, a default one will be initialized.
#' @param ... Additional arguments passed to `grep` if `pattern` is specified
#'   (e.g., `ignore.case = TRUE`).
#' @return A character vector of available template space names. Returns `NULL` if the
#'   list cannot be retrieved, with a warning.
#' @export
#' @examples
#' \donttest{
#'   # List all template spaces
#'   # all_spaces <- tflow_spaces()
#'   # print(head(all_spaces))
#'
#'   # List template spaces containing "MNI"
#'   # mni_spaces <- tflow_spaces(pattern = "MNI")
#'   # print(mni_spaces)
#' }
tflow_spaces <- function(pattern = NULL, api_handle = NULL, ...) {
  if (is.null(api_handle)) {
    tf <- create_templateflow()
  } else {
    if (!inherits(api_handle, "templateflow")) {
      stop("'api_handle' must be an object of class 'templateflow' from create_templateflow().")
    }
    tf <- api_handle
  }

  if (is.null(tf[["api"]])) {
    warning("TemplateFlow API handle is not initialized. Cannot list template spaces.")
    return(NULL)
  }

  available_templates_py <- NULL
  tryCatch({
    available_templates_py <- tf[["api"]]$templates()
  }, error = function(e) {
    warning(paste0("Could not retrieve list of available TemplateFlow template spaces: ", e$message))
    return(NULL)
  })

  if (is.null(available_templates_py)) {
    # Should have been caught by tryCatch, but as a safeguard
    return(NULL)
  }

  available_templates_r <- reticulate::py_to_r(available_templates_py)

  if (!is.null(pattern)) {
    if (!is.character(pattern) || length(pattern) != 1) {
      stop("'pattern' must be a single character string (regular expression).")
    }
    available_templates_r <- grep(pattern, available_templates_r, value = TRUE, ...)
  }

  return(available_templates_r)
}

#' Find TemplateFlow Files Matching Metadata Criteria
#'
#' Retrieves a list of file paths from TemplateFlow that match a given template
#' space and other optional metadata query parameters.
#' This function calls the Python `templateflow.api.get()` method with
#' `raise_on_empty=FALSE` to get a list of all matching files.
#'
#' @param space Character string. The primary TemplateFlow identifier for the template
#'   space (e.g., "MNI152NLin2009cAsym"). This is passed as `template` to the Python API.
#' @param query_args (Optional) A named list of additional query parameters to
#'   filter the results (e.g., `list(suffix = "T1w", resolution = "1", desc = "brain")`).
#'   These are passed directly as keyword arguments to the Python `templateflow.api.get()`.
#' @param api_handle (Optional) An existing `templateflow` S3 object created by
#'   `create_templateflow()`. If `NULL`, a default one will be initialized.
#' @return A character vector of file paths matching the query. Returns an empty
#'   vector if no files match, or `NULL` with a warning if the API call fails.
#' @export
#' @examples
#' \donttest{
#'   # List all T1w files for MNI152NLin2009cAsym template
#'   # mni_t1w_files <- tflow_files("MNI152NLin2009cAsym",
#'   #                                           query_args = list(suffix = "T1w"))
#'   # print(mni_t1w_files)
#'
#'   # List all files for the OASIS30ANTs template with desc "brain"
#'   # oasis_brains <- tflow_files("OASIS30ANTs",
#'   #                                           query_args = list(desc = "brain"))
#'   # print(oasis_brains)
#' }
tflow_files <- function(space, query_args = list(), api_handle = NULL) {
  if (is.null(api_handle)) {
    tf <- create_templateflow()
  } else {
    if (!inherits(api_handle, "templateflow")) {
      stop("'api_handle' must be an object of class 'templateflow' from create_templateflow().")
    }
    tf <- api_handle
  }

  if (is.null(tf[["api"]])) {
    warning("TemplateFlow API handle is not initialized. Cannot list metadata.")
    return(NULL)
  }

  if (!is.character(space) || length(space) != 1) {
    stop("'space' must be a single character string.")
  }
  if (!is.list(query_args)) {
    stop("'query_args' must be a list.")
  }

  # Construct the full query for the Python API
  full_python_query <- query_args
  full_python_query$template <- space
  full_python_query$raise_on_empty <- FALSE # Ensure it returns list, not error on empty

  # Ensure query args are sorted for potential future memoisation consistency if applied here
  if (length(full_python_query) > 0) {
      full_python_query <- full_python_query[sort(names(full_python_query))]
  }

  py_path_list_obj <- NULL
  tryCatch({
    py_path_list_obj <- do.call(tf[["api"]]$get, full_python_query)
  }, error = function(e) {
    warning(paste0("TemplateFlow API error while listing metadata: ", e$message,
                   "\nQuery: template=", space, ", args=", paste(names(query_args), query_args, sep="=", collapse=", ")))
    return(NULL) # Return NULL on API error
  })

  if (is.null(py_path_list_obj)) {
    # This can happen if the API call itself failed and returned NULL from tryCatch
    return(NULL)
  }

  # Convert Python list of Path objects to R character vector of paths
  r_paths <- character(0)
  if (reticulate::is_py_object(py_path_list_obj) && inherits(py_path_list_obj, "python.builtin.list")) {
    if (length(py_path_list_obj) > 0) {
      r_paths <- sapply(py_path_list_obj, function(py_path) {
        tryCatch(reticulate::py_to_r(py_path$as_posix()), error = function(e) NA_character_)
      })
      r_paths <- r_paths[!is.na(r_paths)] # Remove any that failed conversion
    }
    # If length is 0, r_paths remains character(0), which is correct for no matches
  } else if (reticulate::is_py_object(py_path_list_obj)) {
    # If TF returns a single Path object when only one file matches (even with raise_on_empty=F)
    # This is unlikely given raise_on_empty=F usually ensures a list, but handle defensively.
    single_path <- tryCatch(reticulate::py_to_r(py_path_list_obj$as_posix()), error = function(e) NA_character_)
    if (!is.na(single_path)) r_paths <- single_path
  }
  # Else: py_path_list_obj might be something unexpected, r_paths remains empty.
  # Or if TemplateFlow returns R NULL directly for no matches (unlikely with python object)

  return(r_paths)
}

# Inter-package Integration Helpers ----

#' Resolve Template Input to NeuroVol or NeuroSpace
#'
#' This internal helper function takes a flexible input representing a neuroimaging
#' template and resolves it to either a `neuroim2::NeuroVol` object or a
#' `neuroim2::NeuroSpace` object, typically by fetching it via `get_template()`
#' if it's not already in the desired R object form.
#'
#' @param input The input to resolve. Can be:
#'   - A `neuroim2::NeuroVol` object.
#'   - A `neuroim2::NeuroSpace` object.
#'   - A character string: Assumed to be a TemplateFlow `space` identifier.
#'     `get_template()` will be called with this space and default values for
#'     other parameters (e.g., `variant="brain"`, `resolution="1"`).
#'   - A named list: Assumed to be arguments for `get_template()`.
#'     `do.call(get_template, input)` will be used.
#' @param target_type A character string, either "NeuroVol" (default) or "NeuroSpace",
#'   specifying the desired output type.
#' @param api_handle (Optional) An existing `templateflow` S3 object.
#' @return An object of the `target_type`. If `target_type` is "NeuroSpace" and
#'   a `NeuroVol` is obtained, its space is extracted via `neuroim2::space()`.
#'   Returns `NULL` or stops on error if resolution fails.
#' @keywords internal
#' @importFrom neuroim2 space
.resolve_template_input <- function(input, target_type = "NeuroVol", api_handle = NULL) {
  if (!target_type %in% c("NeuroVol", "NeuroSpace")) {
    stop("'target_type' must be either 'NeuroVol' or 'NeuroSpace'.")
  }

  resolved_vol <- NULL

  if (inherits(input, "NeuroVol")) {
    resolved_vol <- input
  } else if (inherits(input, "NeuroSpace")) {
    if (target_type == "NeuroSpace") {
      return(input) # Already correct type
    } else { # target_type == "NeuroVol"
      stop("Input is a NeuroSpace, but target_type is NeuroVol. Cannot convert NeuroSpace to NeuroVol without more information.")
    }
  } else if (is.character(input) && length(input) == 1) {
    # Assume string is a TemplateFlow space ID, use default params for get_template
    message("Resolving template input string '", input, "' as a TemplateFlow space ID with default parameters.")
    resolved_vol <- tryCatch({
      get_template(space = input, api_handle = api_handle) # Uses defaults of get_template
    }, error = function(e) {
      stop("Failed to resolve template string '", input, "' via get_template(): ", conditionMessage(e))
      return(NULL) # Should be caught by stop
    })
  } else if (is.list(input)) {
    # Assume list is arguments for get_template
    message("Resolving template input list via do.call(get_template, ...).")
    if (!is.null(api_handle)) {
      input$api_handle <- api_handle # Add api_handle if provided
    }
    resolved_vol <- tryCatch({
      do.call(get_template, input)
    }, error = function(e) {
      stop("Failed to resolve template list via get_template(): ", conditionMessage(e))
      return(NULL) # Should be caught by stop
    })
  } else {
    stop("Invalid 'input' type. Must be a NeuroVol, NeuroSpace, template name (string), or list of get_template() arguments.")
  }

  if (is.null(resolved_vol)) {
    # This case should ideally be handled by errors within the conditional blocks
    stop("Failed to obtain a NeuroVol from the provided input.")
  }

  if (!inherits(resolved_vol, "NeuroVol")){
      stop("Resolution of input did not result in a NeuroVol object as expected.")
  }

  # Now, convert to target_type if necessary
  if (target_type == "NeuroVol") {
    return(resolved_vol)
  } else { # target_type == "NeuroSpace"
    return(neuroim2::space(resolved_vol))
  }
}

# Typed Helper Functions for TemplateFlow

# Helper: Validate template space
.validate_template_space <- function(tf, space) {
  available <- tryCatch({
    reticulate::py_to_r(tf[["api"]]$templates())
  }, error = function(e) {
    warning("Could not retrieve available templates: ", e$message)
    return(NULL)
  })

  if (!is.null(available) && !(space %in% available)) {
    stop("Template space '", space, "' not found. ",
         "Available: ", paste(available, collapse = ", "))
  }
}

# Helper: Validate resolution
.validate_resolution <- function(tf, space, resolution) {
  # Newer templateflow.api may not expose 'resolutions'; check first
  if (!reticulate::py_has_attr(tf[["api"]], "resolutions")) {
    # Skip strict validation when API metadata is unavailable
    warning("Could not retrieve resolutions: API has no 'resolutions' attribute; skipping check.")
    available <- NULL
  } else {
    available <- tryCatch({
      reticulate::py_to_r(tf[["api"]]$resolutions(space))
    }, error = function(e) {
      warning("Could not retrieve resolutions: ", e$message)
      return(NULL)
    })
  }

  if (!is.null(available)) {
    res_char <- as.character(resolution)
    res_padded <- sprintf("%02d", as.integer(resolution))

    if (!(res_char %in% available || res_padded %in% available)) {
      stop("Resolution '", resolution, "' not available for ", space, ". ",
           "Available: ", paste(available, collapse = ", "))
    }
  }
}

# Helper: Infer template parameters
.infer_template_params <- function(variant, modality, desc, suffix, label) {
  # Variant to desc mapping
  desc_map <- c(
    brain = "brain",
    head = "head",
    mask = "brain",
    probseg = "probseg",
    dseg = "dseg"
  )

  # Modality/variant to suffix mapping
  suffix_map <- c(
    T1w = "T1w",
    T2w = "T2w",
    mask = "mask",
    probseg = "probseg",
    dseg = "dseg"
  )

  # Infer desc if not provided
  final_desc <- desc
  if (is.null(final_desc) && !is.null(variant)) {
    # Only set desc for variants where desc is meaningful/stable
    # For probseg/dseg, desc is typically absent; rely on suffix+label
    if (variant %in% c("brain", "head", "mask")) {
      final_desc <- desc_map[variant]
    } else {
      final_desc <- NULL
    }
  }

  # Infer suffix if not provided
  final_suffix <- suffix
  if (is.null(final_suffix)) {
    # Prefer variant-driven suffix when it implies a specific file type (probseg/dseg/mask)
    if (!is.null(variant) && variant %in% names(suffix_map)) {
      final_suffix <- suffix_map[variant]
    } else if (!is.null(modality) && modality %in% names(suffix_map)) {
      final_suffix <- suffix_map[modality]
    }
  }

  # Validate we have required parameters
  # For probseg/dseg/mask, desc is typically absent and not required.
  if (is.null(final_desc)) {
    if (!is.null(final_suffix) && final_suffix %in% c("probseg", "dseg", "mask")) {
      # OK: these file types are fully determined by suffix (+ optional label)
    } else {
      stop("Could not determine 'desc'. Provide explicitly or use a supported variant.")
    }
  }
  if (is.null(final_suffix)) {
    stop("Could not determine 'suffix'. Provide explicitly or use a supported variant/modality.")
  }

  # Warn about label usage
  if (!is.null(label) && !(final_suffix %in% c("probseg", "dseg"))) {
    warning("'label' typically used with suffix='probseg' or 'dseg', not '", final_suffix, "'")
  }

  return(list(desc = final_desc, suffix = final_suffix))
}

# Helper: Build query arguments
.build_query_args <- function(space, resolution, desc, suffix,
                             label, atlas, cohort, extension, ...) {
  args <- list(
    template = space,  # TemplateFlow API uses 'template'
    desc = desc,
    suffix = suffix
  )

  # Add optional parameters
  if (!is.null(resolution)) args$resolution <- as.character(resolution)
  if (!is.null(label)) args$label <- label
  if (!is.null(atlas)) args$atlas <- atlas
  if (!is.null(cohort)) args$cohort <- cohort
  if (!is.null(extension)) args$extension <- extension

  # Add extra arguments
  extra_args <- list(...)
  for (name in names(extra_args)) {
    args[[name]] <- extra_args[[name]]
  }

  # Remove NULLs and sort for consistent caching
  args <- Filter(Negate(is.null), args)
  if (length(args) > 0) {
    args <- args[sort(names(args))]
  }

  return(args)
}
</file>

<file path="R/dilate_parcels.R">
#' Dilate Atlas Parcellation Boundaries
#'
#' @description
#' Expands the boundaries of brain atlas parcels by dilating them into adjacent
#' unassigned voxels within a specified mask. This is useful for filling small gaps
#' between parcels or extending parcels into neighboring regions.
#'
#' @details
#' The dilation process:
#' \itemize{
#'   \item Identifies unassigned voxels within the mask that are adjacent to existing parcels
#'   \item For each unassigned voxel, finds nearby assigned voxels within the specified radius
#'   \item Assigns the unassigned voxel to the nearest parcel
#'   \item Respects mask boundaries to prevent dilation into unwanted regions
#' }
#'
#' The function uses a k-d tree implementation (via Rnanoflann) for efficient nearest
#' neighbor searches in 3D space.
#'
#' @param atlas An object of class "atlas" containing the parcellation to be dilated
#' @param mask A binary mask (NeuroVol object) specifying valid voxels for dilation.
#'   Dilation will only occur within non-zero mask values. Typically a LogicalNeuroVol,
#'   but can be any NeuroVol that will be converted to logical via as.logical().
#' @param radius Numeric. The maximum distance (in voxels) to search for neighboring
#'   parcels when dilating. Default: 4
#' @param maxn Integer. Maximum number of neighboring voxels to consider when
#'   determining parcel assignment. Default: 50
#'
#' @return A \code{ClusteredNeuroVol} object containing the dilated parcellation.
#'   The object maintains the original label mappings but may include additional
#'   voxels in existing parcels.
#'
#' @examples
#' \dontrun{
#' # Load an atlas
#' atlas <- get_aseg_atlas()
#'
#' # Create or load a brain mask
#' mask <- get_template_brainmask()
#' 
#' # Dilate the atlas within the mask
#' dilated <- dilate_atlas(atlas, mask, radius = 4)
#'
#' # More conservative dilation with fewer neighbors
#' dilated_conservative <- dilate_atlas(atlas, mask, radius = 2, maxn = 20)
#' }
#'
#' @seealso
#' \code{\link{get_template_brainmask}} for creating appropriate masks from TemplateFlow
#'
#' @references
#' The algorithm uses efficient k-d tree based nearest neighbor searches for
#' spatial queries in 3D voxel space.
#'
#' @importFrom assertthat assert_that
#' @importFrom neuroim2 index_to_coord index_to_grid ClusteredNeuroVol
#' @importFrom Rnanoflann nn
#' @export
dilate_atlas <- function(atlas, mask, radius = 4, maxn = 50) {
    # Validate inputs
    assertthat::assert_that(inherits(atlas, "atlas"),
                            msg = "`atlas` arg must be an atlas")
    assertthat::assert_that(inherits(mask, "NeuroVol"),
                            msg = "`mask` must be a NeuroVol object")
    assertthat::assert_that(radius > 0,
                            msg = "`radius` must be positive")
    assertthat::assert_that(maxn > 0,
                            msg = "`maxn` must be positive")

    # Convert the atlas to a dense array
    # Convert ClusteredNeuroVol to regular NeuroVol
    atlas2 <- if (inherits(atlas$atlas, "ClusteredNeuroVol")) {
      # ClusteredNeuroVol needs special handling
      # Get the mask and clusters
      mask_indices <- which(atlas$atlas@mask)
      
      # Create a dense volume
      dense_array <- array(0, dim = dim(atlas$atlas))
      dense_array[mask_indices] <- atlas$atlas@clusters
      
      neuroim2::NeuroVol(dense_array, space = neuroim2::space(atlas$atlas))
    } else {
      atlas$atlas
    }

    # Identify the indices of labeled voxels and mask voxels
    atlas_idx <- which(atlas2 > 0)
    mask_idx <- which(as.logical(mask))
    diff_idx <- setdiff(mask_idx, atlas_idx)

    # Early return if there's nothing to dilate
    if (length(diff_idx) == 0) {
        return(atlas)
    }

    # Convert linear indices to coordinates
    cd_atlas <- neuroim2::index_to_coord(mask, atlas_idx)
    cd_diff <- neuroim2::index_to_coord(mask, diff_idx)

    # Get voxel dimensions to scale radius appropriately
    voxel_dims <- neuroim2::spacing(mask)
    # Scale radius by the minimum voxel dimension to get appropriate search radius in mm
    search_radius <- radius * min(voxel_dims)

    # For very large point sets, process in chunks to avoid memory issues
    chunk_size <- 10000
    n_diff <- nrow(cd_diff)
    
    if (n_diff > chunk_size) {
        # Process in chunks
        all_indices <- list()
        all_distances <- list()
        
        for (start in seq(1, n_diff, by = chunk_size)) {
            end <- min(start + chunk_size - 1, n_diff)
            chunk_points <- cd_diff[start:end, , drop = FALSE]
            
            chunk_ret <- Rnanoflann::nn(data = cd_atlas, 
                                       points = chunk_points, 
                                       k = maxn,
                                       search = "radius", 
                                       radius = search_radius,
                                       sorted = TRUE)
            
            all_indices[[length(all_indices) + 1]] <- chunk_ret$indices
            all_distances[[length(all_distances) + 1]] <- chunk_ret$distances
        }
        
        # Combine results
        ret <- list(
            indices = do.call(rbind, all_indices),
            distances = do.call(rbind, all_distances)
        )
    } else {
        # Process all at once for smaller datasets
        ret <- Rnanoflann::nn(data = cd_atlas, 
                              points = cd_diff, 
                              k = maxn,
                              search = "radius", 
                              radius = search_radius,
                              sorted = TRUE)
    }

    # The nn() function returns matrices, need to convert to list format
    # ret$indices is a matrix where each row contains the indices of neighbors
    # ret$distances is a matrix where each row contains the distances to neighbors
    
    # Convert to list format and filter out points with no neighbors
    # In radius search, points with no neighbors have indices = 0
    valid_queries <- which(ret$indices[,1] != 0)
    
    if (length(valid_queries) == 0) {
        # No neighbors for unlabeled voxels, so no change
        return(atlas)
    }

    # Convert matrix output to list format for compatibility with existing code
    indset <- lapply(valid_queries, function(i) {
        idx <- ret$indices[i,]
        idx[idx != 0]  # Remove zeros (no neighbor indicators)
    })
    
    dset <- lapply(valid_queries, function(i) {
        idx <- ret$indices[i,]
        dist <- ret$distances[i,]
        dist[idx != 0]  # Keep only valid distances
    })

    # Prepare output: list form, then we rbind later
    out_list <- vector("list", length(valid_queries))

    # Grid (x,y,z) for the labeled vs unlabeled sets
    dims <- dim(atlas2)
    grid_atlas <- neuroim2::index_to_grid(mask, atlas_idx)
    grid_diff  <- neuroim2::index_to_grid(mask, diff_idx)

    # For each unlabeled voxel that has neighbors
    for (i in seq_along(valid_queries)) {
        voxel_idx <- valid_queries[i]
        neighbors <- indset[[i]]
        distances <- dset[[i]]

        # Grid coords of the unlabeled voxel we're filling
        g2 <- grid_diff[voxel_idx, , drop = FALSE]

        # The neighbor indices are indices into cd_atlas, which map back to atlas_idx
        neighbor_lin_idx <- atlas_idx[neighbors]
        neighbor_labels  <- atlas2[neighbor_lin_idx]

        # Weight by inverse distance
        weights <- 1 / (distances + .Machine$double.eps)
        label_votes <- tapply(weights, neighbor_labels, sum)
        chosen_label <- as.numeric(names(which.max(label_votes)))

        # Store (x, y, z, chosen_label)
        out_list[[i]] <- cbind(g2, chosen_label)
    }

    # Combine rows
    out_df <- do.call(rbind, out_list)

    # Convert (x,y,z) back to linear indices
    sub2ind <- function(sz, xyz) {
        # xyz is Nx3
        (xyz[,3] - 1) * sz[1] * sz[2] + (xyz[,2] - 1) * sz[1] + xyz[,1]
    }
    new_lin_idx <- sub2ind(dims, out_df[, 1:3, drop = FALSE])

    # Assign chosen labels
    atlas2[new_lin_idx] <- out_df[, 4]

    # Get label_map if available
    label_map <- if (inherits(atlas$atlas, "ClusteredNeuroVol") && !is.null(atlas$atlas@label_map)) {
        atlas$atlas@label_map
    } else {
        # Create a default label map from the atlas IDs
        lm <- as.list(atlas$ids)
        names(lm) <- as.character(atlas$ids)
        lm
    }
    
    # Check that we haven't introduced any labels not present in original atlas
    unique_labels <- unique(atlas2[atlas2 != 0])
    original_labels <- if (!is.null(atlas$ids)) {
        atlas$ids
    } else if (inherits(atlas$atlas, "ClusteredNeuroVol")) {
        # For ClusteredNeuroVol, get unique cluster values
        unique(atlas$atlas@clusters)
    } else {
        # For regular NeuroVol
        unique(atlas$atlas[atlas$atlas != 0])
    }
    missing_labels <- setdiff(unique_labels, original_labels)
    if (length(missing_labels) > 0) {
        stop(sprintf(
            "Found labels in dilated atlas that are not in original: %s",
            paste(missing_labels, collapse = ", ")
        ))
    }

    # Create the new dilated ClusteredNeuroVol
    # First create a LogicalNeuroVol mask
    mask_vol <- neuroim2::LogicalNeuroVol(atlas2 != 0, space = neuroim2::space(atlas2))
    
    dilated_vol <- neuroim2::ClusteredNeuroVol(
        mask    = mask_vol,
        clusters = atlas2[atlas2 != 0],
        label_map = label_map
    )

    # Now return an atlas object (with the same fields/classes as the input).
    # We replace only the $atlas slot with the dilated volume.
    new_atlas <- atlas
    new_atlas$atlas <- dilated_vol

    # Preserve the class of the original atlas
    class(new_atlas) <- class(atlas)

    new_atlas
}
</file>

<file path="DESCRIPTION">
Package: neuroatlas
Title: Neuroimaging Atlases and Parcellations
Version: 0.1.0
Authors@R: 
    person("Bradley", "Buchsbaum", , "brad.buchsbaum@gmail.com", role = c("aut", "cre"),
           comment = c(ORCID = "0000-0000-0000-0000"))
Description: Provides a unified interface to access and work with various
    neuroimaging atlases and parcellations including Schaefer, Glasser,
    FreeSurfer ASEG, and Olsen MTL atlases. Integrates with TemplateFlow
    for standardized template access and supports visualization through
    the ggseg ecosystem.
License: MIT + file LICENSE
URL: https://github.com/bbuchsbaum/neuroatlas,
    https://bbuchsbaum.github.io/neuroatlas/
BugReports: https://github.com/bbuchsbaum/neuroatlas/issues
Depends:
    R (>= 3.5.0)
Imports:
    assertthat,
    cli,
    crayon,
    downloader,
    dplyr,
    ggiraph,
    ggplot2,
    ggseg,
    lifecycle,
    magrittr,
    memoise,
    methods,
    neuroim2,
    neurosurf,
    reticulate,
    Rnanoflann,
    scales,
    scico,
    sf,
    stringr,
    tibble,
    tidyr,
    tools,
    utils
Suggests:
    echarts4r,
    geojsonio,
    geojsonsf,
    ggsegGlasser,
    ggsegSchaefer,
    knitr,
    rmarkdown,
    testthat (>= 3.0.0)
VignetteBuilder: 
    knitr
Remotes: 
    bbuchsbaum/neurosurf,
    ggseg/ggsegGlasser,
    ggseg/ggsegSchaefer
Config/testthat/edition: 3
Encoding: UTF-8
Language: en-GB
LazyData: true
LazyDataCompression: xz
RoxygenNote: 7.3.2.9000
</file>

<file path="R/schaefer.R">
#' Base URL for Schaefer Atlas Files
#' @keywords internal
#' @noRd
schaefer_path <- list(
  rpath = "https://raw.githubusercontent.com/ThomasYeoLab/CBIG/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal/Parcellations/MNI/"
)

#' Find Mode of a Vector
#'
#' @description
#' Internal helper function to find the most frequent value in a vector.
#'
#' @param v Numeric vector
#' @return The most frequent value in the vector
#' @keywords internal
#' @noRd
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

#' Resample Volume to New Space
#'
#' @description
#' Resamples a volume to a new space with optional smoothing of parcel boundaries.
#' This is particularly useful for atlas parcellations where maintaining discrete
#' labels is important.
#'
#' @details
#' The resampling process:
#' \itemize{
#'   \item First performs nearest-neighbor interpolation to the new space
#'   \item Optionally smooths boundaries using a local majority voting scheme
#'   \item Preserves zeros in the mask (background)
#' }
#'
#' @param vol A NeuroVol object to be resampled
#' @param outspace A NeuroSpace object specifying the target space
#' @param smooth Logical. Whether to apply boundary smoothing after resampling.
#'   Default: FALSE
#' @param interp Integer. Interpolation method (0=nearest neighbor, 1=linear).
#'   Default: 0
#' @param radius Numeric. Radius for smoothing neighborhood in voxels.
#'   If NULL, uses max(spacing)+0.5. Default: NULL
#' @param min_neighbors Integer. Minimum number of neighbors required for smoothing.
#'   Default: 3
#'
#' @return A resampled NeuroVol object in the new space
#'
#' @importFrom assertthat assert_that
#' @importFrom neuroim2 resample searchlight_coords spacing
#' @export
resample <- function(vol, outspace, smooth=FALSE, interp=0, radius=NULL,
                    min_neighbors=3) {
  # Input validation
  assertthat::assert_that(inherits(vol, "NeuroVol"),
                         msg="'vol' must be a NeuroVol object")
  assertthat::assert_that(inherits(outspace, "NeuroSpace"),
                         msg="'outspace' must be a NeuroSpace object")
  assertthat::assert_that(length(dim(outspace)) == 3,
                         msg="'outspace' must have 3 dimensions")
  assertthat::assert_that(interp %in% c(0,1),
                         msg="'interp' must be 0 (nearest) or 1 (linear)")
  if (!is.null(radius)) {
    assertthat::assert_that(radius > 0,
                           msg="'radius' must be positive")
  }
  assertthat::assert_that(min_neighbors >= 2,
                         msg="'min_neighbors' must be >= 2")

  # Store original labels for validation
  vol_data <- if (inherits(vol, "NeuroVol")) {
    vol[,,]
  } else {
    as.vector(vol)
  }
  orig_labels <- sort(unique(as.vector(vol_data[vol_data != 0])))

  # Initial resampling
  vol <- neuroim2::resample(vol, outspace, interpolation=interp)
  vol2 <- vol

  if (smooth) {
    ds <- neuroim2::spacing(vol)
    mask <- as.logical(vol != 0)

    # Set radius if not provided
    if (is.null(radius)) {
      radius <- max(ds) + 0.5
    }

    sl <- neuroim2::searchlight_coords(mask, radius=radius, nonzero=TRUE)

    for (i in 1:length(sl)) {
      cds <- sl[[i]]

      if (nrow(cds) >= min_neighbors) {
        labels <- vol[cds]
        center_label <- labels[1]
        neighbor_labels <- labels[2:length(labels)]

        # Modified smoothing logic: smooth if majority differs from center
        if (sum(neighbor_labels != center_label) > length(neighbor_labels)/2) {
          md <- getmode(labels)
          if (md != 0) {
            vol2[cds[1,,drop=FALSE]] <- md
          }
        }
      }
    }

    # Preserve mask
    vol2[mask == 0] <- 0
    vol <- vol2
  }

  # Validate output
  final_labels <- sort(unique(as.vector(vol[vol != 0])))
  if (!all(final_labels %in% orig_labels)) {
    warning("Resampling introduced new label values")
  }
  if (!all(orig_labels %in% final_labels)) {
    warning("Some original labels were lost during resampling")
  }

  vol
}

#' Load Schaefer Atlas Volume
#'
#' @description
#' Internal function to download and load Schaefer atlas volume files.
#'
#' @param parcels Number of parcels
#' @param networks Number of networks
#' @param resolution Resolution in mm
#' @param use_cache Whether to use cached files
#' @return A NeuroVol object containing the atlas
#' @keywords internal
#' @noRd
load_schaefer_vol <- function(parcels, networks, resolution, use_cache=TRUE) {
  fname <- paste0("Schaefer2018_", parcels, "Parcels_",
                 networks, "Networks_order_FSLMNI152_", resolution, "mm.nii.gz")

  vol <- if (use_cache) {
    pname <- paste0(get_cache_dir(), "/", fname)
    if (file.exists(pname)) {
      neuroim2::read_vol(pname)
    }
  }

  if (is.null(vol)) {
    path <- paste0(schaefer_path$rpath, fname)
    des <- paste0(tempdir(), "/", fname)
    ret <- downloader::download(path, des)
    vol <- neuroim2::read_vol(des)
    neuroim2::write_vol(vol, paste0(get_cache_dir(), "/", fname))
  }

  vol
}

#' @noRd
#' @keywords internal
load_schaefer_labels <- function(parcels, networks, use_cache=TRUE) {
  label_name <- paste0("Schaefer2018_", parcels, "Parcels_", networks, "Networks_order.txt")
  labels <- NULL
  if (use_cache) {
    if (file.exists(paste0(get_cache_dir(), "/", label_name))) {
      labels <- read.table(paste0(get_cache_dir(), "/", label_name), header=FALSE, as.is=TRUE)
    }
  }

  if (is.null(labels)) {
    des2 <- paste0(tempdir(), "/", label_name)
    #ret <- downloader::download(paste0(schaefer_path$rpath, label_name), des2)
    message("downloading: ", paste0(schaefer_path$rpath, "/freeview_lut/", label_name))
    ret <- downloader::download(paste0(schaefer_path$rpath, "/freeview_lut/", label_name), des2)
    labels <- read.table(des2, header=FALSE, as.is=TRUE)
    file.copy(des2, paste0(get_cache_dir(), "/", label_name), overwrite=TRUE)
  }

  labels
}


#' @noRd
#' @keywords internal
schaefer_metainfo <- function(parcels, networks, use_cache=TRUE) {
  #browser()
  labels = load_schaefer_labels(parcels, networks, use_cache)

  #browser()
  full_label <- labels[,2]
  labels <- labels[, 1:5]
  names(labels) <- c("roinum", "label", "red", "green", "blue")
  labels$label <- gsub(paste0(networks, "Networks", "_"), "", labels$label)
  hemi <- substr(labels$label, 1,2)
  labels$hemi <- hemi

  labels$hemi <- sapply(strsplit(labels$label, "_"), "[[", 1)
  labels$network <-  sapply(strsplit(labels$label, "_"), "[[", 2)
  labels$name <-   sapply(strsplit(labels$label, "_"), function(x) paste(x[(length(x)-1):length(x)], collapse="_"))

  labels$hemi[hemi == "LH"] <- "left"
  labels$hemi[hemi == "RH"] <- "right"

  labels

}

#' Load Schaefer Brain Parcellation Atlas
#'
#' @description
#' Retrieves and loads the Schaefer brain parcellation atlas, which provides a
#' data-driven parcellation of the cerebral cortex based on both local gradient
#' and global similarity approaches.
#'
#' @details
#' The Schaefer atlas offers multiple resolutions of cortical parcellation
#' (100-1000 parcels) and two network versions (7 or 17 networks). The atlas
#' is based on resting-state functional connectivity from 1489 subjects.
#' Features include:
#' \itemize{
#'   \item Multiple granularity levels (100-1000 parcels)
#'   \item Network assignments (7 or 17 networks)
#'   \item Bilateral parcellation
#'   \item Available in different resolutions (1mm or 2mm)
#' }
#'
#' @param parcels Character string specifying number of parcels.
#'   Options: "100", "200", "300", "400", "500", "600", "800", "1000"
#' @param networks Character string specifying network count.
#'   Options: "7", "17"
#' @param resolution Character string specifying MNI space resolution in mm.
#'   Options: "1", "2"
#' @param outspace Optional \code{NeuroSpace} object for resampling the atlas
#' @param smooth Logical. Whether to smooth parcel boundaries after resampling.
#'   Default: FALSE
#' @param use_cache Logical. Whether to cache downloaded files. Default: TRUE
#' @param ... Additional arguments (currently unused, included for consistency
#'   with convenience functions)
#'
#' @return A list with classes c("schaefer", "volatlas", "atlas") containing:
#' \describe{
#'   \item{name}{Character string identifying atlas version}
#'   \item{atlas}{\code{ClusteredNeuroVol} object containing the parcellation}
#'   \item{cmap}{Data frame with RGB colors for visualization}
#'   \item{ids}{Integer vector of region IDs}
#'   \item{labels}{Character vector of region names}
#'   \item{orig_labels}{Original region labels from source data}
#'   \item{network}{Network assignment for each region}
#'   \item{hemi}{Hemisphere designation for each region}
#' }
#'
#' @examples
#' \dontrun{
#' # Load 300-parcel atlas with 7 networks
#' atlas <- get_schaefer_atlas(parcels = "300", networks = "7")
#'
#' # Load high-resolution version
#' atlas_hires <- get_schaefer_atlas(parcels = "400",
#'                                  networks = "17",
#'                                  resolution = "1")
#'
#' # Resample to a different space
#' new_space <- neuroim2::NeuroSpace(dim = c(91,109,91),
#'                                  spacing = c(2,2,2))
#' atlas_resampled <- get_schaefer_atlas(parcels = "300",
#'                                      outspace = new_space)
#' }
#'
#' @references
#' Schaefer, A., et al. (2018). Local-Global Parcellation of the Human Cerebral
#' Cortex from Intrinsic Functional Connectivity MRI. Cerebral Cortex, 28(9),
#' 3095-3114.
#'
#' @source
#' \url{https://github.com/ThomasYeoLab/CBIG/}
#'
#' @seealso
#' \code{\link{get_schaefer_surfatlas}} for surface-based version
#'
#' @section Convenience Functions:
#' Shorthand functions are provided for common Schaefer atlas configurations. These functions call \code{get_schaefer_atlas} with the \code{parcels} and \code{networks} arguments pre-set. They all accept \code{resolution} (default "2"), \code{outspace}, \code{smooth}, \code{use_cache}, and \code{...} arguments.
#' \itemize{
#'   \item \code{sy_100_7()}: 100 parcels, 7 networks.
#'   \item \code{sy_100_17()}: 100 parcels, 17 networks.
#'   \item \code{sy_200_7()}: 200 parcels, 7 networks.
#'   \item \code{sy_200_17()}: 200 parcels, 17 networks.
#'   \item \code{sy_300_7()}: 300 parcels, 7 networks.
#'   \item \code{sy_300_17()}: 300 parcels, 17 networks.
#'   \item \code{sy_400_7()}: 400 parcels, 7 networks.
#'   \item \code{sy_400_17()}: 400 parcels, 17 networks.
#'   \item \code{sy_500_7()}: 500 parcels, 7 networks.
#'   \item \code{sy_500_17()}: 500 parcels, 17 networks.
#'   \item \code{sy_600_7()}: 600 parcels, 7 networks.
#'   \item \code{sy_600_17()}: 600 parcels, 17 networks.
#'   \item \code{sy_800_7()}: 800 parcels, 7 networks.
#'   \item \code{sy_800_17()}: 800 parcels, 17 networks.
#'   \item \code{sy_1000_7()}: 1000 parcels, 7 networks.
#'   \item \code{sy_1000_17()}: 1000 parcels, 17 networks.
#' }
#'
#' @importFrom neuroim2 read_vol ClusteredNeuroVol write_vol
#' @importFrom downloader download
#' @importFrom assertthat assert_that
#' @importFrom utils read.table
#'
#' @export
get_schaefer_atlas <- function(parcels=c("100","200","300","400","500","600","700","800","900","1000"),
                              networks=c("7","17"), resolution=c("1","2"),
                              outspace=NULL, smooth=FALSE, use_cache=TRUE) {

  parcels <- match.arg(as.character(parcels),
                      choices = c("100","200","300","400","500","600","700","800","900","1000"))
  networks <- match.arg(as.character(networks),
                       choices = c("7","17"))
  resolution <- match.arg(as.character(resolution),
                         choices = c("1","2"))

  # Resolve outspace if it's not NULL and not already a NeuroSpace (T6.1.4)
  if (!is.null(outspace) && !methods::is(outspace, "NeuroSpace")) {
    message("Attempting to resolve 'outspace' argument via TemplateFlow...")
    # We need .resolve_template_input to be available.
    # Assuming it's exported from neuroatlas or accessible.
    # If it's internal, this call would need neuroatlas:::.resolve_template_input
    # For now, assuming it becomes an exported utility or is otherwise accessible.
    # If this file is part of the same package, direct call might work if NAMESPACE handles it.
    resolved_outspace <- tryCatch({
      .resolve_template_input(outspace, target_type = "NeuroSpace")
    }, error = function(e) {
      stop("Failed to resolve 'outspace' via TemplateFlow: ", conditionMessage(e),
           "\n'outspace' must be a NeuroSpace object, a TemplateFlow space ID string, or a list of get_template() arguments.")
      return(NULL) # Should be caught by stop
    })

    if (is.null(resolved_outspace) || !methods::is(resolved_outspace, "NeuroSpace")) {
        stop("Resolution of 'outspace' did not result in a valid NeuroSpace object.")
    }
    outspace <- resolved_outspace # Replace original outspace with the resolved NeuroSpace
  }

  vol <- load_schaefer_vol(parcels, networks, resolution, use_cache)

  if (!is.null(outspace)) {
    #print(outspace)
    assertthat::assert_that(length(dim(outspace)) == 3)
    vol <- resample(vol, outspace, smooth)
  }



  labels <- schaefer_metainfo(parcels, networks, use_cache)
  cids <- 1:nrow(labels)
  label_map <- as.list(cids)
  names(label_map) <- labels$name

  vol <- neuroim2::ClusteredNeuroVol(as.logical(vol), clusters=vol[vol!=0], label_map=label_map)

  ret <- list(
    name=paste0("Schaefer-", parcels, "-", networks, "networks"),
    atlas=vol,
    cmap=labels[,3:5],
    ids=1:nrow(labels),
    labels=labels$name,
    orig_labels=labels[,2],
    network=labels$network,
    hemi=labels$hemi)

  class(ret) <- c("schaefer", "volatlas", "atlas")
  ret
}


#' Load Surface-Based Schaefer Atlas
#'
#' @description
#' Loads the surface-based version of the Schaefer parcellation atlas, compatible
#' with FreeSurfer surface representations.
#'
#' @details
#' Provides the Schaefer parcellation mapped to FreeSurfer surface meshes. The
#' atlas can be loaded onto different surface representations (inflated, white,
#' or pial) and maintains the same parcellation scheme as the volumetric version.
#'
#' @param parcels Character string specifying number of parcels.
#'   Options: "100", "200", "300", "400", "500", "600", "800", "1000"
#' @param networks Character string specifying network count.
#'   Options: "7", "17"
#' @param surf Character string specifying surface type.
#'   Options: "inflated", "white", "pial"
#' @param use_cache Logical. Whether to cache downloaded files. Default: TRUE
#'
#' @return A list with classes c("schaefer", "surfatlas", "atlas") containing:
#' \describe{
#'   \item{surf_type}{Surface type used}
#'   \item{lh_atlas}{Left hemisphere surface atlas}
#'   \item{rh_atlas}{Right hemisphere surface atlas}
#'   \item{name}{Atlas identifier}
#'   \item{cmap}{RGB color specifications}
#'   \item{ids}{Region IDs}
#'   \item{labels}{Region names}
#'   \item{orig_labels}{Original region labels}
#'   \item{network}{Network assignments}
#'   \item{hemi}{Hemisphere designations}
#' }
#'
#' @examples
#' \dontrun{
#' # Load inflated surface atlas
#' surf_atlas <- get_schaefer_surfatlas(parcels = "300",
#'                                     networks = "7",
#'                                     surf = "inflated")
#'
#' # Load pial surface version
#' pial_atlas <- get_schaefer_surfatlas(parcels = "400",
#'                                     networks = "17",
#'                                     surf = "pial")
#' }
#'
#' @seealso
#' \code{\link{get_schaefer_atlas}} for volumetric version
#'
#' @importFrom neurosurf read_freesurfer_annot
#' @importFrom downloader download
#' @importFrom utils data
#' @export
get_schaefer_surfatlas <- function(parcels=c("100","200","300","400","500","600","800","1000"),
                                  networks=c("7","17"), surf=c("inflated", "white", "pial"),
                                  use_cache=TRUE) {


  #https://github.com/ThomasYeoLab/CBIG/blob/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal/Parcellations/FreeSurfer5.3/fsaverage6/label/lh.Schaefer2018_1000Parcels_17Networks_order.annot

  parcels <- match.arg(parcels)
  networks <- match.arg(networks)
  surf <- match.arg(surf)
  #resolution <- match.arg(resolution)

  fsaverage <- NULL  # To avoid R CMD check NOTE
  utils::data("fsaverage", envir = environment())

  get_hemi <- function(hemi) {

    fname <- paste0(hemi, ".", "Schaefer2018_", parcels, "Parcels_", networks, "Networks_order.annot")

    rpath <- "https://raw.githubusercontent.com/ThomasYeoLab/CBIG/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal/Parcellations/FreeSurfer5.3/fsaverage6/label/"
    path <- paste0(rpath,fname)

    des <- paste0(tempdir(), "/", fname)
    ret <- downloader::download(path, des)

    geom <- paste0(hemi, "_", surf)
    annot <- suppressWarnings(neurosurf::read_freesurfer_annot(des, fsaverage[[geom]]))

    nrois <- as.integer(parcels)

    if (hemi == "rh") {
      annot@data <- annot@data + nrois/2
      annot@data <- annot@data - 1
      annot@data[annot@data == nrois/2] <- 0
      annot@labels <- annot@labels[-1]
    } else {
      annot@data <- annot@data - 1
      annot@labels <- annot@labels[-1]
    }

    #class(annot) <- c(class(annot), "surf_atlas")
    annot

  }


  ##rp <-  "https://raw.githubusercontent.com/ThomasYeoLab/CBIG/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal/Parcellations/MNI/"

  labels <- schaefer_metainfo(parcels, networks, use_cache=use_cache)
  #browser()
  lh_surf <- get_hemi("lh")
  rh_surf <- get_hemi("rh")

  ret <- list(
    surf_type=surf,
    lh_atlas = lh_surf,
    rh_atlas = rh_surf,
    name=paste0("Schaefer-", parcels, "-", networks, "networks"),
    cmap=labels[,3:5],
    ids=1:nrow(labels),
    labels=labels$name,
    orig_labels=labels[,2],
    network=labels$network,
    hemi=labels$hemi)

  class(ret) <- c("schaefer", "surfatlas", "atlas")
  ret
}



#' @rdname get_schaefer_atlas
#' @export
sy_100_7 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "100", networks = "7", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_100_17 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "100", networks = "17", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_200_7 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "200", networks = "7", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_200_17 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "200", networks = "17", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_300_7 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "300", networks = "7", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_300_17 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "300", networks = "17", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_400_7 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "400", networks = "7", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_400_17 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "400", networks = "17", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_500_7 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "500", networks = "7", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_500_17 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "500", networks = "17", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_600_7 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "600", networks = "7", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_600_17 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "600", networks = "17", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_700_7 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "700", networks = "7", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_700_17 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "700", networks = "17", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_800_7 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "800", networks = "7", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_800_17 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "800", networks = "17", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_900_7 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "900", networks = "7", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_900_17 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "900", networks = "17", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_1000_7 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "1000", networks = "7", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}

#' @rdname get_schaefer_atlas
#' @export
sy_1000_17 <- function(resolution = "2", outspace = NULL, smooth = FALSE, use_cache = TRUE, ...) {
  get_schaefer_atlas(parcels = "1000", networks = "17", resolution = resolution,
                     outspace = outspace, smooth = smooth, use_cache = use_cache, ...)
}
</file>

<file path="R/atlas.R">
#' @rdname print-methods
#' @importFrom crayon bold green blue red white
#' @importFrom cli rule symbol
#' @export
print.atlas <- function(x, ...) {
  # Header
  cat(cli::rule(left = crayon::bold("Atlas Summary"), col = "cyan", width = 60), "\n\n")

  # Basic info
  cat(crayon::blue(cli::symbol$pointer), " ",
      crayon::bold("Name:   "), crayon::white(x$name), "\n", sep="")

  # Volume info
  dims <- dim(x$atlas)
  cat(crayon::blue(cli::symbol$pointer), " ",
      crayon::bold("Dimensions: "),
      crayon::white(paste0(dims[1], " x ", dims[2], " x ", dims[3])), "\n", sep="")

  # Region counts
  cat(crayon::blue(cli::symbol$pointer), " ",
      crayon::bold("Regions: "),
      crayon::green(length(x$ids)), "\n", sep="")

  # Hemisphere breakdown
  left_count <- sum(x$hemi == "left", na.rm=TRUE)
  right_count <- sum(x$hemi == "right", na.rm=TRUE)
  bilateral_count <- sum(is.na(x$hemi))

  cat("\n", crayon::bold("Structure Distribution:"), "\n", sep="")
  cat(crayon::red("|-"), " Left hemisphere:     ",
      crayon::white(left_count), "\n", sep="")
  cat(crayon::red("|-"), " Right hemisphere:    ",
      crayon::white(right_count), "\n", sep="")
  cat(crayon::red("\\-"), " Bilateral/Midline:   ",
      crayon::white(bilateral_count), "\n", sep="")

  # Footer
  cat("\n", cli::rule(col = "cyan", width = 60), "\n", sep="")
}

#' Create Cache Directory for Atlas Data
#'
#' @description
#' Creates a hidden directory in the user's home folder for caching atlas data.
#'
#' @return Character string containing the path to the cache directory
#' @keywords internal
#' @noRd
create_cache_dir <- function() {
  dname <- paste0(Sys.getenv("HOME"), "/.neuroatlas_cache")
  if (!dir.exists(dname)) {
    dir.create(dname)
  }
  dname
}

#' Get Cache Directory Path
#'
#' @description
#' Returns the path to the atlas cache directory, creating it if necessary.
#'
#' @return Character string containing the path to the cache directory
#' @keywords internal
#' @noRd
get_cache_dir <- function() {
  create_cache_dir()
}

#' Clear Atlas Cache
#'
#' @description
#' Removes all cached atlas files from the cache directory.
#'
#' @return None
#' @keywords internal
#' @noRd
clear_cache <- function() {
  dname <- paste0(Sys.getenv("HOME"), "/.neuroatlas_cache")
  fnames <- list.files(dname, full.names=TRUE)
  sapply(fnames, unlink)
}

#' Merge Two Brain Atlases
#'
#' @description
#' Combines two brain atlases into a single unified atlas object, preserving all
#' region information and adjusting region IDs to prevent conflicts. This is useful
#' for creating composite atlases that combine different parcellation schemes.
#'
#' @details
#' The merging process:
#' \itemize{
#'   \item Verifies that both atlases have the same dimensions
#'   \item Adjusts region IDs in the second atlas to avoid overlap
#'   \item Combines color maps, labels, and hemisphere information
#'   \item Creates a new ClusteredNeuroVol object for the merged atlas
#' }
#'
#' @param atlas1 The first atlas object to merge
#' @param atlas2 The second atlas object to merge
#'
#' @return A new atlas object containing:
#' \describe{
#'   \item{name}{Combined names of input atlases (atlas1::atlas2)}
#'   \item{atlas}{Combined \code{ClusteredNeuroVol} object}
#'   \item{cmap}{Combined colormap for all regions}
#'   \item{ids}{Adjusted vector of all region IDs}
#'   \item{labels}{Combined vector of region labels}
#'   \item{orig_labels}{Original labels from both atlases}
#'   \item{hemi}{Combined hemisphere designations}
#' }
#'
#' @examples
#' \dontrun{
#' # Load two atlases
#' atlas1 <- get_aseg_atlas()
#' atlas2 <- get_aseg_atlas()
#'
#' # Merge the atlases
#' merged <- merge_atlases(atlas1, atlas2)
#'
#' # Check the combined regions
#' print(merged)
#' }
#'
#' @seealso
#' \code{\link{get_aseg_atlas}}, \code{\link{get_roi}}
#'
#' @importFrom assertthat assert_that
#' @importFrom neuroim2 NeuroVol ClusteredNeuroVol space
#' @export
merge_atlases <- function(atlas1, atlas2) {
  assertthat::assert_that(all(dim(atlas1$atlas) == dim(atlas2$atlas)))

  # Start with atlas1 as base
  # Handle different atlas types
  if (inherits(atlas1$atlas, "ClusteredNeuroVol")) {
    # For ClusteredNeuroVol, we need to reconstruct the full volume
    atlmerged <- neuroim2::NeuroVol(array(0, dim=dim(atlas1$atlas)),
                                    space=neuroim2::space(atlas1$atlas))
    # Fill in the cluster values
    atlmerged[atlas1$atlas != 0] <- atlas1$atlas[atlas1$atlas != 0]
  } else {
    atlmerged <- neuroim2::NeuroVol(as.numeric(as.vector(atlas1$atlas)),
                                    space=neuroim2::space(atlas1$atlas))
  }

  # Create mapping for atlas2 values
  # We need to map each unique value in atlas2 to a new value that doesn't conflict with atlas1
  atl2 <- atlas2$atlas
  atl2_data <- if (inherits(atl2, "NeuroVol")) {
    extracted <- atl2[,,]
    # Convert sparse vectors to regular numeric
    if (inherits(extracted, "sparseVector")) {
      as.numeric(extracted)
    } else {
      extracted
    }
  } else {
    as.vector(atl2)
  }
  atl2_vals <- sort(unique(as.vector(atl2_data[atl2_data != 0])))

  # Create a remapping - shift all atlas2 values to come after atlas1's max ID
  max_atlas1_id <- max(atlas1$ids)
  remap <- list()
  shifted_ids <- atlas2$ids  # Start with original IDs

  # Create mapping for each unique value in atlas2
  for (i in seq_along(atl2_vals)) {
    old_val <- atl2_vals[i]
    new_val <- max_atlas1_id + i
    remap[[as.character(old_val)]] <- new_val
  }

  # Update shifted_ids based on the remapping
  for (i in seq_along(atlas2$ids)) {
    old_id <- atlas2$ids[i]
    if (as.character(old_id) %in% names(remap)) {
      shifted_ids[i] <- remap[[as.character(old_id)]]
    }
  }

  # Apply the remapping to atlas2
  atl2_remapped <- atl2
  if (inherits(atl2_remapped, "NeuroVol")) {
    # For NeuroVol objects, we need to extract, modify, and recreate
    atl2_data <- atl2_remapped[,,]
    for (old_val in names(remap)) {
      atl2_data[atl2_data == as.numeric(old_val)] <- remap[[old_val]]
    }
    # Convert to regular numeric vector if it's sparse
    if (inherits(atl2_data, "sparseVector")) {
      atl2_data <- as.numeric(atl2_data)
    }
    atl2_remapped <- neuroim2::NeuroVol(atl2_data, space = neuroim2::space(atl2))
  } else {
    # For regular arrays/vectors
    for (old_val in names(remap)) {
      atl2_remapped[atl2_remapped == as.numeric(old_val)] <- remap[[old_val]]
    }
  }

  # Merge the remapped atlas2 into atlmerged
  if (inherits(atlmerged, "NeuroVol") && inherits(atl2_remapped, "NeuroVol")) {
    # Extract data, modify, and recreate
    atlmerged_data <- atlmerged[,,]
    atl2_remapped_data <- atl2_remapped[,,]
    mask <- atl2_remapped_data != 0
    atlmerged_data[mask] <- atl2_remapped_data[mask]
    atlmerged <- neuroim2::NeuroVol(atlmerged_data, space = neuroim2::space(atlmerged))
  } else {
    # For regular arrays
    atlmerged[atl2_remapped != 0] <- atl2_remapped[atl2_remapped != 0]
  }

  # Get unique cluster values from the merged atlas
  if (inherits(atlmerged, "NeuroVol")) {
    atlmerged_data <- atlmerged[,,]
    unique_clusters <- sort(unique(as.vector(atlmerged_data[atlmerged_data != 0])))
  } else {
    unique_clusters <- sort(unique(atlmerged[atlmerged != 0]))
  }

  # Create a LogicalNeuroVol mask from the merged atlas
  mask <- neuroim2::LogicalNeuroVol(atlmerged != 0, space=neuroim2::space(atlmerged))

  # Get unique cluster values from the merged atlas (excluding 0)
  cluster_values <- atlmerged[atlmerged != 0]
  unique_clusters <- sort(unique(as.vector(cluster_values)))

  # Skip label_map since it causes issues with duplicate labels
  # The atlas object already maintains the mapping between IDs and labels
  atlmerged <- neuroim2::ClusteredNeuroVol(mask=mask,
                                           clusters=cluster_values)



  ret <- list(
    name=paste0(atlas1$name,"::", atlas2$name),
    atlas=atlmerged,
    cmap=rbind(atlas1$cmap, atlas2$cmap),
    ids=c(atlas1$ids, atlas2$ids + max(atlas1$ids)),
    labels=c(atlas1$labels, atlas2$labels),
    orig_labels=c(atlas1$orig_labels, atlas2$orig_labels),
    hemi=c(atlas1$hemi, atlas2$hemi)
  )

  class(ret) <- c(paste0(atlas1$name,"::", atlas2$name), "atlas")
  ret
}


#' @rdname get_roi
#' @importFrom neuroim2 space ROIVol index_to_grid
#' @export
get_roi.atlas <- function(x, label=NULL, id=NULL, hemi=NULL) {
  if (!is.null(label) && !is.null(id)) {
    stop("must supply one of 'id' or 'label' but not both")
  }

  if (is.null(label) && is.null(id)) {
    stop("must supply either 'id' or 'label'")
  }

  if (!is.null(label)) {
    ret <- lapply(label, function(l) {
      id <- x$ids[which(x$labels == l)]
      if (length(id) == 0) {
        stop(paste0("label '", l, "' not found in atlas"))
      }
      rind <- which(x$atlas %in% id)
      neuroim2::ROIVol(neuroim2::space(x$atlas),
                       coords = neuroim2::index_to_grid(x$atlas, rind),
                       data=x$atlas[rind])
    })

    names(ret) <- label
    ret
  } else {
    ret <- lapply(id, function(i) {
      rind <- which(x$atlas %in% i)
      neuroim2::ROIVol(neuroim2::space(x$atlas),
                       coords = neuroim2::index_to_grid(x$atlas, rind),
                       data = x$atlas[rind])
    })
    names(ret) <- id
    ret
  }
}

#' @rdname reduce_atlas
#'
#' @details
#' When \code{data_vol} is a 3D \code{NeuroVol}, the returned tibble contains a
#' single row with one column per ROI. If a 4D \code{NeuroVec} is supplied, each
#' time point is summarised separately and a \code{time} column is added to the
#' tibble.
#'
#' @importFrom stats setNames
#'
#' @export
#' @method reduce_atlas atlas
reduce_atlas.atlas <- function(atlas, data_vol, stat_func, ..., format = NULL) {

  # --- Input Validation ---
  if (!methods::is(data_vol, "NeuroVol") && !methods::is(data_vol, "NeuroVec")) {
    stop("'data_vol' must be a NeuroVol or NeuroVec object.")
  }
  if (!is.function(stat_func)) {
    stop("'stat_func' must be a function.")
  }

  # --- Determine ROI definition volume from 'atlas' ---
  roi_definition_vol <- .get_atlas_volume(atlas)

  # --- Ensure data_vol and ROI definition share dimensions ---
  if (!all(dim(data_vol) == dim(roi_definition_vol))) {
    stop("The dimensions of 'data_vol' and the ROI definition volume do not match.")
  }

  # Check that dimensions match
  atlas_dims <- dim(roi_definition_vol)[1:3]
  data_dims <- dim(data_vol)[1:3]
  if (!all(atlas_dims == data_dims)) {
    stop("Dimensions of atlas (", paste(atlas_dims, collapse="x"),
         ") do not match dimensions of data volume (", paste(data_dims, collapse="x"), ")")
  }

  # --- Extract data using ROI matching ---
  # Get unique ROI labels (excluding 0/background)
  if (inherits(roi_definition_vol, "ClusteredNeuroVol")) {
    # For ClusteredNeuroVol, get labels from clusters
    roi_labels <- sort(unique(roi_definition_vol@clusters))
    roi_labels <- roi_labels[roi_labels != 0]
    # Create a full volume for masking
    roi_vol_data <- array(0, dim = dim(roi_definition_vol))
    roi_vol_data[which(roi_definition_vol@mask)] <- roi_definition_vol@clusters
  } else {
    # For regular NeuroVol
    roi_vol_data <- roi_definition_vol[,,]
    roi_labels <- sort(unique(as.vector(roi_vol_data)))
    roi_labels <- roi_labels[roi_labels != 0]
  }

  # Extract values for each ROI
  if (inherits(data_vol, "NeuroVol")) {
    # 3D data -> single row with one column per ROI
    data_vol_data <- data_vol[,,]
    extracted_values <- sapply(roi_labels, function(label) {
      mask <- roi_vol_data == label
      roi_data <- data_vol_data[mask]
      if (length(roi_data) > 0) {
        stat_func(roi_data, ...)
      } else {
        NA
      }
    })
    extracted_values <- matrix(extracted_values, nrow = 1)
    colnames(extracted_values) <- as.character(roi_labels)
  } else if (inherits(data_vol, "NeuroVec")) {
    # 4D data -> each row is a time point
    nvol <- dim(data_vol)[4]
    extracted_values <- matrix(NA, nrow = nvol, ncol = length(roi_labels))

    for (i in seq_along(roi_labels)) {
      label <- roi_labels[i]
      mask <- as.logical(roi_vol_data == label)

      # Extract time series for this ROI
      for (t in 1:nvol) {
        vol_t <- data_vol[,,,t]
        # Convert mask to array indices for subsetting
        roi_data <- vol_t[which(mask)]
        if (length(roi_data) > 0) {
          extracted_values[t, i] <- stat_func(roi_data, ...)
        } else {
          extracted_values[t, i] <- NA
        }
      }
    }
    colnames(extracted_values) <- as.character(roi_labels)
  } else {
    stop("data_vol must be a NeuroVol or NeuroVec object")
  }

  id_to_label <- NULL
  if (!is.null(atlas$orig_labels)) {
    id_to_label <- setNames(as.character(atlas$orig_labels), atlas$ids)
  } else if (!is.null(atlas$labels)) {
    id_to_label <- setNames(as.character(atlas$labels), atlas$ids)
  }

  if (!is.null(id_to_label)) {
    region_labels <- id_to_label[as.character(colnames(extracted_values))]
    # Only update non-NA labels
    valid_labels <- !is.na(region_labels)
    if (any(valid_labels)) {
      colnames(extracted_values)[valid_labels] <- region_labels[valid_labels]
    }
  }

  # --- Determine output format ---
  if (is.null(format)) {
    # Default: long for NeuroVol, wide for NeuroVec
    format <- if (inherits(data_vol, "NeuroVol")) "long" else "wide"
  }
  
  format <- match.arg(format, c("wide", "long"))
  
  # --- Convert to tibble ---
  if (format == "wide") {
    # Wide format (current behavior)
    if (nrow(extracted_values) == 1) {
      result_tibble <- tibble::as_tibble(extracted_values, .name_repair = "minimal")
    } else {
      result_tibble <- tibble::as_tibble(extracted_values, .name_repair = "minimal")
      result_tibble <- tibble::add_column(result_tibble, time = seq_len(nrow(result_tibble)), .before = TRUE)
    }
  } else {
    # Long format
    if (nrow(extracted_values) == 1) {
      # NeuroVol: region, value
      result_tibble <- tibble::tibble(
        region = colnames(extracted_values),
        value = as.numeric(extracted_values[1, ])
      )
    } else {
      # NeuroVec: time, region, value
      long_data <- expand.grid(
        time = seq_len(nrow(extracted_values)),
        region = colnames(extracted_values),
        stringsAsFactors = FALSE
      )
      long_data$value <- as.numeric(t(extracted_values))
      result_tibble <- tibble::as_tibble(long_data)
    }
  }

  return(result_tibble)
}
</file>

</files>
